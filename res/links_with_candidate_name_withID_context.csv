repoId,link,text,prev_text,next_text
155,http://scikit-learn.org/stable/tutorial/statistical_inference/settings.html#datasets,supervised dataset format, above have the now-standard scikit-learn ,". This means we can use any classifier that satisfies the scikit-learn API. Below, we use a simple wrapper around the scikit-learn "
269,http://snap.stanford.edu/data/index.html,Stanford Large Network Dataset (SNAP),"
","
"
269,http://grouplens.org/datasets/movielens/,Movielens dataset GroupLens,"
","
"
269,http://aws.amazon.com/datasets,Amazon Web Services public datasets,"
","
"
301,http://shuyo.wordpress.com/2012/03/02/estimation-of-ldig-twitter-language-detection-for-liga-dataset/,Estimation of ldig (twitter Language Detection) for LIGA dataset,"
","
"
308,https://github.com/ucd-spatial/Datasets/tree/master/geresid-geo_relatedness_similarity_dataset,Geo-Relatedness and Similarity Dataset (GeReSiD),2. ,"
"
308,https://github.com/ucd-spatial/Datasets/tree/master/mdsm-similarity_dataset,MDSM Geo-Semantic Similarity Dataset,3. ,"
"
308,https://github.com/ucd-spatial/Datasets/tree/master/sentiment_detection_hotel_reviews_dataset,Sentiment Detection in Hotel Reviews Dataset,4. ,"
"
374,http://nilm-metadata.readthedocs.org/en/latest/dataset_metadata.html,Dataset metadata,"Or, if you are already familiar with NILM Metadata then perhaps you want direct access to the full description of the ""","""."
685,http://www.bbci.de/competition/iii/#data_set_i,"BCI Competition3, Data Set 1",An example for classification of motor imagery in ECoG recordings. For that example the , was used.
685,http://www.bbci.de/competition/iii/#data_set_ii,"BCI Competition 3, Data Set 2",An example for classification with a P300 Matrix Speller in EEG recordings. The , was used for that example.
760,http://snap.stanford.edu/data/amazon/amazon_readme.txt,data set,"First, obtain the ",", and clone this repository. The outline of the processing steps is as follows:"
761,https://github.com/Spirals-Team/npe-dataset/,https://github.com/Spirals-Team/npe-dataset/,The evaluation dataset is at ,"
"
791,http://alt.qcri.org/semeval2014/task1/index.php?id=data-and-tools,SICK dataset,"
", (semantic relatedness task)
1067,http://cs.mcgill.ca/~jpineau/datasets/ubuntu-corpus-1.0/ubuntu_dialogs.tgz,cs.mcgill.ca/~jpineau/datasets/ubuntu-corpus-1.0/ubuntu_dialogs.tgz,": directory where 1on1 dialogs will downloaded and extracted, the data will be downloaded from ", (default = '.')
1121,http://www.ub.edu/cvub/egocentric-dataset-of-the-university-of-barcelona-segmentation-edub-seg/,EDUB-Seg dataset,The training and validation of the code was performed using the ,.
1355,http://www.cvlibs.net/datasets/kitti/eval_odometry.php,KITTI dataset, cameras that computes the camera trajectory and a sparse 3D reconstruction (in the stereo and RGB-D case with true scale). It is able to detect loops and relocalize the camera in real time. We provide examples to run the SLAM system in the ," as stereo or monocular, in the "
1355,http://vision.in.tum.de/data/datasets/rgbd-dataset,TUM dataset," as stereo or monocular, in the "," as RGB-D or monocular, and in the "
1355,http://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets,EuRoC dataset," as RGB-D or monocular, and in the "," as stereo or monocular. We also provide a ROS node to process live monocular, stereo or RGB-D streams. "
1374,http://www.ub.edu/cvub/egocentric-dataset-of-the-university-of-barcelona-segmentation-edub-seg/,EDUB-Seg dataset,The , has been used in this paper. Please cite to 
1463,#dataset,Dataset,"
","
"
1506,https://github.com/Element-Research/dataload#dl.loadGBW,Google Billion Words dataset, language models on the ,. The example uses 
1591,https://www.microsoft.com/en-us/research/publication/wikiqa-a-challenge-dataset-for-open-domain-question-answering/,WikiQA: A Challenge Dataset for Open-Domain Question Answering,"
","
"
1690,https://motchallenge.net/data/MOT15/,2D MOT 2015 benchmark dataset,Download the ,"
"
1766,./src/main/java/info/debatty/java/datasets/dblp/,DBLP dataset,"
","
"
1766,./src/main/java/info/debatty/java/datasets/reuters/,Reuters-21578 dataset,"
","
"
1766,./src/main/java/info/debatty/java/datasets/textfile/,Text file dataset,"
","
"
1766,./src/main/java/info/debatty/java/datasets/enron/,ENRON email dataset,"
","
"
1766,./src/main/java/info/debatty/java/datasets/sift/,Scale-invariant feature transform (SIFT) dataset,"
","
"
1824,http://data.computational-advertising.org,iPinYou dataset,"For running further large-scale experiments, you will rely on another repository which is written for ", feature engineering.
1856,https://sites.google.com/site/assistmentsdata/home/assistment-2009-2010-data/skill-builder-data-2009-2010,Assistments 2009-2010 dataset,We have included the skill builder version of the , which is one of the datasets evaluated in the paper.
1915,http://www.comp.leeds.ac.uk/mat4saj/lspet_dataset.zip,LSP Extended dataset,"
","
"
2006,https://github.com/kermitt2/article-dataset-builder,article-dataset-builder,"Finally, the following python utilities can be used to create structured full text corpora of scientific articles. The tool simply takes a list of strong identifiers like DOI or PMID, performing the identification of online Open Access PDF, full text harvesting, metadata aggregation and Grobid processing in one workflow at scale: ","
"
2013,#datasets,Datasets,"
","
"
2104,http://caffe2.ai/docs/datasets.html,Datasets,"
","
"
2210,https://archive.ics.uci.edu/ml/datasets/Adult,UCI Adult Data Set,"We cannot release our dataset publicly, so the a toy dataset needs to be set up. We use the "," for this purpose. Although it is a regular tabular dataset, and has a Gausian distribution instead of a heavy tailed one over the attributes, it is fine for experimenting. Then you can work on your own."
2270,https://github.com/petteriTeikari/vesselNN_dataset/tree/4daf46cee49f411b759f04ff92b92dd1dbbc25b4,open-source dataset, (see below for full citation). The repository comes with an , with dense voxel-level annotations for vasculature that we hope that stimulate further research on vascular segmentation using deep learning networks.
2270,https://github.com/petteriTeikari/vesselNN/blob/master/configs/ZNN_configs/datasetPaths/dataset_forVD2D.spec,dataset_forVD2D3D.spec,"
"," defines path for image/label files of your dataset. For example images 1-12 refer to the images from the microscope, 13-24 refer to the output images from the VD2D part of the recursive ""two-stage"" approach of ZNN. The outputs of the VD2D part are provided in the "
2270,https://github.com/petteriTeikari/vesselNN_dataset/tree/4daf46cee49f411b759f04ff92b92dd1dbbc25b4/experiments/VD2D_tanh,dataset repository," defines path for image/label files of your dataset. For example images 1-12 refer to the images from the microscope, 13-24 refer to the output images from the VD2D part of the recursive ""two-stage"" approach of ZNN. The outputs of the VD2D part are provided in the ",", and can be used for re-training of the VD2D3D stage, or if you may you can obtain new VD2D outputs for your dataset if you wish."
2288,http://web.science.mq.edu.au/~dqnguyen/papers/TACL-datasets.zip,[Datasets],"
","
"
2315,#preparing-and-using-the-coco-and-pascal-datasets,Preparing and using the COCO and PASCAL datasets,"
","
"
2468,#datasets,Datasets and Simulators,"
","
"
2468,https://zhangjiqing.com/dataset/,dataset,", ",.
2468,http://sar-lab.net/event-based-vehicle-detection-and-tracking-dataset/,dataset,", ",.
2468,http://wp.doc.ic.ac.uk/pb2114/datasets/,Dataset: 4 sequences,", ","
"
2468,https://sites.google.com/a/udayton.edu/issl/software/dataset?authuser=0,Dataset,", ","
"
2468,https://datasets.hds.utc.fr/share/er2aA4R0QMJzMyO,Dataset,", ",", "
2468,https://github.com/wl082013/ESIM_dataset,Dataset,", ","
"
2468,#1mpx_detection_dataset,1Mpx Detection Dataset,", Advances in Neural Information Processing Systems 33 (NeurIPS), 2020. ","
"
2468,#dvsgesture_dataset,Dataset,", ","
"
2468,#ncars_dataset,N-CARS Dataset,"
",: A large real-world event-based dataset for car classification.
2468,https://sites.google.com/a/udayton.edu/issl/software/dataset,Dataset,", ","
"
2468,http://rpg.ifi.uzh.ch/davis_data.html,"The Event-Camera Dataset and Simulator: Event-based Data for Pose Estimation, Visual Odometry, and SLAM","
",","
2468,http://rpg.ifi.uzh.ch/davis_data.html,Dataset,", ",.
2468,http://sensors.ini.uzh.ch/databases.html,Datasets from the Sensors group at INI,"
"," (Institute of Neuroinformatics), Zurich:"
2468,https://sites.google.com/a/udayton.edu/issl/software/dataset?authuser=0,DVSMOTION20 Dataset,. ,"
"
2468,http://rpg.ifi.uzh.ch/davis_data.html,"The Event-Camera Dataset and Simulator: Event-based Data for Pose Estimation, Visual Odometry, and SLAM","
",","
2468,http://rpg.ifi.uzh.ch/davis_data.html,Dataset,", ",.
2468,http://sensors.ini.uzh.ch/databases.html,Dataset," Int. Conf. Machine Learning, Workshop on Machine Learning for Autonomous Vehicles, 2017. ","
"
2468,https://sites.google.com/view/davis-driving-dataset-2020/home,Dataset,", IEEE Intelligent Transportation Systems Conf. (ITSC), 2020. ",", "
2468,http://sensors.ini.uzh.ch/databases.html,More datasets,", ","
"
2468,https://vision.in.tum.de/data/datasets/visual-inertial-event-dataset,TUM-VIE: The TUM Stereo Visual-Inertial Event Data Set,"
","
"
2468,https://visibilitydataset.github.io/,ViViD++: Vision for Visibility Dataset,"Lee, A. J., Cho, Y., Shin, Y., Kim, A., Myung, H., ",", IEEE Robotics and Automation Letters (RA-L), 2022. "
2468,https://visibilitydataset.github.io/,Dataset,", IEEE Robotics and Automation Letters (RA-L), 2022. ","
"
2468,https://star-datasets.github.io/vector/,Dataset,", ",", "
2468,https://github.com/mgaoling/mpl_dataset_toolbox,MPL Dataset Toolbox,", ",.
2468,http://www.garrickorchard.com/datasets/n-mnist,Neuromorphic-MNIST (N-MNIST) dataset,"
", is a spiking version of the original frame-based MNIST dataset (of handwritten digits). 
2468,http://www.garrickorchard.com/datasets/n-caltech101,The Neuromorphic-Caltech101 (N-Caltech101) dataset,"
", is a spiking version of the original frame-based Caltech101 dataset. 
2468,http://dgyblog.com/projects-term/dvs-dataset.html,Dataset," Front. Neurosci. (2016), 10:405. ","
"
2468,http://www.prophesee.ai/dataset-n-cars/,N-CARS Dataset,"
",: A large real-world event-based dataset for car classification.     
2468,https://www.prophesee.ai/2020/11/24/automotive-megapixel-event-based-dataset/,1Mpx Detection Dataset," Perot, E., de Tournemire, P., Nitti, D., Masci, J., Sironi, A.,  ",: 
2468,https://sites.google.com/view/dnd21/datasets?authuser=0,DND21 DeNoising Dynamic vision sensors dataset,"
", associated to the paper 
2532,http://people.bath.ac.uk/hc551/dataset.html,Photo-Art-50 dataset,We provide a link to the page on which the , is hosted. Please cite the papers of the authors of the dataset if you use it. The models for testing SwiDeN can be found 
2553,https://github.com/yjxiong/temporal-segment-networks/wiki/Working-on-custom-datasets.,How to add a custom dataset,",    ","
"
2592,#datasets,Datasets,"
","
"
2617,https://serv.cusp.nyu.edu/projects/urbansounddataset/index.html,UrbanSound8k dataset," format [1,2] for the ", [3]. It also contains the extended JAMS files returned by the 
2689,https://retriever.readthedocs.io/en/latest/datasets_list.html,List of Available Datasets,"
","
"
2689,https://en.wikipedia.org/wiki/Iris_flower_data_set,"
Iris flower dataset",These examples are using the ,. More examples can be found in the Data Retriever documentation.
2757,https://web.archive.org/web/20131118073324/https://www.infochimps.com/datasets/word-list-350000-simple-english-words-excel-readable,https://www.infochimps.com/datasets/word-list-350000-simple-english-words-excel-readable,While searching for a list of english words (for an auto-complete tutorial) I found: https://stackoverflow.com/questions/2213607/how-to-get-english-language-word-database which refers to , (archived).
2791,http://www.cvlibs.net/datasets/kitti/,http://www.cvlibs.net/datasets/kitti/,"[1] A. Geiger, P. Lenz, C. Stiller, and R. Urtasun, ""Vision meets robotics: The KITTI dataset,"" Int. J. Robot. Research (IJRR), vol. 32, no. 11, pp. 1231–1237, Sep. 2013. ","
"
2822,https://archive.ics.uci.edu/ml/datasets/Character+Trajectories,Character Trajectories Data Set , is the , from UCI
2895,https://fcav.engin.umich.edu/sim-dataset,10k dataset, on our , and evaluate on 
3014,#62-datasets,6.2. Datasets,"
","
"
3083,#dataset-summary,Dataset Summary,"
","
"
3083,http://labrosa.ee.columbia.edu/millionsong/pages/getting-dataset,Million Song Dataset,"A 10,000-song subset was downloaded from the ",.
3216,datasets/facemodel/README.md,datasets/facemodel/README.md,"This demo requires a database of high resolution images, which is used to select source and target images for the transformation. Follow the instructions at ", to collect the database.
3216,datasets/test/,datasets/test/,The source of each test image and our test masks are in ,". We find that DFI works well on photographs of natural faces which are: un-occluded, front-facing, and lit by natural or office-environment lighting."
3261,http://mscoco.org/dataset/#download,COCO dataset,Please download , and annotations for the 5k image 
3296,https://github.com/fvisin/dataset_loaders,The dataset loader,"
",". Thanks a lot to Francesco Visin for its data loader, please cite it if you use it."
3311,https://www.cityscapes-dataset.com/downloads/,Cityscapes dataset,Download the ,", and put the extracted images into the directory:"
3366,#6-paris-street-view-dataset,Download Dataset,"
","
"
3372,https://towardsdatascience.com/a-data-lakes-worth-of-audio-datasets-b45b88cd4ad,Over 1.5 TB’s of Labeled Audio Datasets,"
",", Towards Data Science, 2018-11-13."
3372,https://www.analyticsvidhya.com/blog/2018/03/comprehensive-collection-deep-learning-datasets/,25 Open Datasets for Deep Learning Every Data Scientist Must Work With,"
",", Analytics Vidhya, 2018-03-29."
3372,https://tensorflow.blog/2017/03/14/fma-a-dataset-for-music-analysis,FMA: A Dataset For Music Analysis,"
",", tensorflow.blog, 2017-03-14."
3372,https://github.com/caesar0301/awesome-public-datasets,https://github.com/caesar0301/awesome-public-datasets,"
","
"
3372,https://archive.ics.uci.edu/ml/datasets/FMA:+A+Dataset+For+Music+Analysis,https://archive.ics.uci.edu/ml/datasets/FMA:+A+Dataset+For+Music+Analysis,"
","
"
3372,http://deeplearning.net/datasets,http://deeplearning.net/datasets,"
","
"
3372,https://github.com/ismir/mir-datasets,https://github.com/ismir/mir-datasets,"
","
"
3372,https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research,https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research,"
","
"
3372,https://cloudlab.atlassian.net/wiki/display/datasets/FMA:+A+Dataset+For+Music+Analysis,https://cloudlab.atlassian.net/wiki/display/datasets/FMA:+A+Dataset+For+Music+Analysis,"
","
"
3372,https://www.datasetlist.com,https://www.datasetlist.com,"
","
"
3552,https://github.com/RSIA-LIESMARS-WHU/LSHBOX-sample-data,LSHBOX-sample datasets,"
",: a dataset for performance tests
3559,https://github.com/deepdsl/deepdsl/tree/master/deepdsl-java/dataset/mnist/,dataset/mnist/," uses Mnist, which is assumed to be located at ", (please use the script described in the previous section to prepare the dataset).
3695,https://github.com/yiling-chen/flickr-cropping-dataset,Flickr cropping dataset,We provide the evaluation script to reproduce our evaluation results on ,". For example,"
3695,https://github.com/yiling-chen/flickr-cropping-dataset,Flickr cropping dataset, and the test images from the , and specify the path of your model when running 
3844,http://vision.in.tum.de/data/datasets/rgbd-dataset,TUM RGBD datasets,The example application takes input frames and poses from the ,", and requires that your create an "
3915,http://lmb.informatik.uni-freiburg.de/resources/datasets/,FBMS-59 dataset,The datasets included originate from the ,". The datasets are provided only for research purposes and without any warranty. When using the BMS-26 or FBMS-59 in your research work, you should cite the appropriate papers in the link above."
3955,http://www.vs.inf.ethz.ch/res/show.html?what=eco-data,The ECO dataset,"
",: Together with 
4004,#download-datasets,Download Datasets,"
","
"
4004,#evaluating-on-benchmark-datasets,Evaluating on benchmark datasets,"
","
"
4027,http://vlado.fmf.uni-lj.si/pub/networks/data/ucinet/ucidata.htm,Ucinet IV Datasets,"
",.
4042,https://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption,https://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption,The repository supports optimization of the above models on artifical multivariate noisy AR time series and household electricity conspumption dataset , The dataset has to be specified alongside the paremeters in each of the files listed above.
4066,http://ganymed.imib.rwth-aachen.de/irma/datasets/,IRMA Skin Lesion Dataset,The ," has 747 dermoscopic images (187 melanomas). This dataset is unlisted, but available under special request, and the signing of a license agreement."
4066,http://www.fc.up.pt/addi/ph2%20database.html,PH2 Dataset,The , has 200 dermoscopic images (40 melanomas). It's freely available after signing a short online registration form.
4072,#suggested-datasets-and-models,Suggested Datasets and Models,"
","
"
4072,#datasets,Datasets,"
","
"
4072,#adding-a-dataset,Adding a dataset,"
","
"
4100,https://archive.ics.uci.edu/ml/datasets/Wine+Quality,winequality dataset,Download ,", and other datasets and change utils.py to add new datasets to test out the pruning algorithm."
4113,http://datahub.io/dataset/amsterdam-museum-as-edm-lod,http://datahub.io/dataset/amsterdam-museum-as-edm-lod,Amsterdam Museum (,)
4254,http://lemire.me/data/integercompression2014.html,Document identifier data set,"
","
"
4259,http://mscoco.org/dataset/#captions-challenge2015,MSCOCO Image Caption dataset, and , using an auto-tagging system for each image. Some of the results are shown below (left and right columns are selected samples from Clickture and MSCOCO caption dataset respectively.)
4285,#example-dataset,Example dataset,"
","
"
4304,http://www.comp.leeds.ac.uk/mat4saj/lspet_dataset.zip,LSP Extended dataset,"
", (10000 train images)
4309,http://people.ee.ethz.ch/~ihnatova/#dataset,DPED dataset,Download , (patches for CNN training) and extract it into 
4352,https://www.dropbox.com/s/9t770jhcjqo3mmg/release_data.zip,Horse Dataset,Download the , (580 MB)
4353,https://github.com/davidstutz/superpixel-benchmark-data,Datasets, | , | 
4366,https://github.com/AlexKuhnle/ShapeWorld/tree/master/shapeworld/datasets,dataset arguments," if necessary, see ", for details)
4366,https://github.com/AlexKuhnle/ShapeWorld/tree/master/shapeworld/datasets,dataset arguments," if necessary, see ", for details)
4475,#preprocess-vqa-dataset,Preprocess VQA dataset,"
","
"
4495,http://www.cse.cuhk.edu.hk/leojia/projects/dblurdetect/dataset.html,Blur Detection Dataset,Test images are from , [2].
4549,https://github.com/sajao/CrisisLex/tree/master/data/CrisisLexT26,CrisisLexT26 Dataset,"
","
"
4549,http://www.crowdflower.com/data-for-everyone,CrowdFlower10K Dataset,"
","
"
4633,https://github.com/ctuning/ctuning-datasets-min,'ctuning-datasets-min' repository,) to the ,.
4661,https://www.researchgate.net/publication/320475411_When_to_use_what_data_set_for_your_self-driving_car_algorithm_An_overview_of_publicly_available_driving_datasets,"""When to use what data set for your self-driving car algorithm: An overview of publicly available driving datasets""","H. Yin, C. Berger: ","
"
4688,#adding-a-new-dataset,Adding a new dataset,"
","
"
4705,http://datadryad.org/resource/doi:10.5061/dryad.jp917,data set," concept unique identifiers (CUIs), derived from 20 million clinical notes spanning 19 years of data from Stanford Hospital and Clinics, using a  ", released in a 
4711,https://www.tensorflow.org/datasets/catalog/fashion_mnist,TensorFlow Datasets,"
","
"
4711,https://huggingface.co/datasets/fashion_mnist,HuggingFace Datasets,"
","
"
4745,/terngrad/split_dataset.sh,split_dataset.sh,We also provide , to 
4747,http://jmcauley.ucsd.edu/data/amazon/,Amazon dataset,"
","
"
4789,https://cs.adelaide.edu.au/users/hwong/doku.php?id=data,AdelaideRMF dataset,Download the , into 
4789,http://vision.jhu.edu/data/,Hopkings dataset,Download , into 
4799,dataset/multi_paste/cattle_gcs500_copy_rb5.png,cattle dataset," of the blocks group and the total number of the blocks it is formed with. If this list is not empty, we can assume that the image is being tampered. For example, running the ", with 32 px of block size will result in:
4839,https://omnomnom.vision.rwth-aachen.de/data/atari_v1_release/full.tar.gz,the whole dataset (screenshots + trajectories) for all five games,"
","
"
4862,#11-train-with-a-face-dataset-celeba,Face dataset: CelebA,"
","
"
4862,#12-train-with-a-digit-dataset-mnist,Digit dataset: MNIST,"
","
"
4903,http://slate.cse.ohio-state.edu/UTSAuthenticatedDownloader/index.html?dataset=BMASS,Download the dataset,"
", (requires a valid 
5016,http://pytorch.org/audio/main/datasets.html,Dataloaders for common audio datasets,"
","
"
5040,src/example/java/apps/dataset,dataset, to construct an index from a raw corpus of documents (several examples of this latter could be consulted in directory ,", including, e.g., the "
5040,src/example/java/apps/dataset,dataset, extractor. The , directory contains many examples of corpus indexing. Both extractors are subclasses of the generic class 
5074,datasets.md,datasets,53 datasets used. See the list of ,. Datasets pie chart: 
5074,http://www.audiocontentanalysis.org/data-sets/,AudioContentAnalysis nearly exhaustive list of music-related datasets,"
","
"
5074,https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research#cite_ref-215,Wikipedia's list of datasets for machine learning research,"
","
"
5074,http://deeplearning.net/datasets/,Datasets for deep learning,"
","
"
5074,https://github.com/caesar0301/awesome-public-datasets,Awesome public datasets,"
","
"
5102,http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html,LibSVM Datasets," dataset, available at ",.
5113,https://github.com/gittar/k-means-u-star/blob/master/notebooks/dataset_class.ipynb,dataset_class.ipynb,"
","
"
5167,#datasets,Datasets,"
","
"
5168,#kbp-dataset,Processing KBP Dataset,"
","
"
5189,#download-dataset-locally,Download Dataset Locally,"
","
"
5189,#create-your-own-dataset-files,Create Your Own Dataset Files,"
","
"
5194,http://spatialrelations.cs.uni-freiburg.de/#dataset,dataset,Download the ,"
"
5385,https://github.com/codeneuro/neurofinder-datasets,"
neurofinder-datasets
","
", example scripts for loading the datasets
5507,#datasets,Datasets,"
","
"
5507,http://math.bu.edu/people/kolaczyk/datasets.html,Eric D. Kolaczyk’s Network Datasets,"
",.
5507,http://networksciencebook.com/translations/en/resources/data.html,Network Science Book - Network Datasets,"
", - Network data sets from Albert-László Barabási’s 
5507,http://vlado.fmf.uni-lj.si/pub/networks/data/,Pajek Datasets,"
",.
5507,http://www.stats.ox.ac.uk/~snijders/siena/siena_datasets.htm,Siena Datasets,"
",.
5507,http://www.sociopatterns.org/datasets/,SocioPatterns Datasets,"
", - Network data obtained through the 
5507,http://snap.stanford.edu/data/index.html,Stanford Large Network Dataset Collection,"
",.
5507,https://toreopsahl.com/datasets/,tnet Datasets,"
", - Weighted network data.
5507,https://sites.google.com/site/ucinetsoftware/datasets,UCINET Datasets,"
", - Network data in UCINET format.
5559,docs/datasets.md,Datasets,"
","
"
5592,https://github.com/CornellNLP/ConvoKit#datasets,conversational datasets, inspired by (and compatible with) scikit-learn.  Several large , are included together with scripts exemplifying the use of the toolkit on these datasets. The latest version is 
5624,#grab-a-dataset,Grab a Dataset,"
","
"
5624,https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html,https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html,"For this example, we'll use the ""a1a"" dataset, acquired from ",. Currently the Photon ML dataset converter supports only the LibSVM format.
5643,http://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets,EuRoC MAV Dataset,Download ,". Although it contains stereo cameras, we only use one camera. The system also works with "
5643,http://robotics.ethz.ch/~asl-datasets/maplab/multi_session_mapping_CLA/bags/,ETH-asl cla dataset,". Although it contains stereo cameras, we only use one camera. The system also works with ",. We take EuRoC as the example.
5688,doc/tutorials/datasetmapper.md,DatasetMapper,"
","
"
5701,#twitter-dataset,Twitter Dataset,"
","
"
5772,http://graphics.stanford.edu/data/3Dscanrep/,Stanford dragon_stand dataset, using the ,.
5772,http://qianyi.info/scenedata.html,Stanford lounge dataset, can be used to register depth frames in the ,. Please see section below for results.
5772,http://qianyi.info/scenedata.html,Stanford lounge dataset,Results of running GMMReg-Rigid on ,"
"
5855,https://github.com/val-iisc/sketch-parse/tree/master/exp-src/data/sketch-dataset,exp-src/data/sketch-dataset,"For instructions to get annotated sketch dataset, navigate to ",. Pose dataset is present in 
5856,http://lixirong.net/data/mm2015/rucmmc_irc2015_data.tar.gz,dataset,Download , without image visual feature.
5956,https://www.audiocontentanalysis.org/data-sets/,MIR datasets,"
",: An awesome list of MIR datasets
6028,http://rpg.ifi.uzh.ch/davis_data.html,The Event Camera Dataset and Simulator,", such as those of ",. 
6065,https://sites.google.com/site/iitaffdataset/,IIT-AFF dataset,). This weight is trained on the training set of the ,:
6065,https://sites.google.com/site/iitaffdataset/,IIT-AFF dataset,We train AffordanceNet on ,"
"
6065,https://sites.google.com/site/iitaffdataset/,IIT-AFF dataset,If you use ,", please consider citing:"
6232,https://ram-lab.com/file/tai_icra_2018_dataset.zip,pedestrian navigation dataset,The collected , contains:
6315,https://github.com/haozhenWu/lightchem/tree/master/datasets,Datasets,"
","
"
6325,http://ml.cs.tsinghua.edu.cn/~yinpeng/adversarial/dataset.zip,http://ml.cs.tsinghua.edu.cn/~yinpeng/adversarial/dataset.zip,"We use a subset of ImageNet validation set containing 1000 images, most of which are correctly classified by those models. Our dataset can be downloaded at ",. You can alternatively use the NIPS 2017 competition official 
6325,https://github.com/tensorflow/cleverhans/tree/master/examples/nips17_adversarial_competition/dataset,dataset,. You can alternatively use the NIPS 2017 competition official ,.
6337,https://preferredjp.box.com/v/pfn-pic-dataset-main,Download (dataset-main.zip),"
","
"
6338,http://www.mohamedaly.info/datasets/caltech-lanes,Caltech Lanes Dataset,Download ,.
6347,https://research.googleblog.com/2017/08/launching-speech-commands-dataset.html,Speech Commands Dataset,"Honk is a PyTorch reimplementation of Google's TensorFlow convolutional neural networks for keyword spotting, which accompanies the recent release of their ",". For more details, please consult our writeup:"
6347,http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz,Speech Commands Dataset, trains or evaluates the model. It expects all training examples to follow the same format as that of ,". The recommended workflow is to download the dataset and add custom keywords, since the dataset already contains many useful audio samples and background noise."
6348,https://github.com/mmalekzadeh/replacement-autoencoder/blob/master/skoda/RAE_on_Skoda_dataset.ipynb,RAE_on_Skoda_dataset.ipynb,"Codes and files are available under ""skoda"" folder: ","
"
6362,http://projects.asl.ethz.ch/datasets/doku.php?id=laserregistration:laserregistration,"
Challenging data sets for point cloud registration algorithms
","
","
"
6365,http://www.cvlibs.net/datasets/kitti/,kitti dataset,"In this example we create a cblox map using the lidar data and ""ground-truth"" pose estimates from the ",. This simple example demonstrates the 
6365,http://www.cvlibs.net/datasets/kitti/raw_data.php,kitti raw dataset,To run the example download a ,". To produce the map above, we ran the ""2011_09_30_drive_0018"" dataset under the catagory ""residential"". Convert the data to a rosbag using "
6367,https://www.microsoft.com/en-us/research/project/figureqa-dataset/,The dataset is available for download here,Code to generate the FigureQA dataset. ,.
6458,https://github.com/ramey/datamicroarray/wiki/Alon-%281999%29,Alon et al. (1999) Colon Cancer data set," command. For example, to load the well-known ",", type the following at the R console:"
6458,https://github.com/ramey/datamicroarray/wiki/Alon-%281999%29,Alon et al. (1999) Colon Cancer data set,Here is a summary for the ,.
6475,https://github.com/xuchen/jacana/tree/master/tree-edit-data/answerSelectionExperiments/data,answer sentence selection dataset,We use the , from TREC QA as our source of indirect supervision. We ran Stanford NER to extract entity mentions on both question and answer sentences and process the dataset into JSON format containing QA-pairs. Details of how we construct QA-pairs can be found in our paper.
6503,https://rose1.ntu.edu.sg/dataset/actionRecognition/,https://rose1.ntu.edu.sg/dataset/actionRecognition/,"
","
"
6516,http://www.fc.up.pt/addi/ph2%20database.html,PH2 Dataset,The , has 200 dermoscopic images (40 melanomas). It's freely available after signing a short online registration form.
6568,https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/0_Prerequisite/mnist_dataset_intro.ipynb,Introduction to MNIST Dataset,"
",.
6568,https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/tensorflow_v1/0_Prerequisite/mnist_dataset_intro.ipynb,Introduction to MNIST Dataset,"
",.
6663,#qa-datasets,QA Datasets,". We also list several different datasets for evaluation, see ",. Note that this work is a refactored and more efficient version of the original code. Reproduction numbers are very similar but not exact.
6682,#datasets,datasets,. Check the , section for details.
6703,https://ai.stanford.edu/~jkrause/cars/car_dataset.html,Standford cars dataset,a script to finetune a pretrained resnet50 on the , to 90% accuracy in 60 epochs.
6774,https://github.com/sfzhang15/RefineDet/blob/master/test/lib/datasets/pascal_voc.py,"
test/lib/datasets/pascal_voc.py
",Change the ‘self._devkit_path’ in , to yours.
6774,https://github.com/sfzhang15/RefineDet/blob/master/test/lib/datasets/coco.py,"
test/lib/datasets/coco.py
",Change the ‘self._data_path’ in , to yours.
6786,http://cocodataset.org/#download,http://cocodataset.org/#download,Download MSCOCO images from ,. We train in COCO 
6803,#datasets,Datasets,"
","
"
6816,http://cocodataset.org/#home,COCO Dataset,Download COCO2017 image from ,"
"
6871,http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html,notMNIST dataset," does the same accuracy comparisons, but for the ",. We omit the textual explanations since it would be redundant with what's in the MNIST notebook.
6872,#build-your-own-dataset,Build Your Own Dataset,"
","
"
6873,utils/datasetcollections.py,dataset collections,This runs all experiments included in the results section of our paper. It is up to the user to download the datasets and link to them in the ," file. The output folders including the folders where the data will be stored (in this case testoutput/fullruns/2003_np/) have to exist before running the code, if folders are missing an error message will indicate this. Speeding up the simulations can be done by allocating more processes using the n_proc flag."
6874,utils/datasetcollections.py,dataset collections, to be installed. It is up to the user to download the datasets and link to them in the ," file. The output folders including the folders where the data will be stored (in this case testoutput/fullruns/2003_np/) have to exist before running the code, if folders are missing an error message will indicate this. Speeding up the simulations can be done by allocating more processes using the n_proc flag."
6999,http://www.robots.ox.ac.uk/~vgg/data/dtd/,Describable Textures Dataset,"get a dataset with backgrounds, e.g. the ","
"
7000,https://archive.ics.uci.edu/ml/datasets/airfoil+self-noise,"
UCI Airfoil Self-Noise Data Set
", trained on the ,", converted to the TT format via cross-approximation):"
7030,http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d,Kitti Object Detection Dataset,To train on the ,:
7042,http://pytorch.org/docs/master/torchvision/datasets.html#torchvision.datasets.ImageFolder,torchvision.datasets.ImageFolder,Our script uses ," for loading ImageNet data, which expects folders organized as follows:"
7147,http://redwood-data.org/3dscan/dataset.html?c=chair,Redwood Dataset,"
","
"
7278,https://github.com/afagarap/pt-datasets,"
pt-datasets
","To use the dataset from this repository, you can intall ",","
7310,http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset,German Traffic Sign Dataset,"This project creates and trains a deep convolutional neural network from scratch, with the task of classifying German traffic signs using the ",". The trained model is subsequently tested on German traffic signs found on the web, as well as US traffic signs."
7392,#2-berkeley-adobe-perceptual-patch-similarity-bapps-dataset,Berkeley-Adobe Perceptual Patch Similarity (BAPPS) dataset,"
","
"
7392,#c-about-the-dataset,About the dataset, c. ,"
"
7392,#d-using-the-dataset-to-train-the-metric,Train the metric using the dataset, d. ,"
"
7504,recognition/_datasets_,dataset,"The training data includes, but not limited to the cleaned MS1M, VGG2 and CASIA-Webface datasets, which were already packed in MXNet binary format. Please ", page for detail.
7564,https://data.mendeley.com/datasets/5ty2wb6gvg/1,RDD2020 dataset,[2021-03-19]: , is now available at Mendeley in a citable and easy to share form!
7564,https://mycityreport.s3-ap-northeast-1.amazonaws.com/02_RoadDamageDataset/public_data/Japan/RDD2020_data.tar.gz,RoadDamageDataset_2019 (2.4GB),"
","
"
7564,https://mycityreport.s3-ap-northeast-1.amazonaws.com/02_RoadDamageDataset/public_data/Japan/CACAIE2018/RoadDamageDataset.tar.gz,RoadDamageDataset_v1 (1.7GB),"
","
"
7608,#dataset-set-up,Dataset set-up,"
","
"
7668,maskrcnn_benchmark/data/datasets/coco.py,"
maskrcnn_benchmark/data/datasets/coco.py
"," is implemented, check ",.
7668,maskrcnn_benchmark/data/datasets/__init__.py,"
maskrcnn_benchmark/data/datasets/__init__.py
","
",: add it to 
7668,maskrcnn_benchmark/data/datasets/evaluation/__init__.py,"
maskrcnn_benchmark/data/datasets/evaluation/__init__.py
","To enable your dataset for testing, add a corresponding if statement in ",:
7670,http://corpus-texmex.irisa.fr/,Datasets for approximate nearest neighbor search,"dataset, ","
"
7694,https://archive.org/details/comma-dataset,archive.org comma dataset,or get it at ,"
"
7716,https://github.com/fMoW/dataset,fMoW-rgb dataset,Download the ," and uncompress it. To run our fMoW submission for a test set without running the training, execute the following sequence of commands:"
7726,docs/data_config_en.md,Dataset,"Dataset will be automatically configured in current path, or download manually your data in ",",  step-by step."
7731,kernet/datasets/,kernet/datasets,You can add dataset and model by modifying , and  
7745,#datasets,Datasets,"
","
"
7751,https://data.4tu.nl/articles/dataset/MTL_Music_Representation_data_underlying_the_publication_One_deep_music_representation_to_rule_them_all_A_comparative_analysis_of_different_representation_learning_strategies/12692300/1,dataset page,"To extract CNN features from provided model, one should first download the model files from the ",". Once the model is stored locally, one then can extract features by calling following command."
7762,https://bitbucket.org/franrruiz/augment-reduce-data/src,the datasets,You can also obtain , used in the paper.
7772,https://github.com/twitter/torch-dataset,torch-Dataset,"
","
"
7800,http://archive.ics.uci.edu/ml/datasets/Musk+(Version+1),musk1 dataset,An example script is included that trains classifiers on the ,; see:
7822,https://archive.ics.uci.edu/ml/datasets/Daphnet+Freezing+of+Gait,Daphnet Freezing of Gait dataset at UCI,Please download the , to run this code with an openly available dataset.
7961,#dataset,Dataset,"
","
"
8002,http://pytorch.org/docs/data.html,torch.utils.data.Dataset, I recommend to write your own dataloader using , since 
8003,./datasets.py,datasets.py,"Dataloaders for FlyingChairs, FlyingThings, ChairsSDHom and ImagesFromFolder are available in ",. 
8035,https://data.vision.ee.ethz.ch/cvl/DIV2K/,DIV2K dataset,Download DIV2K training data (800 training + 100 validtion images) from , or 
8096,https://download.visinf.tu-darmstadt.de/data/from_games/,GTA5 Dataset,Download the ," as the source domain, and put it in the "
8096,https://www.cityscapes-dataset.com/,Cityscapes Dataset,Download the ," as the target domain, and put it in the "
8119,http://www.cs.cmu.edu/~glai1/data/race/,RACE dataset,Pretrain our model with , for 10 epochs.
8196,http://www.cvlibs.net/datasets/kitti/raw_data.php,KITTI raw dataset," tasks, the training data is ", and you can download them by the 
8196,http://www.cvlibs.net/download.php?file=data_odometry_color.zip,KITTI odometry dataset," task, the training data is ", and you should download the calibration files as well as ground truth poses (for evaluation).
8196,http://www.cvlibs.net/download.php?file=data_scene_flow.zip,KITTI flow 2015 dataset,Firstly you need to download the , and its 
8214,https://www.cityscapes-dataset.com/,CityScapes dataset for urban scenes,"Semantic segmentation benefits robotics related applications especially autonomous driving. Most of the research on semantic segmentation is only on increasing the accuracy of segmentation models with little attention to computationally efficient solutions. The few work conducted in this direction does not provide principled methods to evaluate the      different design choices for segmentation. In RTSeg, we address this gap by presenting a real-time semantic segmentation benchmarking framework with a decoupled design for feature extraction and decoding methods. The code and the experimental results are presented on the ",.
8259,#part-2-prepare-dataset,Prepare dataset,"
","
"
8259,http://www.cvlibs.net/datasets/kitti/raw_data.php,KITTI Driving Dataset,The main dataset used in this project is ,. Please follow the instruction in 
8270,http://luminoth.readthedocs.io/en/latest/usage/dataset.html,Adapting a dataset,See ,.
8316,https://www.crowdai.org/challenges/www-2018-challenge-learning-to-recognize-musical-genre/dataset_files,datasets,Download and extract , such as:
8316,https://www.crowdai.org/challenges/www-2018-challenge-learning-to-recognize-musical-genre/dataset_files,challenge's dataset page,"Note that this script can take many hours to complete on the whole 60k tracks. For you to play with the data right away, you'll find those features pre-computed on the ",.
8367,#dataset,Dataset,"
","
"
8441,http://mscoco.org/dataset/#download,MSCOCO dataset,"For ease-of-use, we make pretrained features available for the entire ",. It is not necessary to clone or build this repo to use features downloaded from the links below. Features are stored in tsv (tab-separated-values) format that can be read with 
8510,#additional-datasets,Additional datasets,"
","
"
8510,#creating-and-preprocessing-a-new-java-dataset,creating a new dataset,For , or 
8510,https://github.com/tech-srl/code2seq/blob/master/README.md#datasets,https://github.com/tech-srl/code2seq/blob/master/README.md#datasets," paper, using the code2vec preprocessing. These datasets are available in raw format (i.e., .java files) at ",", and are also available to download in a preprocessed format (i.e., ready to train a code2vec model on) here:"
8520,dataset-code/build_json_dataset.py,build_json_dataset.py,"
",: several functions for creating the dataset from BMJ Case Reports (code for scraping and processing HTML data from the web will be added later)
8520,dataset-code/refine_json_dataset.py,refine_json_dataset.py,"
",: removing instances matching partly with a part of the passage
8536,./utils/datasets.py,./utils/datasets.py,"In the paper, we present the Continuous task-agnostic Permuted MNIST experiment, where task-switch is performed slowly over time. To create similar experiment, you can use the included sampler - ContinuousMultinomialSampler. The sampler, and the function of creating data for the continuous experiment are at ", (relevant function: ds_padded_cont_permuted_mnist()).
8537,http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html,notMNIST dataset,The , is a image recognition dataset of font glypyhs for the letters A through J useful with simple neural networks. It is quite similar to the classic 
8650,http://www.cvlibs.net/datasets/kitti/eval_odometry.php,http://www.cvlibs.net/datasets/kitti/eval_odometry.php,See https://github.com/JakobEngel/dso for how to run on a dataset. Run on a dataset from , using:
8681,http://www.icwsm.org/data/,ICWSM 2011 Spinn3r dataset,The ,"
"
8743,https://storage.googleapis.com/graphsense-dumps/ransomware/ransomware_dataset_04_11_2018.tar.gz,expanded dataset,Possibility 2a: Download the dataset , and save it into 
8746,#dataset,Dataset,"
","
"
8781,https://ember.elastic.co/ember_dataset.tar.bz2,https://ember.elastic.co/ember_dataset.tar.bz2,| Year | Feature Version | Filename                     | URL                                                                                                            | sha256                                                             | |------|-----------------|------------------------------|----------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------| | 2017 | 1               | ember_dataset.tar.bz2        | ,               | 
8781,https://ember.elastic.co/ember_dataset_2017_2.tar.bz2,https://ember.elastic.co/ember_dataset_2017_2.tar.bz2, | | 2017 | 2               | ember_dataset_2017_2.tar.bz2 | , | 
8781,https://ember.elastic.co/ember_dataset_2018_2.tar.bz2,https://ember.elastic.co/ember_dataset_2018_2.tar.bz2, | | 2018 | 2               | ember_dataset_2018_2.tar.bz2 | , | 
8809,http://pr.cs.cornell.edu/grasping/rect_data/data.php,Cornell Grasping Dataset,"Currently, both the ", and 
8809,http://pr.cs.cornell.edu/grasping/rect_data/data.php,Cornell Grasping Dataset,Download the and extract ,.
8820,#how-can-i-use-my-own-dataset,How can I use my own dataset?,"
","
"
8823,https://www.tensorflow.org/datasets/catalog/scientific_papers,Tensorflow Datasets,The dataset is also available on , which makes it easy to use within Tensorflow or colab.
8842,https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data,"MNIST dataset provided by tensorflow
"," dataframes. The typical pattern is as follows (for loading, e.g., the ",", as already done in "
8842,deepconcolic/datasets.py,"
deepconcolic.datasets
",", as already done in ",):
8842,dc_plugins/toy_datasets/random.py,an example dataset plugin,"For further illustrative purposes, we provide ",", which can be used to randomly generate classification tasks. This plugin registers several datasets (named, e.g., "
8847,#configuring-datasets,Configuring Datasets,"
","
"
8847,#adding-a-dataset,Adding a Dataset,"
","
"
8847,#adding-a-dataset,Adding a Dataset,Methods to import and configure datasets correctly can be found in the section ,.
8874,http://www.phontron.com/data/qi18naacl-dataset.tar.gz,qi18naacl-dataset.tar.gz,Datasets for the specific language pairs used in the experiments mentioned in this paper: ,.
8911,https://web.eecs.umich.edu/~lahiri/gutenberg_dataset.html,Project Guttenberg Dataset, no longer have it available for public download. The , is a somewhat smaller (200M word) collection of older books that are public domain.
8920,https://www.twentybn.com/datasets/something-something,jester dataset,Download the , or 
8920,http://www.cbsr.ia.ac.cn/users/jwan/database/isogd.html,ChaLearn LAP IsoGD dataset, or ,. Decompress them into the same folder and use 
8920,process_dataset.py,process_dataset.py,. Decompress them into the same folder and use ," to generate the index files for train, val, and test split. Poperly set up the train, validatin, and category meta files in "
8920,datasets_video.py,datasets_video.py," to generate the index files for train, val, and test split. Poperly set up the train, validatin, and category meta files in ",". Finally, use directory "
8920,https://github.com/metalbubble/TRN-pytorch/blob/master/process_dataset.py,process_dataset.py,", from which we imported ", to our project.
8932,https://github.com/huggingface/datasets,"
datasets
", integrates with , to manage task data
8944,#22-analysis-of-the-data-set,2.2 Analysis of the Data Set,"
","
"
8944,#31-preparing-the-data-set-for-machine-learning,3.1 Preparing the Data Set for Machine Learning,"
","
"
8944,#314-data-set-creation-for-shapes-study,3.1.4 Data Set Creation for Shapes study,"
","
"
8980,src/dataset.py,"
src/dataset.py
", function in ,.
8998,http://mscoco.org/dataset/#download,COCO dataset,Please download , and annotations for the 5k image 
9093,get_dataset_from_youtube.py,get_dataset_from_youtube.py,"
"," Directy download from youtube the videos and audio files of youtube audioset. Inside the script you will note the following hardcoded files : 2000max_subset_unbalanced_train_segments.csv, subset_eval_segments.csv,etc... This csv files are derived from the audioset "
9142,https://jiji.cat/weasel2018/data.csv,reformatted version of the Assistments 2009 dataset,Our ,.
9142,https://jiji.cat/weasel2018/data.csv,Assistments 2009 dataset,You can also download the , into 
9148,#datasets,Datasets,"
","
"
9148,#adding-a-dataset,Adding a dataset,"
","
"
9175,data/README.md,"instructions on how to process standard datasets like PTB, CTB, and the SMPRL 2013/2014 Shared Task data","Prior to training the parser, you will first need to obtain appropriate training data. We provide ",". After following the instructions for the English WSJ data, you can use the following command to train an English parser using the default hyperparameters:"
9204,https://github.com/udacity/self-driving-car/tree/master/datasets/CH2,Udacity dataset,"In order to learn steering angles, the publicly available ", has been used. It provides several hours of video recorded from a car. We additionally recorded an outdoor dataset to learn the probability of collision by riding a bicycle in the streets of our city.
9266,https://www.idiap.ch/dataset,EYEDIAP dataset, scripts. The ," is required. If using another dataset, these scripts have to be changed accordingly. The scripts also load the 3D landmarks computed using "
9287,#datasets,Datasets,"
","
"
9294,http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html,Other datasets,"
","
"
9322,#prepare-datasets,Prepare datasets,"
","
"
9335,https://github.com/adalca/medical-datasets,a list of medical imaging datasets here,We encourage users to download and process their own data. See ,". Note that you likely do not need to perform all of the preprocessing steps, and indeed VoxelMorph has been used in other work with other data."
9392,https://snap.stanford.edu/data/index.html,SNAP dataset collection,Graphs from the , are commonly used for graph algorithm benchmarks. We provide a tool that converts the most common SNAP graph format to the adjacency graph format that GBBS accepts. Usage example:
9422,https://github.com/EagleW/ACL_titles_abstracts_dataset,ACL_titles_abstracts_dataset,"
","
"
9450,#train-on-custom-dataset,Train on Custom Dataset,"
","
"
9454,http://www.cs.ubc.ca/~mbrown/patchdata/patchdata.html,Phototour Patch dataset,This repository contains reference source code for evaluating MatchNet models on ,.
9588,http://cocodataset.org/#download,official COCO dataset website,Please follow the , to download the dataset. After downloading the dataset you should have the following directory structure:
9614,#the-raw-moderated-dataset,The raw moderated dataset,"
","
"
9614,#preprocessed-dataset,Preprocessed dataset,"
","
"
9614,#projects-using-the-dataset,Projects using the dataset,"
","
"
9614,https://cloud.google.com/storage/docs/access-public-data,accessing public datasets,", or read more about "," using other methods. As an example, to easily download all simplified drawings, one way is to run the command "
9680,www.newsreader-project.eu/results/data/the-ecb-corpus/,dataset,The ECB+ ,"
"
9839,http://gvv.mpi-inf.mpg.de/3dhp-dataset/,the original MPI-INF-3DHP dataset,Download ,.
9840,./data/downloadDataset.md,downloadDataset,Refer to , for data download instructions
9849,https://github.com/adaa-polsl/GuideR/tree/master/datasets,datasets,"For convenience, we provide "," invesitgated in the GuideR paper, together with the corresponding "
9913,dataset/entity_typing,dataset/entity_typing,The dataset used in this experiment is contained in the , directory.
9927,https://sigsep.github.io/datasets/musdb.html,full MUSDB18 dataset,Download the ," and extract it into a folder of your choice. It should have two subfolders: ""test"" and ""train"" as well as a README.md file."
9943,http://cocodataset.org/#home,MS COCO Dataset,"
","
"
9945,./download_dataset.sh,download_dataset.sh,see , for more datasets
9967,http://www.cs.cmu.edu/~glai1/data/race/,RACE: Large-scale ReAding Comprehension Dataset From Examinations,"
","
"
9983,#dataset-information,Dataset information,"
","
"
10030,/datasets,datasets,Benchmark problems for various solvers above can be found in ,.
10041,https://github.com/apmoore1/Bella/blob/master/notebooks/datasets.ipynb,dataset notebook, to state where the datasets are stored like we did but this is not a requirement as you can state where they are stored explictly in the code. For more details on the datasets and downloading them see the , The datasets used:
10041,http://alt.qcri.org/semeval2014/task4/index.php?id=data-and-tools,SemEval 2014 Resturant dataset,"
",. We used Train dataset version 2 and the test dataset of which the gold standatd test can be found 
10041,http://alt.qcri.org/semeval2014/task4/index.php?id=data-and-tools,SemEval 2014 Laptop dataset,"
",. We used Train dataset version2 and the test dataset of which the gold standard test can be found 
10041,https://figshare.com/articles/EACL_2017_-_Multi-target_UK_election_Twitter_sentiment_corpus/4479563/1,Election dataset,"
","
"
10041,https://github.com/bluemonk482/tdparse/tree/master/data/lidong,Twitter dataset,"
","
"
10059,http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset,http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset,Download GTSRB from , and get the training 'Images and annotations' (
10106,#datasets,Datasets,"
","
"
10106,http://www.uco.es/grupos/ayrna/ucobigfiles/datasets-orreview.zip,datasets," folder includes different configuration files for running all the algorithms. In order to use these files, the ", used in the previously cited review paper are needed. To add your own method see 
10106,http://www.uco.es/grupos/ayrna/ucobigfiles/datasets-orreview.zip,datasets-OR-review, folder includes partitions of several small ordinal datasets for code testing purposes. We have also collected 44 publicly available ordinal datasets from various sources. These can be downloaded from: ,. The link also contains data partitions as used in different papers in the literature to ease experimental comparison. The characteristics of these datasets are the following:
10130,http://www.caida.org/data/ixps/,IXPs Dataset,"
",", in particular the "
10168,http://personal.ie.cuhk.edu.hk/~ccloy/downloads_mall_dataset.html,Mall dataset,"
","
"
10168,https://engineering.purdue.edu/~sorghum/dataset-plant-centers-2016,Plant dataset,"
","
"
10229,./data/,datasets,These are improved forms of prior datasets and a new dataset we developed. We have separate files describing the ,", "
10257,http://www.cs.sfu.ca/~colour/data/shi_gehler/,Gehler-Shi dataset,The ColorChecker RECommended dataset is an updated version of the original ,", which re-generates a new ""recommended"" ground-truth set. See "
10298,https://github.com/FerranAlet/modular-metalearning/blob/master/create_functions_datasets.py,create_functions_datasets,First you have to generate the datasets using  ,. For instance to create the functions dataset:
10320,https://github.com/RAMitchell/ml_dataset_loader/tree/ac520d8c34d1d3bd68819e49dffd97f4a3f671c6,ml_dataset_loader,Datasets are loaded using ,. Datasets are automatically downloaded and cached over subsequent runs. Allow time for these downloads on the first run.
10389,https://lcas.lincoln.ac.uk/wp/research/data-sets-software/l-cas-3d-point-cloud-people-dataset/,https://lcas.lincoln.ac.uk/wp/research/data-sets-software/l-cas-3d-point-cloud-people-dataset/,Dataset: ,"
"
10399,multi_categorical_gans/datasets,Datasets,"
","
"
10478,https://data.vision.ee.ethz.ch/cvl/DIV2K/,DIV2K dataset,Download DIV2K training data (800 training + 100 validtion images) from , or 
10546,http://ai.stanford.edu/~jkrause/cars/car_dataset.html,http://ai.stanford.edu/~jkrause/cars/car_dataset.html,Cars-196: ,"
"
10550,http://cocodataset.org,COCO Dataset,We have tested our method on ,"
"
10700,https://www.robots.ox.ac.uk/~vgg/data/vgg_face2/,VGGFace2 dataset,These models were trained on a training set from , using Softmax loss
10701,https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/,the IMDB-WIKI dataset,"This is a Keras implementation of a CNN for estimating age and gender from a face image [1, 2]. In training, ", is used.
10701,check_dataset.ipynb,check_dataset.ipynb, file. Please check , for the details of the dataset. The training data is created by:
10701,https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/,the IMDB-WIKI dataset,"This project is released under the MIT license. However, ", used in this project is originally provided under the following conditions.
10702,recognition/_datasets_,dataset,"The training data includes, but not limited to the cleaned MS1M, VGG2 and CASIA-Webface datasets, which were already packed in MXNet binary format. Please ", page for detail.
10742,http://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/iden_split.txt,dataset split, dataset and lists of , and 
10750,readme/dataset.md,Dataset,"
","
"
10750,readme/dataset.md,Dataset Page,The dataset for the visual mesh is provided via TFRecord files. The keys that are used in the TFRecord files are determined by the flavour that is used. See the , for more information.
10808,https://vision.cs.tum.edu/data/datasets/mono-dataset,dataset, provided by the ,.
10851,https://data.bris.ac.uk/data/dataset/dobuvuu00mh51q773bo8ybkdz,Historical Newspapers Yearly N-grams and Entities Dataset,"
",": Yearly time series for the usage of the 1,000,000 most frequent 1-, 2-, and 3-grams from a subset of the British Newspaper Archive corpus, along with yearly time series for the 100,000 most frequent named entities linked to Wikipedia and a list of all articles and newspapers contained in the dataset (3.1 GB)"
10851,https://datadryad.org/resource/doi:10.5061/dryad.nh775,Historical Newspapers Daily Word Time Series Dataset,"
",": Time series of daily word usage for the 25,000 most frequent words in 87 years of UK and US historical newspapers between 1836 and 1922. (2.7GB)"
10851,https://github.com/caesar0301/awesome-public-datasets#natural-language,Awesome public datasets/NLP,"
", (includes more lists)
10851,http://aws.amazon.com/de/datasets/,AWS Public Datasets,"
","
"
10851,https://www.reddit.com/r/datasets,/r/datasets,"
"," (endless list of datasets, most is scraped by amateurs though and not properly documented or licensed)"
10851,https://www.kaggle.com/gentrexha/kosovo-news-articles-dataset,Albanian News Articles Dataset,"
",": Over 3 million Albanian news articles alongwith metadata, extracted from various albanian news sources (see list in link)."
10874,#datasetconstruction,Creation of a dataset of Kotlin applications,"
","
"
10874,https://androidtimemachine.github.io/dataset,dataset," applications and it has been executed in October 2017. As their infrastructure is publicly available,", and 
10877,https://www.tensorflow.org/guide/datasets,Datasets, and ,.
10877,http://reclab.idi.ntnu.no/dataset,SmartMedia Adressa dataset,"
"," - This dataset contains approximately 20 million page visits from a Norwegian news portal [91]. In our experiments we used 16 days of the full dataset, which is available upon request, and includes article text and click events of about 2 million users and 13,000 articles."
10877,http://reclab.idi.ntnu.no/dataset,Adressa dataset,The creators of the ," can make available the full textual content of articles upon request. After download their data, you must follow this steps:"
10928,http://jmcauley.ucsd.edu/data/amazon/,amazon-review dataset," language model for unsupervised modeling of large text datasets, such as the ",", is implemented in PyTorch. We also support other tokenization methods, such as character or sentencepiece tokenization, and language models using various recurrent architectures."
10928,http://jmcauley.ucsd.edu/data/amazon/,amazon review dataset,This project uses the , collected by J. McAuley
10958,#datasets,Datasets,"
","
"
10966,#dataset,Dataset,"
","
"
11048,https://archive.ics.uci.edu/ml/datasets/covertype,Covertype dataset,To distributedly train a multi-class logistic regression classifier on the ," as in the paper,  run the following command first"
11077,https://github.com/MKLab-ITI/image-verification-corpus,VMU 2015 dataset,"For CCMR Twitter, each tweet is saved as a json object with keys ""tweet_id"", ""content"", ""image_id"", ""event"", and ""timestamp"". For CCMR Google and Baidu, each webpage is saved as a json object with keys ""url"", ""title"", ""image_id"", and ""event"". The values of ""image_id"" are lists of image or video names from ",". All of those image files and video URLs are available in ""images.zip""."
11109,https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones,dataset,The , can be found on the UCI Machine Learning Repository:
11112,#some-datasets,Some Datasets,"
","
"
11112,https://github.com/caesar0301/awesome-public-datasets,Awesome Public Datasets,"
", - An awesome list of public datasets.
11115,https://github.com/Pascalson/chatbot-data,"our dataset repository (OpenSubtitles, Counting)",The dataset can be downloaded from ,". Feel free to cope with any dataset you prepare, but please make sure the format is consistent with our assigned format."
11116,https://ltnas1.informatik.uni-hamburg.de:8081/owncloud/index.php/s/lhcJQNxaGBLjL8o?path=%2Fdatasets,datasets,"
","
"
11171,#process-of-imagenet-dataset,Process of ImageNet dataset,"
","
"
11174,http://visionandlanguage.net/VIST/dataset.html,visual storytelling dataset,"
","
"
11174,https://github.com/google-research-datasets/sentence-compression/tree/master/data,compression dataset,"
","
"
11225,https://cmu-perceptual-computing-lab.github.io/foot_keypoint_dataset/,"
OpenPose foot dataset
","
","
"
11241,http://data.csail.mit.edu/places/places365/val_256.tar,raw dataset,Download the , from the Places365 website to 
11270,https://github.com/artetxem/vecmap/blob/master/get_data.sh,VecMap dataset,These embeddings have been trained jointly using en-XX bilingual dictionaries and embeddings from the ,.
11288,datasets/README.md,datasets/README.md, folder. Follow the specific instructions provided in: ,"
"
11293,video_prediction/datasets/kth_dataset.py,"
kth_dataset.py
","To use a different dataset, preprocess it into TFRecords files and define a class for it. See ", for an example where the original dataset is given as videos.
11305,make_dataset.py,make_dataset.py,", which can use tagging datasets created using the ", script. Note that 
11331,http://www.robots.ox.ac.uk/~vgg/data/parisbuildings/,The Paris Dataset,. You can also use , to train your model
11432,https://github.com/xinntao/BasicSR#datasets,BasicSR-Datasets,HR images can be downloaed from ,.
11473,#download-dataset,Download Dataset,"
","
"
11485,http://ai.stanford.edu/~amaas/data/sentiment/,Large movie review dataset,The dataset construction is based on the method noted in ," from Maas et al., 2011."
11519,https://www.robots.ox.ac.uk/~vgg/data/dtd/,Describable Textures Dataset, and ,.
11519,https://www.robots.ox.ac.uk/~vgg/data/dtd/,Describable Textures Dataset, and ,.
11562,datasets.py,"
datasets.py
", | string | yes | | The type of the dataset to be used corresponding to one of the classes defined in ,", but without the "
11570,#dataset--preparation,Dataset Preparation,"
","
"
11594,./modules/datasets/,"
datasets
","
", : Provides dataset parsing and evaluation utilities with precaching and async processing support.
11638,#datasets,Datasets,"
","
"
11848,https://www.cityscapes-dataset.com/,Cityscapes dataset,"For better adaptation to real world images, we have used the ",.
11878,data/corpora_processed/train_processed_dialogs.txt,dummy train dataset,"The training data should be a txt file, where each line is a valid json object, representing a list of dialog utterances. Refer to our ", to see the necessary file structure. Replace this dummy corpus with your data before training.
11894,utils/datasetcollections.py,dataset collections,This runs all experiments included in the results section of our paper. It is up to the user to download the datasets and link to them in the , file. The output folders including the folder where the data will be stored (in this case 
11948,https://download.visinf.tu-darmstadt.de/data/from_games/,The GTA5 Dataset,Download ,"
"
11948,http://synthia-dataset.net/download-2/,The SYNTHIA Dataset,Download ,"
"
11948,https://www.cityscapes-dataset.com/,The Cityscapes Dataset,Download ,"
"
11961,#24-supported-datasets,Supported datasets,"
","
"
11961,datasets/,"
datasets
",Own dataset interfaces can be defined by creating a new module in the ," package, defining a class derived from "
11961,datasets/common.py,"
FileDatasetGenerator
"," package, defining a class derived from ",", importing it in "
11961,datasets/__init__.py,"
datasets/__init__.py
",", importing it in ",", and adding a branch for it in the "
11962,http://www.cvlibs.net/datasets/kitti/eval_odometry.php,http://www.cvlibs.net/datasets/kitti/eval_odometry.php,See https://github.com/JakobEngel/dso for how to run on a dataset. Run on a dataset from , using:
11991,#datasets,Datasets,"
","
"
12056,http://robotcar-dataset.robots.ox.ac.uk/datasets/,Oxford Robotcar dataset, and , to evaluate the robustness of our method.
12078,https://www.tensorflow.org/datasets,TensorFlow Datasets,Compare GAN uses , and it will automatically download and prepare the data. For ImageNet you will need to download the archive yourself. For CelebAHq you need to download and prepare the images on your own. If you are using TPUs make sure to point the training script to your Google Storage Bucket (
12166,https://www.biometricupdate.com/202007/facial-biometrics-training-dataset-leads-to-bipa-lawsuits-against-amazon-alphabet-and-microsoft,"Jul 2020 - Facial biometrics training dataset leads to BIPA lawsuits against Amazon, Alphabet and Microsoft","
","
"
12166,https://venturebeat.com/2021/05/06/deepfake-detectors-and-datasets-exhibit-racial-and-gender-bias-usc-study-shows/,"May 2021 - Deepfake detectors and datasets exhibit racial and gender bias, USC study shows","
","
"
12184,http://lmb.informatik.uni-freiburg.de/resources/datasets/FlyingChairs.en.html,the flying chair dataset,"The code provides a training example, using "," , with data augmentation. An implementation for "
12184,http://lmb.informatik.uni-freiburg.de/resources/datasets/SceneFlowDatasets.en.html,Scene Flow Datasets," , with data augmentation. An implementation for ", may be added in the future.
12184,http://lmb.informatik.uni-freiburg.de/resources/datasets/FlyingChairs.en.html,the flying chair dataset,"First, you need to download the ", . It is ~64GB big and we recommend you put it in a SSD Drive.
12185,http://www.cvlibs.net/datasets/kitti/eval_odometry.php,Odometry dataset,Pose evaluation is also available on ,. Be sure to download both color images and pose !
12241,https://www.tensorflow.org/datasets,TensorFlow Datasets,"Alternatively, you can access the DeepWeeds dataset with ",", TensorFlow's official collection of ready-to-use datasets. "
12247,https://github.com/m4nh/cables_dataset,Cable Dataset,Check also for , ...
12293,datasets/mnist.yaml,"
datasets/mnist.yaml
"," for an example of a neural network model description, "," of the MNIST dataset, and "
12333,http://www.vision.ee.ethz.ch/en/datasets/,ETH Dataset," ETH or UCY datasets, you can find them here: ", and 
12333,https://graphics.cs.ucy.ac.cy/research/downloads/crowd-data,UCY Dataset, and ,.
12388,https://github.com/huggingface/datasets,HuggingFace datasets library,You can also access this dataset as part of the , library as follow:
12453,http://www.cvlibs.net/datasets/kitti/eval_object.php,Kitti Object Detection Dataset,KittiBox is a collection of scripts to train out model FastBox on the ,. A detailed description of Fastbox can be found in our 
12516,https://magenta.tensorflow.org/datasets/nsynth,NSynth dataset,SING is a deep learning based music notes synthetizer that can be trained on the ,". Despite being 32 times faster to train and 2,500 faster for inference, SING produces audio with significantly improved perceptual quality compared to the NSynth wavenet-like autoencoder "
12567,https://catalog.ldc.upenn.edu/docs/LDC93S4B/corpus.html,ATIS (Airline Travel Information Systems) dataset,There is example code available using Magnitude to build an intent classification model for the , (
12568,https://rare-technologies.com/new-download-api-for-pretrained-nlp-models-and-datasets-in-gensim/,New Download API for Pretrained NLP Models and Datasets,Read more about the project rationale and design decisions in this article: ,.
12590,#dataset,Dataset,"
","
"
12590,#download-dataset,Download dataset,"
","
"
12590,https://motchallenge.net/data/MOT17.zip,mot 17 dataset 5.5 GB,Download the , and 
12628,https://sites.google.com/view/calgary-campinas-dataset/home,Calgary-Campinas dataset,The MR raw-data is publicly available as part of the , for benhcmarking purposes.
12694,https://github.com/SullyChen/driving-datasets,dataset,Download the , and extract into the repository folder
12713,#ecpe-2d-on-reccon-dataset,ECPE-2D on RECCON dataset,"
","
"
12713,#rank-emotion-cause-on-reccon-dataset,Rank-Emotion-Cause on RECCON dataset,"
","
"
12713,#ecpe-mll-on-reccon-dataset,ECPE-MLL on RECCON dataset,"
","
"
12713,#roberta-and-spanbert-baselines-on-reccon-dataset,RoBERTa and SpanBERT Baselines on RECCON dataset,"
","
"
12745,http://lcl.uniroma1.it/wsdeval/data/WSD_Unified_Evaluation_Datasets.zip,http://lcl.uniroma1.it/wsdeval/data/WSD_Unified_Evaluation_Datasets.zip,"'s versions of SensEval/SemEval corpora (6 separate corpora, original data: ",)
12745,https://github.com/google-research-datasets/word_sense_disambigation_corpora,https://github.com/google-research-datasets/word_sense_disambigation_corpora,MASC (original data: ,)
12800,#the-nyu-depth-v2-dataset,The NYU-Depth-v2 dataset,"
","
"
12837,https://github.com/udacity/self-driving-car/tree/master/datasets,"
Driving Datasets
","
"," – Over 10 hours of driving data (LIDAR, camera frames and more)"
12843,https://www.cs.toronto.edu/~vmnih/data/,Massachusetts road & building dataset,This is a state-of-the-art project for building extraction in high resolution remote sensing image using dataset ," . And, our approach was published in ACCV 2016, clik here to download "
12850,https://github.com/alabatie/moments-dnns/blob/master/notebooks/Complements%20on%20width%2C%20boundary%20conditions%2C%20dataset%2C%20epsilon.ipynb,"Complements on width, boundary conditions, dataset, epsilon.ipynb","
"," discusses the effect of changing the width, boundary conditions of convolutional layers, input dataset and batch normalization fuzz factor"
12887,http://www.m-ailabs.bayern/en/the-mailabs-speech-dataset/,new M-AILABS speech dataset,We are also running current tests on the , which contains more than 700h of speech (more than 80 Gb of data) for more than 10 languages.
13003,#datasets,datasets,. Check the , section for details.
13006,#define-a-customized-dataset,Define a customized dataset,"
","
"
13006,#define-a-customized-dataset,Define a customized dataset,"
", at 
13006,#define-a-customized-dataset,Define a customized dataset,"
", at 
13007,#define-a-customized-dataset,Define a customized dataset,"
","
"
13096,https://github.com/mshaikh2/HDL_Forensics/tree/master/BMVC_XAI/dataset,dataset,Please try out our , to try your algorithms and kindly cite the below research papers:
13106,pytracking/evaluation/avistdataset.py,avistdataset.py,", the integration ", and the evaluation code 
13147,ops/dataset_configs.py,ops/dataset_configs.py,Add the information to ,"
"
13256,http://pan.webis.de/data.html,datasets can be found there,. A number of ,", and all of them are formatted as follows."
13261,https://www.kaggle.com/google/google-landmarks-dataset,Google-Landmarks-Dataset,We have additionally trained a ResNet-50 model not documented in the original paper. By refined from a base model trained on ,", it achieves better performance than GoogleNet on object retrieval datasets (Oxford5K and Paris6K)."
13274,https://ailb-web.ing.unimore.it/publicfiles/drive/show-control-and-tell/dataset_coco.tgz,dataset_coco.tgz,Download the annotations and metadata file , (~85.6 MB) and extract it in the code folder using 
13274,https://ailb-web.ing.unimore.it/publicfiles/drive/show-control-and-tell/dataset_flickr.tgz,dataset_flickr.tgz,"As before, download the annotations and metadata file ", (~32.8 MB) and extract it in the code folder using 
13276,https://ailb-web.ing.unimore.it/publicfiles/drive/CVPR%202019%20-%20Art2Real/datasets/monet2photo.zip,[Dataset],"
","
"
13276,https://ailb-web.ing.unimore.it/publicfiles/drive/CVPR%202019%20-%20Art2Real/datasets/landscape2photo.zip,[Dataset],"
","
"
13276,https://ailb-web.ing.unimore.it/publicfiles/drive/CVPR%202019%20-%20Art2Real/datasets/portrait2photo.zip,[Dataset],"
","
"
13321,https://www.cityscapes-dataset.com/anonymous-results/?id=b2cc8f49fc3267c73e6bb686425016cb152c8bc34fc09ac207c81749f329dc8d,https://www.cityscapes-dataset.com/anonymous-results/?id=b2cc8f49fc3267c73e6bb686425016cb152c8bc34fc09ac207c81749f329dc8d,ShelfNet18-lw real-time: ,"
"
13321,https://www.cityscapes-dataset.com/anonymous-results/?id=c0a7c8a4b64a880a715632c6a28b116d239096b63b5d14f5042c8b3280a7169d,https://www.cityscapes-dataset.com/anonymous-results/?id=c0a7c8a4b64a880a715632c6a28b116d239096b63b5d14f5042c8b3280a7169d, ShelfNet34-lw non real-time: ,"
"
13349,http://www.cvlibs.net/datasets/kitti/eval_semantics.php,KITTI Semantic Dataset, Bayesian SegNet trained on the ,; these weights were first trained using the 
13349,https://www.cityscapes-dataset.com,Cityscapes Dataset,; these weights were first trained using the ,", and were then fine tuned. All weights have the batch normalization layer merged with the preceding convolutional layer in order to speed up inference."
13349,http://www.cvlibs.net/datasets/kitti/eval_odometry.php,KITTI dataset, cameras that computes the camera trajectory and a sparse 3D reconstruction (in the stereo and RGB-D case with true scale). It is able to detect loops and relocalize the camera in real time. We provide examples to run the SLAM system in the ," as stereo or monocular, in the "
13349,http://vision.in.tum.de/data/datasets/rgbd-dataset,TUM dataset," as stereo or monocular, in the "," as RGB-D or monocular, and in the "
13349,http://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets,EuRoC dataset," as RGB-D or monocular, and in the "," as stereo or monocular. ORB_SLAM2 also contains a ROS node to process live monocular, stereo or RGB-D streams. "
13368,https://www.kaggle.com/c/painter-by-numbers/data,Kaggle's painter-by-numbers dataset, from ,; extract the content (paintings) into this new directory: 
13368,https://github.com/bethgelab/stylize-datasets,https://github.com/bethgelab/stylize-datasets,"This repository is tailored to creating a stylized version of ImageNet. Should you be interested in stylizing a different dataset, I recommend using this code: ", which stylizes arbitrary image datasets.
13386,https://media.githubusercontent.com/media/molecularsets/moses/master/data/dataset_v1.csv,a benchmarking dataset,We propose , refined from the ZINC database.
13390,https://www.ipf.kit.edu/lafida_datasets.php,Lafida dataset, to utilize the large FoV of the fisheye camera without introducing the distortion. The system is able to compute the camera trajectory and recover a sparse structure of the environment. It is also able to detect loops and relocalize the camera in real time. We provide examples on the ," and the self-collected data sequences. Like ORB-SLAM, we also provide a GUI to change between a "
13434,https://github.com/Spirals-Team/npe-dataset,NPE-dataset, on the dataset ,.
13494,https://github.com/facebookresearch/clevr-dataset-gen,CLEVR dataset,This is a repository modified from the , for generating realistic visualizations of 
13505,http://www.eecs.qmul.ac.uk/~kz303/vsumm-reinforce/datasets.tar.gz,http://www.eecs.qmul.ac.uk/~kz303/vsumm-reinforce/datasets.tar.gz,Original version of the datasets can be downloaded from , or 
13531,#datasets,Datasets,"
","
"
13546,https://www.prhlt.upv.es/contests/icfhr2016-kws/data.html,botany or konzilsprotokolle datasets,For the , run
13596,doc/datasets.md,dataset documentation,Refer to our , for an overview of the supported datasets and their expected directory structure.
13596,doc/datasets.md,dataset documentation,Download the datasets as indicated in the ,". SfM models of Aachen, RobotCar, CMU, and Extended CMU, built SuperPoint and usable with HF-Net, are provided "
13617,slowfast/datasets/DATASET.md,DATASET.md,. You may follow the instructions in , to prepare the datasets.
13635,https://sites.google.com/site/yangdingqi/home/foursquare-dataset,Global-Scale Check-in Dataset,", in the same format of the ",", and the previously mentioned "
13678,https://github.com/NVlabs/ffhq-dataset,Flickr-Faces-HQ dataset, | Raw data for the ,. | └  
13678,./dataset_tool.py,dataset_tool.py,"To obtain other datasets, including LSUN, please consult their corresponding project pages. The datasets can be converted to multi-resolution TFRecords using the provided ",:
13777,#dataset,dataset,"
","
"
13818,https://github.com/ultralytics/yolov5/tree/master/data,datasets, and , download automatically from the latest YOLOv3 
13836,#how-to-fine-tune-one-of-the-trained-models-on-your-own-dataset,How to fine-tune one of the trained models on your own dataset,"
","
"
13837,https://github.com/michalfaber/rmpe_dataset_server,rmpe_dataset_server,Download and compile the dataset server ,. This server generates augmented samples on the fly. Source samples are retrieved from previously generated hdf5 dataset file.
13903,dataset,dataset directory,Various file format for learning with IUST-DeepFuzz and then fuzz testing is available at ,.
13926,https://github.com/vendi12/ODExploration_data,Open Data Exploration dataset,"
", for the conversational browsing task contains 26 transcripts annotated with dialog acts and entity spans. 
13929,https://github.com/JTrippas/Spoken-Conversational-Search/blob/master/SCSdataset.csv,(SCSdataset.csv), and ,"
"
13937,https://github.com/huggingface/datasets,"
datasets
", integrates with , to manage task data
13969,http://people.ee.ethz.ch/~ihnatova/#dataset,DPED dataset,Download , (patches for CNN training) and extract it into 
14098,http://ferandrade.com/blog/2015/07/interactive-segmentation-dataset.html,Novel Dataset for Interactive Segmentation Evaluation,"
","
"
14103,https://www.dropbox.com/s/2fdn26rj6h9bpvl/ubuntu_data.zip?dl=0,Ubuntu dataset,Download the ," released by (Xu et al, 2017)"
14118,docs/en/1_exist_data_model.md,with existing dataset,"
","
"
14118,docs/en/2_new_data_model.md,with new dataset,"
","
"
14118,docs/en/3_exist_data_new_model.md,with existing dataset_new_model,"
","
"
14118,docs/en/tutorials/customize_dataset.md,customize_datasets,"
","
"
14163,http://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets,EuRoC MAV Dataset,Download ," to YOUR_DATASET_FOLDER. Take MH_01 for example, you can run VINS-Fusion with three sensor types (monocular camera + IMU, stereo cameras + IMU and stereo cameras). Open four terminals, run vins odometry, visual loop closure(optional), rviz and play the bag file respectively. Green path is VIO odometry; red path is odometry under visual loop closure."
14163,http://www.cvlibs.net/datasets/kitti/eval_odometry.php,KITTI Odometry dataset,Download ," to YOUR_DATASET_FOLDER. Take sequences 00 for example, Open two terminals, run vins and rviz respectively. (We evaluated odometry on KITTI benchmark without loop closure funtion)"
14163,http://www.cvlibs.net/datasets/kitti/raw_data.php,KITTI raw dataset,Download , to YOUR_DATASET_FOLDER. Take 
14389,https://crowdai-prd.s3.eu-central-1.amazonaws.com/dataset_files/challenge_50/7dcfad42-65c6-4481-abe8-5a44339fa305_Dataset%20Description.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAILFF3ZEGG7Y4HXEQ%2F20210916%2Feu-central-1%2Fs3%2Faws4_request&X-Amz-Date=20210916T141008Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=79e00ec4fc5a8d083aa77a3da93694d86525b8c9904e9850f9cb1b36b8a9c212,Dataset Description,"
","
"
14428,#builddata,Building datasets, 2.2. , 2.3. 
14462,https://www.floydhub.com/redeipirati/datasets/pytorch-mnist,uploaded it as FloydHub dataset," dataset for you, moreover I have already ", so that you can try and familiarize with 
14476,https://github.com/harvardnlp/boxscore-data,Data-to-Text Datasets,This dataset is derived from one of the , (RotoWire) proposed in the paper 
14478,#set-up-the-classification-datasets,Set up the classification datasets,"
","
"
14546,https://webscope.sandbox.yahoo.com/catalog.php?datatype=a,Webscope: Datasets, folder. The dataset is available at ,.
14605,./dataset_builder.py,dataset_builder.py,The dataset splits are built once for all using the ," script and then pickled for fast subsequent runs. JRC-Acquis is automatically donwloaded the first time. RCV1/RCV2, despite being public, cannot be downloaded without a formal permission. Please, refer to "
14650,http://mlg.ucd.ie/datasets/bbc.html,BBC Datasets Descrition,"
","
"
14650,http://mlg.ucd.ie/files/datasets/bbc-fulltext.zip,Dataset,"
","
"
14654,#datasets,Datasets,"
","
"
14705,https://github.com/fjxmlzn/RNN-SM#steganalysis-speech-dataset,dataset,[,]
14833,https://www.kaggle.com/crawford/cat-dataset,Cat-Dataset,: Download and preprocesses the ,"
"
14833,https://neerajkumar.org/databases/lfpw/,LFPW Dataset,: Preprocesses an already downloaded ZIP file of the , (Download is recommended from 
14846,https://elki-project.github.io/datasets/,DataSets,", ",", "
14850,https://vision.in.tum.de/mono-dataset,https://vision.in.tum.de/mono-dataset,TUM-Mono: ,"
"
14850,https://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets,Euroc MAV dataset,EuRoC: ,"
"
14851,http://www.cvlibs.net/datasets/kitti/eval_odometry.php,KITTI dataset, cameras that computes the camera trajectory and a sparse 3D reconstruction (in the stereo and RGB-D case with true scale). It is able to detect loops and relocalize the camera in real time. We provide examples to run the SLAM system in the ," as stereo or monocular, in the "
14851,http://vision.in.tum.de/data/datasets/rgbd-dataset,TUM dataset," as stereo or monocular, in the "," as RGB-D or monocular, and in the "
14851,http://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets,EuRoC dataset," as RGB-D or monocular, and in the "," as stereo or monocular. We also provide a ROS node to process live monocular, stereo or RGB-D streams. "
14899,http://www.cs.sfu.ca/~colour/data/shi_gehler/,Shi's Re-processing of Gehler's Raw Dataset,"
","
"
14899,http://www.cs.sfu.ca/~colour/data/shi_gehler/,"
Shi's Re-processing of Gehler's Raw Dataset:","
","
"
14922,https://www.uni-ulm.de/en/in/driveu/projects/dense-datasets,DENSE dataset webpage,Download the Gated2Depth dataset and the models from the ,". Please download the zip files of the synthetic and real dataset, and the models into separate folders."
14933,https://smoosavi.org/datasets/lstw,Large-Scale Traffic and Weather Events Dataset,": The first step is to extract traffic and weather events/entities from the raw traffic and weather data, and create a dataset such as ",. In 
14947,www.cvlibs.net/datasets/kitti/,Kitti dataset,The ," has been used. First download the dataset of the depth completion. Secondly, you'll need to unzip and download the camera images from kitti. I used the file "
14951,multigrain/datasets/retrieval.py,datasets/retrieval.py," is in progress, but one may already use the dataloaders implemented in ", for this purpose.
15030,https://www.tensorflow.org/datasets/catalog/ag_news_subset,tensorflow-datasets,"
", is used to support AG's News dataset.
15063,http://ais.informatik.uni-freiburg.de/projects/datasets/fr360/,Freiburg Campus 360 dataset, from the ,", each point has (x,y,z) "
15084,https://etsin.avointiede.fi/dataset/urn-nbn-fi-csc-kata20170601153214969115,FI-2010 dataset,. The dataset was based on the ,.
15090,https://zdzhaoyong.github.io/GSLAM/dataset.html,Dataset Plugin for GSLAM,"
","
"
15090,https://zdzhaoyong.github.io/GSLAM/dataset.html,implement dataset plugins by own,Users can also ,.
15115,#dataset,Dataset,"
","
"
15223,http://www.cvlibs.net/datasets/kitti/raw_data.php,KITTI raw dataset,You need to download ," first, then the raw data is processed with the following three steps:"
15270,https://github.com/golsun/SpaceFusion/blob/master/data/toy,toy dataset, datasets as well as a , in this repo for debugging.
15328,https://github.com/WangXuhongCN/adVAE/tree/master/datasets,"""datasets""",. These datasets are also included in file folder ,.
15334,#dataset-description,Dataset Description,"
","
"
15347,http://archive.ics.uci.edu/ml/datasets/Student+Performance,Student Performance Dataset,Code for preprocessing the , can be found in 
15350,datasets,datasets,The datasets can be found in the folder ,". Like in the original word2vec-toolkit, the files to be evaluated are named "
15350,datasets,datasets,"If you want to extend or modify the test data, edit the respective source files in the folder ",: 
15350,datasets,datasets,Adding new datasets and models: add the raw dataset into ,", generate the "
15364,datasets,datasets,The datasets can be found in the folder ,". Like in the original word2vec-toolkit, the files to be evaluated are named "
15364,datasets,datasets,"If you want to extend or modify the test data, edit the respective source files in the folder ",: 
15364,datasets,datasets,Adding new datasets and models: add the raw dataset into ,", generate the "
15398,charades_dataset.py,charades_dataset.py,This relied on having the optical flow and RGB frames extracted and saved as images on dist. , contains our code to load video segments for training.
15398,charades_dataset_full.py,charades_dataset_full.py, contains the code to load a pre-trained I3D model and extract the features and save the features as numpy arrays. The , script loads an entire video to extract per-segment features.
15403,https://datasets.d2.mpi-inf.mpg.de/andriluka14cvpr/mpii_human_pose_v1.tar.gz,MPII Human Pose Dataset,"If you would like to pretrain an EpipolarPose model on MPII data, please download image files from ", (12.9 GB). Extract it under 
15420,datasets,datasets,The datasets can be found in the folder ,". Like in the original word2vec-toolkit, the files to be evaluated are named "
15420,datasets,datasets,"If you want to extend or modify the test data, edit the respective source files in the folder ",: 
15420,datasets,datasets,Adding new datasets and models: add the raw dataset into ,", generate the "
15435,https://github.com/Braamling/contextual-search-features-for-large-datasets-in-spark,contextual-search-features-for-large-datasets-in-spark,"
", contains all the neccary Scala Spark code to generate the contextual features in VITOR from the raw ClueWeb12 dataset. The resulting data will be in the same format as the LETOR dataset.
15487,https://lmb.informatik.uni-freiburg.de/resources/datasets/SceneFlowDatasets.en.html,Scene Flow Datasets,Download ,", "
15557,data/AerialImageDataset,Inria Aerial Image Dataset,"
","
"
15557,data/bradbury_buildings_roads_height_dataset,"Aerial imagery object identification dataset for building and road detection, and building height estimation","
","
"
15557,data/mapping_challenge_dataset,Mapping Challenge from CrowdAI Dataset,"
","
"
15557,projects/mapalign/dataset_utils,dataset_utils,All scripts for dataset handling relative to the alignment project are located in the , folder. See the README in that folder for instructions on dataset pre-processing.
15560,http://asrl.utias.utoronto.ca/datasets/mrclam/,http://asrl.utias.utoronto.ca/datasets/mrclam/,You can dowload data at , and then extract data in the folder 
15579,http://www.caida.org/data/passive/passive_2016_dataset.xml,http://www.caida.org/data/passive/passive_2016_dataset.xml,CAIDA-2016 - ,"
"
15579,http://www.caida.org/data/passive/ddos-20070804_dataset.xml,http://www.caida.org/data/passive/ddos-20070804_dataset.xml,CAIDA-DDoS - ,"
"
15598,/data/construct_dataset_Market.m,/data/construct_dataset_Market.m,Then run ," in MATLAB. If you prefer to use another dataset, just modify the MATLAB code accordingly. The processed Market-1501 and DukeMTMC-reID are available in "
15598,/data/construct_dataset_MSMT17.m,/data/construct_dataset_MSMT17.m,Then run ," in MATLAB. If you prefer to use another dataset, just modify the MATLAB code accordingly. Again, the processed MSMT17 is available in "
15600,https://github.com/tensorflow/datasets,TensorFlow Datasets,: Observations is in the process of being replaced by ,". Unlike Observations, TensorFlow Datasets is more performant, provides pipelining for >2GB data sets and all of "
15714,https://sites.google.com/view/reside-dehaze-datasets/reside-standard?authuser=0,RESIDE dataset,"
", (
15737,#data-sets,Data Sets, data set in [1] stored using Python pickle module. See , for more details.
15759,http://snap.stanford.edu/data/index.html,SNAP dataset," folder of the project, taken from the ",.
15768,https://github.com/uclmr/jack/tree/master/data/sentihood,dataset mirror," has failed, we use the ", listed in 
15793,https://download.visinf.tu-darmstadt.de/data/from_games/,GTA5 Dataset,Download the , as the source domain and unzip it to  
15793,https://www.cityscapes-dataset.com,Cityscapes Dataset,Download the , as the target domain and unzip it to  
15825,https://github.com/felipelouza/bwsd/blob/master/dataset/input.100.txt,dataset/input.100.txt,To run a test with d=10 strings from , using Alg. 1 
15852,https://github.com/awesomedata/awesome-public-datasets#readme,Public Datasets,"
","
"
15852,https://github.com/leomaurodesenv/game-datasets#readme,Game Datasets,"
", - Materials and datasets for Artificial Intelligence in games.
15852,https://github.com/jdorfman/awesome-json-datasets#readme,Datasets,"
","
"
15864,https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator,Dataset,", ",", "
15884,https://kaggle.com/bryanpark/korean-single-speaker-speech-dataset,KSS Dataset, 4. ,"
"
15922,#dataset,Dataset,"
","
"
15923,#dataset,Dataset,"
","
"
15975,https://sir2data.github.io/,SIR^2 dataset,"Three sub-datasets, namely ‘Objects’, ‘Postcard’, ‘Wild’ from ","
"
15978,https://box.vicos.si/skokec/villard/detectron-model-yaml-DFG-dataset.zip,detectron-model-yaml-DFG-dataset.zip,"
","
"
15978,https://box.vicos.si/skokec/villard/detectron-model-yaml-DFG-dataset-augmented.zip,detectron-model-yaml-DFG-dataset-augmented.zip,"
","
"
16026,http://weegee.vision.ucmerced.edu/datasets/landuse.html,"
UC Merced Data Set
",In our paper we have experimented with two remote sensing benchmark archives - , (UCMD) and 
16027,https://github.com/tttthomasssss/iwcs2019/tree/master/datasets,datasets,All datasets are in the , folder of this repository.
16027,https://github.com/tttthomasssss/iwcs2019/blob/master/datasets/aux_verb_agreement.txt,dataset,The , is tab separated and contains correct (e.g. 
16027,https://github.com/tttthomasssss/iwcs2019/blob/master/datasets/translation_operation.txt,dataset,The ," is tab separated and contains the auxiliary, the corresponding inflected verb and the infinitive form of a verb. The goal is to learn a translation operation from infinitive forms to inflected forms (or contextualised forms if the tense uses auxiliaries). Evaluation has been done using Mean Reciprocal Rank (MRR) - see our "
16070,data/feature-vis/dataset-p/,"
data/feature-vis/dataset-p/
","
",: positive dataset examples for each channel
16085,https://github.com/sshan-zhao/GASDA/tree/master/datasets,datasets,Prepare the two datasets according to the datalists (*.txt in ,)
16192,#get-the-filtered-raw-kp20k-training-dataset,Get the filtered raw KP20k training dataset,"
","
"
16237,https://ai.googleblog.com/2017/08/launching-speech-commands-dataset.html,Google Speech Commands Dataset,For evaluating the proposed and the baseline models we use ,.
16237,https://github.com/hyperconnect/TC-ResNet/tree/master/speech_commands_dataset,speech_commands_dataset/,Follow instructions in ,"
"
16270,https://bingyaohuang.github.io/pub/CompenNeSt++/photometric_cmp_data,benchmark dataset,Download CompenNet , and extract to 
16403,https://github.com/shaohua0116/Multiview2Novelview#datasets,datasets,". We provide codes, ",", and "
16415,https://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets,EuRoC dataset,DSM is a novel approach to monocular SLAM. It is a fully direct system that estimates the camera trajectory and a consistent global map. Is is able to detect and handle map point reobservations when revisiting already mapped areas using the same photometric model and map points. We provide examples to run the SLAM system in the , and with custom videos. We also provide an optional GUI for 3D visualization of the system results.
16415,https://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets,https://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets,Download a sequence (ASL format) from ,.
16448,https://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets,ETHZ EuroC Dataset,"
","
"
16448,https://vision.in.tum.de/data/datasets/visual-inertial-dataset,TUM Visual Inertial Dataset,"
","
"
16477,http://www.rdfhdt.org/datasets,http://www.rdfhdt.org/datasets,. (This dataset has been downloaded from , and extracted using the HDT [2] software at 
16510,documentation/dataset_format.md,Dataset conversion,"
","
"
16516,https://github.com/tom-pelsmaeker/deep-generative-lm/tree/master/dataset,dataset,"
",: expected location of data. Contains code for preprocessing and batching PTB.
16566,./doc/new_dataset_guide.md,New Dataset,"
",: Instructions to train KPConv networks on your own data.
16582,http://www.cvlibs.net/datasets/kitti/raw_data.php,KITTI's dataset,"This version of the app assumes the LiDAR data to be stored in a binary float matrix (.bin extension). Each column is a point, where the rows are in the following order: x, y, z, and intensity (little endian). See the 3D Velodyne point clouds in ", for example.
16609,https://github.com/openai/gpt-2-output-dataset,released a dataset,We have also , for researchers to study their behaviors.
16612,www.mathieuramona.com/wp/data/jamendo/,Jamendo dataset by Mathieu Ramona,The experiments use the public ,". To download and prepare it, open the cloned or extracted repository in a bash terminal and execute the following scripts (in this order):"
16675,https://download.visinf.tu-darmstadt.de/data/from_games/,GTA5 Dataset,Download the , as source dataset
16675,https://www.cityscapes-dataset.com/,Cityscapes Dataset,Download the , as target dataset
16681,/datasets/data.md,datasets/data.md,Please see , for detail.
16733,/dataset,dataset,"
","
"
16741,https://github.com/StanfordVL/taskonomy/tree/master/data,dataset,"
","
"
16741,https://github.com/StanfordVL/taskonomy/tree/master/data,DATASET, | , | |:-----|:-----| | The 
16741,https://docs.omnidata.vision/starter_dataset_download.html#Examples,instructions for how to download the full dataset," folder contains information and statistics about the dataset, some sample data, and ",. | | 
16791,http://www.fki.inf.unibe.ch/databases/iam-handwriting-database,IAMDB dataset,IMDBLabelGeneration: to generate the target labels required for evaluation by extending the ,"
"
16798,http://www.msmarco.org/dataset.aspx,MS MARCO re-ranking dataset,Get the , & clone this repository
16806,https://github.com/ashafahi/free_adv_train/tree/master/datasets,Datasets section,"To prepare the data, please see ",.
16826,https://github.com/abhipec/HAnDS/tree/master/datasets,"Datasets (Wiki-FbF, Wiki-FbT and 1k-WFB-g) along with the preprocessed Wikipedia and Freebase.","
","
"
16891,https://deepmind.com/research/open-source/open-source-datasets/kinetics/,Kinetics dataset,"
","
"
16905,https://github.com/gidariss/wDAE_GNN_FewShot/blob/master/low_shot_learning/datasets/imagenet_dataset.py#L19,imagenet_dataset.py, Download the ImageNet dataset and set in , the path to where the dataset resides in your machine.
16959,https://raw.githubusercontent.com/ocatak/malware_api_class/master/sample_analysis_data.csv,Sample dataset,"
","
"
16961,http://www.ipb.uni-bonn.de/data/rgbd-dynamic-dataset/,Bonn RGB-D Dynamic Dataset," scenes. To test it, please use our ","
"
16989,https://deepmind.com/research/open-source/open-source-datasets/,data sets,", ",", and "
16992,#datasets,Datasets,"
","
"
16992,https://www.center-tbi.eu/data,Center TBI dataset,"
","
"
16992,https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html,Boston Housing Dataset,"
","
"
16992,https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html,Boston Housing dataset,A script which trains and evaluates all models on the , can be found 
16998,http://cocodataset.org/#download,COCO dataset,"If you'd like to train LightTrack, download the ", and the 
17159,https://github.com/fastnlp/nlp-dataset/raw/master/text%20classification/mtl16.zip,dataset:mtk16,] [,]
17159,https://github.com/fastnlp/nlp-dataset/raw/master/text%20style%20transfer/imdb.zip,dataset:imdb,][,]
17190,#datasets,Datasets,"
","
"
17224,https://dl.dropboxusercontent.com/s/7qjye3efr0czux8/dataset_pose.zip,training dataset, that I used and the generated , (1427 images already split into training and validation).
17228,./Part_0_Prepare_dataset_Magnatagatune.ipynb,Jupyter Notebook - Part_0_Prepare_dataset_Magnatagatune,(,)
17228,https://www.audiocontentanalysis.org/data-sets/,List of Datasets,"
", by Alexander Lerch
17331,http://cocodataset.org/#download,COCO 2014 dataset,Download ,"
"
17381,#43-computing-dataset-statistics,Computing Dataset Statistics,      4.3 ,"
"
17394,http://www.cs.tut.fi/sgn/arg/dcase2016/task-sound-event-detection-in-synthetic-audio#audio-dataset,isolated sound events dataset from DCASE 2016 task 2," provides four-channel directional microphone recordings from a tetrahedral array configuration. Both formats are extracted from the same microphone array, and additional information on the spatial characteristics of each format can be found below. The participants can choose one of the two, or both the datasets based on the audio format they prefer. Both the datasets, consists of a development and evaluation set. The development set consists of 400, one minute long recordings sampled at 48000 Hz, divided into four cross-validation splits of 100 recordings each. The evaluation set consists of 100, one-minute recordings. These recordings were synthesized using spatial room impulse response (IRs) collected from five indoor locations, at 504 unique combinations of azimuth-elevation-distance. Furthermore, in order to synthesize the recordings the collected IRs were convolved with ",". Finally, to create a realistic sound scene recording, natural ambient noise collected in the IR recording locations was added to the synthesized recordings such that the average SNR of the sound events was 30 dB."
17429,http://www.cvlibs.net/datasets/kitti/raw_data.php,KITTI Dataset,Download the raw data of ,. This dataset is for training and eigen split evaluation.
17429,http://www.cvlibs.net/datasets/kitti/eval_scene_flow.php,KITTI 2015 scene flow dataset,Download , and save it in KITTI_PATH. This dataset is for optical flow and kitti split evaluation.
17437,https://github.com/deepmind/dsprites-dataset,https://github.com/deepmind/dsprites-dataset,Download from ,"
"
17445,http://www.cvlibs.net/datasets/kitti/eval_odometry.php,KITTI Odometry dataset,Download , to YOUR_DATASET_FOLDER and set the 
17487,./scripts/datasets,GluonNLP Datasets,"To facilitate both the engineers and researchers, we provide command-line-toolkits for downloading and processing the NLP datasets. For more details, you may refer to ", and 
17508,#extend-to-other-tasks-and-datasets,Extend to other tasks and datasets,"If you want to use your own datasets, please follow the guidance of next section ",.
17583,https://surprise.readthedocs.io/en/stable/getting_started.html#load-a-custom-dataset,Dataset handling,Alleviate the pain of ,. Users can use both 
17595,#dataset-preparation,Dataset Preparation,"
","
"
17595,dataset_preparation/,"
dataset_preparation/
","You need to extract frame-level features for each video to run the codes. To extract features, please check ",.
17595,dataset_preparation/,"
dataset_preparation/
","To generate the file list, please check ",.
17628,#datasets-instructions,Datasets instructions,"
","
"
17661,https://huggingface.co/datasets/imagenet_sketch,dataset,Hugging Face ,"
"
17669,https://www.robots.ox.ac.uk/~vgg/data/flowers/,Oxford Flowers dataset,", and the ",", move into "
17708,https://www.tensorflow.org/datasets/,TensorFlow Datasets API,We utilize the ,. Running any of our code that requires data will automatically download the requisite data.
17727,http://convai.io/#personachat-convai2-dataset,http://convai.io/#personachat-convai2-dataset,. More details about this dataset can be found at the ConvAI2 homepage at ,.
17762,https://sigsep.github.io/datasets/musdb.html,MUSDB18 dataset,"For audio source separation experiments, you will need to download the ", from 
17773,https://vision.in.tum.de/mono-dataset,https://vision.in.tum.de/mono-dataset,Get some datasets from , .
17773,https://vision.in.tum.de/mono-dataset,https://vision.in.tum.de/mono-dataset,Run on a dataset from , using
17773,https://vision.in.tum.de/mono-dataset,https://vision.in.tum.de/mono-dataset,The format assumed is that of ,". However, it should be easy to adapt it to your needs, if required. The binary is run with:"
17773,https://github.com/tum-vision/mono_dataset_code,https://github.com/tum-vision/mono_dataset_code,Use a photometric calibration (e.g. using , ).
17818,http://cocodataset.org/#home,COCO dataset,", for the purpose of providing the image pairs, i.e., the person image and its texture image. The texture image stores the RGB texture of the full person 3D surface. In particular, we use 929 raster-scanned texture maps provided by the SURREAL dataset to generate the image pairs. On SURREAL, all faces in the texture image are replaced by an average face of either man or woman. We generate 9,290 different meshes of diverse poses/shapes/viewpoints. For each texture map, we assign 10 different meshes and render these 3D meshes with the texture image. Then we obtain in total 9,290 different synthesized (person image, texture image) pairs. To simulate real-world scenes, the background images for rendering are randomly sampled from ",. Each synthetic person image is centered on a person with resolution 256x128. The resolution of the texture images is 256x256. The PIT dataset can be downloaded from 
17818,torchreid/datasets/__init__.py,torchreid/datasets/__init__.py, dataset as an example for description. See , for details. The data managers of image reID are implemented in 
17837,https://storage.cloud.google.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz,Speech Commands dataset,"In the experiments of this work, we use the "," (2.3GB), which is publically accessible. You don't need to download it if you want to train the target model from scratch because the training code will automatically download it."
17848,https://github.com/warnikchow/3i4k/blob/master/data/fci.txt,dataset, or the ,", cite the following:"
17885,https://datasets.d2.mpi-inf.mpg.de/rakshith/a4nt_usenix/dataset/dataset_speech.json,Political speech dataset,"
","
"
17885,https://datasets.d2.mpi-inf.mpg.de/rakshith/a4nt_usenix/dataset/dataset_blog.json,Blog dataset for age and gender,"
","
"
17963,test_dataset,"
test_dataset
",". CBLasso takes a long time to run, therefore, the result of running CBLasso on ", is precomputed and provided in 
17963,test_dataset/cblasso_results,"
test_dataset/cblasso_results
", is precomputed and provided in ,. Performance of CBLasso is obtained with 
17963,`generate_dataset.py`,"
generate_dataset.py
","
", provides the code to generate data. An example usage is shown below:
17963,test_dataset,"
test_dataset
",The particular instance of test data used in the original paper is available in the ,.
18030,https://archive.ics.uci.edu/ml/datasets/Epileptic+Seizure+Recognition,Epileptic  Seizure  Recognition  Dataset (2001),"
",". Real Multivariate Time Series dataset contains 11,500 instances and 179 attributes."
18058,https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/summarization/multi_news.py,"

Tensorflow datasets

","
","
"
18081,https://github.com/lijuncen/Sentiment-and-Style-Transfer/tree/master/data/yelp,Yelp dataset,Download the pre-processed datasets from , and 
18081,https://github.com/lijuncen/Sentiment-and-Style-Transfer/tree/master/data/amazon,Amazon dataset, and ,", which include"
18145,dataset,dataset,The , folder contains the 
18156,https://www.tensorflow.org/datasets/catalog/overview#all_datasets,available datasets,List of all ,"
"
18156,https://github.com/tensorflow/datasets/issues/new?assignees=&labels=dataset+request&template=dataset-request.md&title=%5Bdata+request%5D+%3Cdataset+name%3E,Dataset request GitHub issue,Request a dataset by opening a ,.
18189,#datasets,Datasets,"
","
"
18189,https://www.ims.uni-stuttgart.de/data/durel,Dataset,| Dataset | Language | Corpus 1 | Corpus 2 | Download | Comment | | --- | --- | --- | --- | --- | --- | | DURel | German | DTA18 | DTA19  | ,", "
18189,https://www.ims.uni-stuttgart.de/data/surel,Dataset, | | SURel | German | SDEWAC | COOK | ,", "
18189,https://www.ims.uni-stuttgart.de/data/lsc-simul,Dataset, | | SemCor LSC | English | SEMCOR1 | SEMCOR2 | ,", "
18189,https://www.ims.uni-stuttgart.de/data/sem-eval-ulscd,Dataset, | | | SemEval Eng | English | CCOHA 1810-1860 | CCOHA 1960-2010 | ,", "
18189,https://www.ims.uni-stuttgart.de/data/sem-eval-ulscd,Dataset, | | | SemEval Ger | German | DTA 1800-1899 | BZND 1946-1990 | ,", "
18189,https://www.ims.uni-stuttgart.de/data/sem-eval-ulscd,Dataset, | | | SemEval Lat | Latin | LatinISE -200-0 | LatinISE 0-2000 | ,", "
18189,https://www.ims.uni-stuttgart.de/data/sem-eval-ulscd,Dataset, | | | SemEval Swe | Swedish | Kubhist2 1790-1830 | Kubhist2 1895-1903 | ,", "
18189,https://github.com/diacr-ita/data/tree/master/test,Dataset, | | | DIACR-Ita | Italian | Unità 1945-1970 | Unità 1990-2014 | ,", "
18244,https://github.com/yyaghoobzadeh/WIKI-PSE/tree/master/dataset,dataset,"(For only the (word, semantic-classes) datasets, please visit this directory: ",.)
18412,data/README.md,Datasets,"
","
"
18412,dataset_creation/README.md,Tools for Creating our datasets,"
","
"
18442,https://github.com/oscartackstrom/sentence-sentiment-data,Täckström Dataset,", ",", "
18456,https://github.com/Tessil/hat-trie#wikipedia-dataset,Wikipedia dataset,The benchmark protocol is the same as for the ,.
18457,https://www.kaggle.com/jessicali9530/celeba-dataset,https://www.kaggle.com/jessicali9530/celeba-dataset, from ," (or other source), and put it in "
18457,https://github.com/deepmind/dsprites-dataset,https://github.com/deepmind/dsprites-dataset, from , and put it in the 
18461,http://vhosts.eecs.umich.edu/vision//activity-dataset.html,collective activity dataset,To evaluate on of the ," (without any training) we selected 6 scenes that contain people talking to each other. This allows for a balanced dataset, but any other configuration will work."
18465,https://www.med.upenn.edu/sbia/brats2018/data.html,BraTS 2018 dataset,We trained with the ,", which is available from the organizers of the "
18473,#1-train-sDNet-from-scratch-on-sceneflow-dataset,1 Train SDNet from Scratch on SceneFlow Dataset,"
","
"
18473,#2-train-sdnet-on-kitti-dataset,2 Train SDNet on KITTI Dataset,"
","
"
18499,https://www.tensorflow.org/datasets/catalog/clic,CLIC dataset,", the ", will be downloaded using TensorFlow Datasets.
18517,#where-can-i-get-a-dataset-for-deep-xi,Where can I get a dataset for Deep Xi?,"
","
"
18517,https://ieee-dataport.org/open-access/deep-xi-dataset,Deep Xi dataset,Each available model is trained using the ,. Please see 
18517,https://ieee-dataport.org/open-access/deep-xi-dataset,Deep Xi dataset,Average objective scores obtained over the conditions in the test set of the ,. 
18609,./dataset_tool.py,dataset_tool.py,"To obtain other datasets, including LSUN, please consult their corresponding project pages. The datasets can be converted to multi-resolution TFRecords using the provided ",:
18657,https://github.com/deepmind/dsprites-dataset,dSprites dataset github repository,To run experiments with the dSprites dataset you will need to clone the , into 
18670,https://github.com/jorgegus/autotext_data,Datasets,Public data: ,"
"
18676,https://www.uni-ulm.de/en/in/driveu/projects/dense-datasets,DENSE dataset webpage,Download the benchmark data from the ,.
18682,#datasets,Datasets,"
","
"
18714,#dataset-format,Dataset Format,"
","
"
18730,https://github.com/fMoW/dataset,Functional Map of the World (fMoW) Dataset,This code is centered around the ,". The pre-processing and partitioning scripts assume that this dataset is being used, but most of the code is general, and can be adapted to other datasets."
18794,https://github.com/karoldvl/paper-2015-esc-dataset,ESC: Dataset for Environmental Sound Classification - paper replication data,"
","
"
18796,http://rpg.ifi.uzh.ch/davis_data.html,Event-Camera Dataset,To get a bag file from the ,:
18797,http://rpg.ifi.uzh.ch/davis_data.html,Event Camera Dataset,We provide a minimal example to process events from a plain text file. You can use the event text files from the the ,", e.g. "
18797,http://rpg.ifi.uzh.ch/davis_data.html,Event Camera Dataset,"Alternatively, you can also play a rosbag file. You can use rosbags from the from the the ",", e.g. "
18807,http://millionsongdataset.com/,Million Song Dataset,This repo contains code and information for singing-voice-based ,. It can be used for singing voice or singer relevant tasks.
18808,http://millionsongdataset.com/,Million Song Dataset, This is created from the , by running singing voice detection. MSD-singer repo is 
18824,#preprocessed-dataset,Preprocessed Dataset Section,Preprocessed dataset is available in the ,.
18894,http://www.cvl.isy.liu.se/en/research/datasets/swedish-leaf/,Swedish leaf dataset,", ", and 
18900,#download-pretrain-models-and-published-dataset,Download Pretrain Model and Dataset,step2: ,"
"
18925,https://archive.ics.uci.edu/ml/datasets/adult,Adult Census Dataset,In this example we load the ,* which is a built-in demo dataset. We use CTGAN to learn from the real data and then generate some synthetic data.
18926,https://docs.sdv.dev/sdgym/customization/datasets,Customized Datasets,"For more information, see the docs for ",.
18948,#datasets,event-time datasets,", and a collection of ",". In addition, some useful preprocessing tools are available in the "
18957,https://openml.github.io/automlbenchmark/benchmark_datasets.html,benchmarking datasets,Curated suites of , from 
19074,#dataset-download,Dataset Download,Follow the instructions from the simulator under ,", "
19074,#dataset-preprocessing,Dataset Preprocessing,", ", and 
19100,https://archive.ics.uci.edu/ml/datasets/iris,Iris dataset,We're using the ,", so let's load it and perform an 80/20 train/test split."
19104,dataset,dataset folder,See the , to create a dataset for analysis from the 
19104,analysis/dataset/export_full.csv.zip,dataset analysed in the paper, to replicate analytical results from the paper. The ," is provided, so that the two replication steps can be done independently."
19171,PQ/pq_data.tar.gz,Download tarball of PQ dataset,"
","
"
19171,RQ1/rq1_data.tar.gz,Download tarball of RQ1 dataset,"
","
"
19171,RQ2/rq2_data.tar.gz,Download tarball of RQ2 dataset,"
","
"
19186,#waymo-open-dataset-baselines,Waymo Open Dataset,Add performance of several models trained with full training set of ,.
19186,#waymo-open-dataset-baselines,Waymo Open Dataset,Add PointPillar related baseline configs/results on ,.
19186,#waymo-open-dataset-baselines,Waymo Open Dataset,Improve the performance of all models on ,. Note that you need to re-prepare the training/validation data and ground-truth database of Waymo Open Dataset (see 
19186,#waymo-open-dataset-baselines,Waymo Open Dataset,[2020-11-10] The , has been supported with state-of-the-art results. Currently we provide the configs and results of 
19193,#datasets,Datasets,"
","
"
19202,/nagisa/data/sample_datasets,sample datasets,. Note that you put EOS between sentences. Refer to , and 
19279,#2-dsprite-textures-dataset,dSprite-textures dataset,"
","
"
19279,https://www.robots.ox.ac.uk/~vgg/data/dtd/index.html,Describable Textures Dataset," dataset by adding texture patterns to all shapes. Additionally, we add labels for shape class, bounding box, and mask. Textures are cropped from images in the ",.
19279,https://github.com/deepmind/dsprites-dataset,dSprite dataset,This repository builds upon code from several projects and individuals: ," by Loic Matthey, Irina Higgins, Demis Hassabis, and Alexander Lerchner "
19279,https://www.robots.ox.ac.uk/~vgg/data/dtd/index.html,Describable Textures Dataset," by Loic Matthey, Irina Higgins, Demis Hassabis, and Alexander Lerchner "," by Mircea Cimpoi, Subhransu Maji, Iasonas Kokkinos, Sammy Mohamed, and Andrea Vedaldi "
19291,https://github.com/huggingface/datasets,datasets,": loads data from plaintext, tsv, and huggingface's ","
"
19324,https://pytorch.org/docs/stable/torchvision/datasets.html,torchvision.datasets,"The dataset for the ""polyphonic music modeling"" experiment is already included in audio/data/. For other experiments that are based on much larger datasets, the data needs to be downloaded (from ", or 
19400,#SIP-dataset,SIP dataset,"
","
"
19423,https://figshare.com/articles/PHEME_dataset_for_Rumour_Detection_and_Veracity_Classification/6392078,PHEME 6392078 dataset,Augmented Raw data is based on ,. We have two versions of augmented rumor corpus.
19455,qa+adapter/re-organize_dataset/mix_dataset.py,mix_dataset.py, and the script for re-organize this dataset is ,.
19467,https://www.kaggle.com/c/painter-by-numbers/data,Kaggle's painter-by-numbers dataset,Get style images: Download train.zip from ,"
"
19554,#data-set-up,Data set-up,"
","
"
19554,#data-set-up,Data Set-up,"Download the audio files (i.e. the Audio 1/5, Audio 2/5, ..., Audio 5/5), do your feature extraction and follow the instructions at the ", section.
19554,#data-set-up,Data Set-up,"Download the audio files, do your feature extraction and follow the instructions at the ", section.
19554,#data-set-up,Data Set-up,"Download the audio files, do your feature extraction and follow the instructions at the ", section.
19568,http://www-rech.telecom-lille.fr/DHGdataset/,DHG-14/28 Dataset,"We propose a Dynamic Graph-Based Spatial-Temporal Attention (DG-STA) method for hand gesture recognition. The key idea is to first construct a fully-connected graph from a hand skeleton, where the node features and edges are then automatically learned via a self-attention mechanism that performs in both spatial and temporal domains. The code of training our approach for skeleton-based hand gesture recognition on the ", and the 
19568,http://www-rech.telecom-lille.fr/DHGdataset/,DHG-14/28 Dataset,Download the , or the 
19570,#datasets,datasets,"
","
"
19590,https://github.com/openai/gpt-2-output-dataset,released a dataset,We have also , for researchers to study their behaviors.
19604,https://github.com/faisal-iut/linkPrediction/tree/master/dataset,Dataset,"
","
"
19604,https://github.com/faisal-iut/linkPrediction/blob/master/dataset/apnea-all%2C3.csv,Apnea dataset,"
", - All keywords are atleast 3-degree keywords
19604,https://github.com/faisal-iut/linkPrediction/blob/master/dataset/obesity-all%2C3.csv,Obesity dataset,"
", - All keywords are atleast 3-degree keywords
19641,https://github.com/iremeyiokur/multipie_ear_dataset,Multi-PIE ear dataset,This dataset is the extended version of , [3].
19670,http://data.csail.mit.edu/tofu/dataset/vimeo_triplet.zip,vimeo triplet dataset,Download Vimeo90k training data from ,.
19683,#datasets,Datasets,"
","
"
19696,#datasets,Datasets,"
","
"
19696,./download-glas-dataset.sh,./download-glas-dataset.sh,GlaS: ,.
19696,./download-caltech-ucsd-birds-200-2011-dataset.sh,./download-caltech-ucsd-birds-200-2011-dataset.sh,Caltech-UCSD Birds-200-2011:  ,"
"
19696,./download-Oxford-flowers-102-dataset.sh,./download-Oxford-flowers-102-dataset.sh,Oxford flower 102: ,"
"
19743,http://www.sociopatterns.org/datasets/hypertext-2009-dynamic-contact-network/,'Hypertext 2009'-dataset,In order to download the SocioPatterns ," and visualize it interactively, do the following."
19756,https://github.com/paulcon/as-data-sets,Active Subspaces Data Sets,"To see active subspace in action on real science and engineering applications, see the "," repository, which contains several Jupyter notebooks applying the methods to study input/output relationships in complex models."
19865,https://github.com/googlecreativelab/quickdraw-dataset/blob/master/README.md#numpy-bitmaps-npy,https://github.com/googlecreativelab/quickdraw-dataset/blob/master/README.md#numpy-bitmaps-npy,"
","
"
19870,https://tianchi.aliyun.com/dataset/dataDetail?dataId=52,https://tianchi.aliyun.com/dataset/dataDetail?dataId=52,Taobao: ," the released dataset is been changed a litte by Alibaba. If you want the totally same dataset as the paper used, you can click "
19898,https://structured3d-dataset.org/,Structured3D dataset,2019.08.19: Report results on ,. (See 
19901,https://github.com/ssarfraz/SPL/tree/master/FCC_dataset,FCC_Dataset, | Contains the proposed loss formulation for both Tensorflow and Pytorch | ├ , | Contains scripts for recreating the FCC dataset and data preparations for training/testing | ├ 
19913,https://cran.r-project.org/package=cluster.datasets,cluster.datasets,. The real-world datasets are from R ’s , package.
19935,../../wiki/1-Batch-interface#13-dataset-definition,Dataset definition,"
","
"
19941,http://www.viratdata.org/,VIRAT Ground Dataset Release2.0,"To extract features from scratch, ", and 
19970,https://github.com/jfzhang95/pytorch-video-recognition/blob/master/dataloaders/dataset.py,dataset.py,"These models were trained in machine with NVIDIA TITAN X 12gb GPU. Note that I splited train/val/test data for each dataset using sklearn. If you want to train models using official train/val/test data, you can look in ",", and modify it to your needs."
20016,documentation/dataset_format.md,Dataset conversion,"
","
"
20024,https://github.com/godka/comyco-video-description-dataset,Video Description Dataset,"
","
"
20104,#51-gan-tree-for-single-channel-dataset,GAN Tree for Single Channel Dataset,"
","
"
20104,#52-gan-tree-for-single-channel-mixed-dataset,GAN Tree for Single Channel Mixed Dataset,"
","
"
20104,#53-gan-tree-for-multiple-channel-mixed-dataset,GAN Tree for Multiple Channel Mixed Dataset,"
","
"
20104,#61-generated-gan-tree-for-single-channel-mixed-dataset,Generated GAN Tree for Single Channel Mixed Dataset,"
","
"
20104,#62-generated-gan-tree-for-multiple-channel-mixed-dataset,Generated GAN Tree for Multiple Channel Mixed Dataset,"
","
"
20115,https://pan.baidu.com/s/1usnQtW-YodlPUQ1TNrrafw#list/path=%2Fdataset%2Fkg4rs,https://pan.baidu.com/s/1usnQtW-YodlPUQ1TNrrafw#list/path=%2Fdataset%2Fkg4rs,Step 1. Download the data from , or 
20136,https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning/blob/master/datasets.py,"
datasets.py
", in ,.
20136,https://pytorch.org/docs/master/data.html#torch.utils.data.Dataset,"
Dataset
",This is a subclass of PyTorch ,. It needs a 
20169,#suggested-datasets,Suggested Datasets,"
","
"
20241,https://ieee-dataport.org/open-access/file-fragment-type-fft-75-dataset],FFT-75 dataset,You need to download the ,.
20250,docs/datasets.md,Datasets,"
","
"
20251,https://bingyaohuang.github.io/pub/CompenNeSt++/full_cmp_data,benchmark dataset (~11G), and CompenNet++ ,.
20251,https://bingyaohuang.github.io/pub/CompenNeSt++/full_cmp_data,benchmark dataset (~11G),Download CompenNet++ , and extract to 
20258,../master/datasets,datasets,We provide the dirty and the clean version of a number of ,.
20309,https://github.com/IdeasLabUT/CHIP-Network-Model/tree/master/storage/datasets,storage/datasets,All datasets used in this repo are either available in the , directory or will be automatically downloaded by the preprocessing script.
20329,https://cirl.lcsr.jhu.edu/research/hmm/datasets/jigsaws_release/,JIGSAWS dataset,You will need the , to re-run the experiments of the paper.
20380,https://github.com/tsunghan-wu/Depth-Completion/blob/master/doc/data.md,dataset section,. Detailed instructions for downloading the dataset are described in the ,"
"
20391,http://www.qizhexie.com/data/RACE_leaderboard.html,RACE Reading Comprehension Dataset Leaderboard,"
","
"
20391,#datasets,Datasets,"
","
"
20391,http://www.cs.cmu.edu/~glai1/data/race/,RACE dataset,The following script finetunes the BERT model for evaluation on the ,. The 
20443,https://colab.research.google.com/github/google/jax/blob/main/docs/notebooks/neural_network_with_tfds_data.ipynb,"Training a Simple Neural Network, with TensorFlow Dataset Data Loading","
","
"
20530,https://github.com/kristenvaccaro/fashion-data,[dataset],"
","
"
20560,http://www.cvlibs.net/datasets/kitti/eval_tracking.php,KITTI Tracking dataset,The experiments were done on ,.
20561,http://www.cvlibs.net/datasets/kitti/raw_data.php,raw KITTI dataset,You can download the entire , by running:
20561,http://www.cvlibs.net/datasets/kitti/eval_odometry.php,KITTI odometry dataset,"For this evaluation, the ","
"
20579,https://www.eecs.yorku.ca/~kamel/sidd/dataset.php,SIDD Medium Dataset,The real-world VDN denoiser was trained on the ,", and directly tested on the SIDD and DND benchmarks."
20622,https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs,Quora Question Pairs dataset," corpus, first download the original ", and save the tsv file to some location 
20655,https://www.fc.up.pt/addi/ph2%20database.html,Skin Lesion Segmentation PH2 Dataset,", ", and 
20663,#datasets,Datasets,"
","
"
20747,https://github.com/huggingface/datasets,datasets, : RONEC v2 is available on HuggingFace's ," library. To use, simply "
20776,https://github.com/golsun/StyleFusion/tree/master/data/toy,toy dataset,A , is provied as an example following the format described above.
20788,http://www.research.ibm.com/haifa/dept/vst/debating_data.shtml,IBM Claim Stance Dataset, model and was fine-tuned on the ,. The model files are hosted on 
20788,http://www.research.ibm.com/haifa/dept/vst/debating_data.shtml,IBM Claim Stance Dataset,| Domain | Application | Industry  | Framework | Training Data | Input Data | | --------- | --------  | -------- | --------- | --------- | --------------- | | Natural Language Processing (NLP) | Sentiment Analysis | General | TensorFlow | , | Text |
20788,http://www.research.ibm.com/haifa/dept/vst/debating_data.shtml#Project,IBM Claims Stance Dataset,"
", and 
20828,#datasets,Datasets,"
","
"
20829,#datasets,Datasets,"
","
"
20913,#download-datasets,Download Datasets,"
","
"
20922,#datasets,Datasets,"
","
"
20922,./download-glas-dataset.sh,./download-glas-dataset.sh,GlaS: ,.
20922,https://github.com/jeromerony/survey_wsl_histology/tree/init-branch/datasets-split,datasets-split,See ,.
20922,https://github.com/jeromerony/survey_wsl_histology/blob/init-branch/datasets-split/README.md,datasets-split/README.md,Detailed documentation: ,.
20942,#making-predictions-on-existing-datasets,Making predictions on existing datasets,"
","
"
20942,#working-with-new-datasets,Working with new datasets,"
","
"
20942,https://ai2-s2-mechanic.s3-us-west-2.amazonaws.com/data/data.zip,Download the dataset,"
","
"
20942,doc/data.md#formatting-a-new-dataset,Formatting a new dataset,Follow the instructions as described in ,.
20942,#making-predictions-on-existing-datasets,existing datasets,Make predictions the same way as with the ,:
20981,http://www.tmbdev.net/ocrdata-split/,UW3 dataset,) was trained on the , (link seems to be down)
21004,data/dataset_splits,dataset splits,A model has to be trained and evaluated using the four different ,". Afterwards, the resulting evaluation json files should be merged into a single json containing the results for all 24 held out concept pairs. The average recall@5 and some other statistics can be visualized using "
21007,https://github.com/mmalekzadeh/privacy-preserving-bandits/tree/master/experiments/Criteo/criteo_dataset,"
create_datasets.ipynb
",", for the first time, the script ", should be used. You should first set this parameter (number of rows) in the  
21007,https://github.com/mmalekzadeh/privacy-preserving-bandits/tree/master/experiments/Criteo/criteo_dataset,"
create_datasets.ipynb
",", build the dataset, and then run the Criteo experiment. Please see ", for more dtail.
21040,dataset_configurations/coil_training_dataset_singlecamera.py,dataset configuration file,The user can configure a ,". This file contains a set of start/end positions, weathers and number of dynamic objects to appear on every data collection episode. Further, the user also configure a "
21053,https://20bn.com/datasets/jester,jester dataset,Download the , or 
21053,https://20bn.com/datasets/something-something/v2,something-something-v2 dataset, or ,. Decompress them into the same folder and use 
21053,process_dataset.py,process_dataset.py,. Decompress them into the same folder and use ," to generate the index files for train, val, and test split. Poperly set up the train, validatin, and category meta files in "
21053,datasets_video.py,datasets_video.py," to generate the index files for train, val, and test split. Poperly set up the train, validatin, and category meta files in ",". To convert the something-something-v2 dataset, you can use the "
21096,#datasets,Datasets,"
","
"
21098,https://projects.asl.ethz.ch/datasets/doku.php?id=laserregistration:laserregistration,"
Challenging data sets for point cloud registration algorithms
",Download the ,. Extract the zip file of each sequence corresponding to the point clouds in base frame in the 
21180,https://github.com/jongpillee/music_dataset_split/tree/master/MSD_split,Million Song Dataset,) and  the , (
21214,http://cognimuse.cs.ntua.gr/database,extended Cognimuse dataset,We use the ,"
"
21296,https://github.com/Xiaoming-Yu/DMIT/blob/master/data/template_dataset.py,Dataset,You can implement your , and 
21297,http://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz,movie review dataset,Download the , and put 
21371,#dataset,Dataset,"
","
"
21378,http://buildingparser.stanford.edu/dataset.html,S3DIS dataset, Download the ,.
21427,https://data.vision.ee.ethz.ch/sagea/lld/#paper,LLD-logo dataset,For this paper we removed all text-based images from the , and extended the remaining logos with image based logos and illustrations scraped off of Google images.
21472,https://data.vision.ee.ethz.ch/cvl/DIV2K/,DIV2K dataset,Download DIV2K training data (800 training + 100 validtion images) from , and put in the file DIV2K.
21519,#datasets,Datasets,"
","
"
21519,#adding-new-datasets,Adding new datasets,"
","
"
21519,#adding-new-datasets,Adding new datasets, and , for information about reading and saving data in this format.
21530,https://www.nature.com/articles/sdata2018251#data-citations,VQA-RAD dataset, for close-end on ,". For the detail, please refer to "
21601,#datasets,Datasets,"
","
"
21651,https://download.visinf.tu-darmstadt.de/data/from_games/,"
GTA5 datasets
",Download ,", which contains 24,966 annotated images with 1914×1052 resolution taken from the GTA5 game. We use the sample code for reading the label maps and a split into training/validation/test set from "
21651,https://yihsinchen.github.io/segmentation_adaptation_dataset/,"
NTHU dataset
",Download ,", which consists of images with 2048 × 1024 resolution from four different cities: Rio, Rome, Tokyo, and Taipei. We resize images to 1024x512, the same as Cityscapes."
21726,https://github.com/jleuschn/dival/blob/master/dival/datasets/lodopab_dataset.py,lodopab_dataset, class defined in ,.
21801,https://github.com/TurkuNLP/hockey-text-generation-corpus,Data set of manually aligned game statistics and news text segments,"
","
"
21848,#configured-datasets,Datasets,"
","
"
21848,#add-a-dataset,Add a Dataset,"
","
"
21873,/dataset/office_real,/dataset/office_real,Sample training data can be found in the folders , and 
21873,/dataset/gazebo_sim,/dataset/gazebo_sim, and ,. The entire dataset can be downloaded by clicking the link here: 
21874,#datasets,Datasets,"
","
"
21874,#datasets,Datasets,"
","
"
21884,#knowledge-grounded-hate-countering-dataset,Knowledge-grounded hate countering dataset,                                      | Multilingual expert-based HS/CN pairs dataset on Islamophobia. | 2019         | https://aclanthology.org/P19-1271.pdf             | | , | HS/CN pairs with the background knowledge corresponding to the CN.     | 2021         | https://aclanthology.org/2021.findings-acl.79.pdf |
21964,https://sites.google.com/view/calgary-campinas-dataset/home,CC359 dataset, on the test set that is compound with a subset of entries from the ,", "
21972,#ecpe-2d-on-reccon-dataset,ECPE-2D on RECCON dataset,"
","
"
21972,#rank-emotion-cause-on-reccon-dataset,Rank-Emotion-Cause on RECCON dataset,"
","
"
21972,#ecpe-mll-on-reccon-dataset,ECPE-MLL on RECCON dataset,"
","
"
21972,#roberta-and-spanbert-baselines-on-reccon-dataset,RoBERTa and SpanBERT Baselines on RECCON dataset,"
","
"
21993,https://github.com/UFAL-DSG/cs_restaurant_dataset,https://github.com/UFAL-DSG/cs_restaurant_dataset,: ,"
"
22029,https://data.noaa.gov/dataset/dataset/global-surface-summary-of-the-day-gsod,GSOD dataset, shows how the system can be used to send a collection of small data and track lineage. It parses the dataset , downloaded using 
22047,https://www.cityscapes-dataset.com/,CityScapes Datasets,You can download ,.Put it in data folder.
22058,https://archive.ics.uci.edu/ml/datasets/Parking+Birmingham,Birmingham parking data set,"
","
"
22058,https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page,New York City (NYC) taxi data set,"
","
"
22058,https://github.com/xinychen/transdim/tree/master/datasets,../datasets/,"For example, if you want to view or use these data sets, please download them at the "," folder in advance, and then run the following codes in your Python console:"
22099,#running-on-new-datasets,Running on New Datasets,"
","
"
22108,https://huggingface.co/datasets/bookcorpus,a dataset class by huggingface/datasets,"
",: This internally accesses the file above (by Igor) but easy to use in some cases.
22120,http://data.statmt.org/bzhang/neurips19_rmsnorm/,dataset & training script & pretrained model,"To ease the training of RNNSearch, we also provide the used/preprocessed ",.
22124,http://dataset.cs.mcgill.ca/ubuntu-corpus-1.0/,Ubuntu Dialog Dataset,for ,"
"
22192,http://cocodataset.org/,COCO dataset,Where the object class comes from the , and are listed in the 
22192,https://vision.in.tum.de/data/datasets/rgbd-dataset/download,https://vision.in.tum.de/data/datasets/rgbd-dataset/download, sequence of the TUM-RGBD dataset here: ,"
"
22227,https://github.com/warnikchow/coaudiotext/blob/master/README.md#0-problem-definition--loading-dataset,0. Problem definition & loading dataset,"
","
"
22238,https://github.com/MikulasZelinka/textworld_kg_dataset/blob/master/dataset.zip,"
dataset.zip
",We have split the dataset (,", "
22275,https://sigsep.github.io/datasets/musdb.html,full MUSDB18 dataset,Download the ," and extract it into a folder of your choice. It should have two subfolders: ""test"" and ""train"" as well as a README.md file."
22279,#hda-person-dataset,HDA Person Dataset,                 | 2014             | 84           | 1           |          | Pyramid Features(ACF)      | Vary      | ✔          |                    | ✔                        | | ,        | 2014             | 53           | 13          | 2976     | Hand/Pyramid Features(ACF) | Vary      | ✔          | ✔                  | ✔                        | | 
22279,#shinpuhkan-dataset,Shinpuhkan Dataset,        | 2014             | 53           | 13          | 2976     | Hand/Pyramid Features(ACF) | Vary      | ✔          | ✔                  | ✔                        | | ,        | 2014             | 24           | 16          |          | Hand                       | 128X48    | ✔          | ✔                  |                          | | 
22279,http://vislab.isr.ist.utl.pt/hda-dataset/,HDA Person Dataset,"
","
"
22279,http://www.mm.media.kyoto-u.ac.jp/en/datasets/shinpuhkan/,Shinpuhkan Dataset,"
","
"
22306,#dataset-preparation,Dataset Preparation,"
","
"
22306,https://www.tensorflow.org/datasets,TensorFlow Datasets (TFDS),", but we also provide simpler wrappers for datasets available in ", (a 
22306,https://www.tensorflow.org/datasets,TensorFlow Datasets (TFDS),s use , as their data source. When you run our training binary (see instructions 
22358,http://data.allenai.org/downloads/qasc/qasc_dataset.tar.gz,http://data.allenai.org/downloads/qasc/qasc_dataset.tar.gz,: ,"
"
22534,https://www.robots.ox.ac.uk/~vgg/data/mview/,dinosaur dataset,"If you want to try the method on the public dataset like the dinosour, please first find the images from ",", then apply the "
22572,https://github.com/davide-belli/toulouse-road-network-dataset/tree/master/dataset,"
dataset/
","
",: Should contain the output Toulouse Road Network dataset. If you run 
22572,https://github.com/davide-belli/toulouse-road-network-dataset/tree/master/generate_toulouse_road_network_dataset.py,"
generate_toulouse_road_network_dataset.py
","
",: Main script to generate the dataset. It takes a few hours on a laptop. It calls three main subcomponents:
22572,https://github.com/davide-belli/toulouse-road-network-dataset/tree/master/dataset.py,"
dataset.py
","
",": PyTorch class extending Dataset Class. Includes options to load from source images, pickle files, apply BFS heuristics and others."
22573,https://github.com/davide-belli/generative-graph-transformer/blob/master/data/download_dataset.sh,"
data/download_dataset.sh
",First download Toulouse Road Network dataset using ,.
22662,./datasets,datasets,We provide the (z-scored) benchmark classification datasets used to generate the paper in the ," directory, but we omit the ICU mortality dataset (generated using the same procedures from "
22731,https://www.kaggle.com/quora/question-pairs-dataset,Quora Question Pairs Dataset,The Quora dataset is composed from the ,"
"
22753,https://archive.ics.uci.edu/ml/datasets/UJIIndoorLoc,https://archive.ics.uci.edu/ml/datasets/UJIIndoorLoc,"Indoor WIFI Dataset: UJIIndoorLoc, ",.
22753,http://cs.joensuu.fi/sipu/datasets/,http://cs.joensuu.fi/sipu/datasets/,"P. Fränti and S. Sieranoja: Clustering Basic Benchmarks, ",.
22789,/dataset,dataset,"
","
"
22817,src/dataset.py,dataset.py,"
",: processing of data
22889,https://kaolin.readthedocs.io/en/latest/modules/kaolin.io.dataset.html#kaolin.io.dataset.CachedDataset,CachedDataset,Reformated the data preprocessing with a new , replacing 
22889,https://kaolin.readthedocs.io/en/latest/modules/kaolin.io.dataset.html#kaolin.io.dataset.ProcessedDataset,ProcessedDataset, replacing ,"
"
22899,https://s3-us-west-2.amazonaws.com/allennlp/datasets/drop/drop_dataset.zip,The whole dataset,DROP: ,"
"
22908,https://www.inf.ufpr.br/vri/databases/vehicle-reid/data.tgz,Dataset,"
","
"
22981,http://www.cvlibs.net/datasets/kitti/eval_depth_all.php,KITTI dataset,"First, you need to download a stereo vision dataset. For this, we recommend ", and 
22981,https://lmb.informatik.uni-freiburg.de/resources/datasets/SceneFlowDatasets.en.html,SceneFlow dataset, and , and pass the path to the skeleton code.
23000,dataset/Imagenet,dataset/Imagenet,Please download the test images from https://drive.google.com/file/d/1Gs_Rw-BDwuEn5FcWigYP5ZM9StCufZdP/view?usp=sharing and extract it under ,"
"
23000,dataset/Imagenet,dataset/Imagenet,Please download the train images from https://drive.google.com/file/d/1R_aC1onf0Yv77cL0OHjJ2VeXjrIbgKXb/view?usp=sharing and extract it under ,"
"
23026,./datasets,datasets,Download one or both datasets to start training/inference with this code. Our scripts expect the datasets to be placed in ,.
23032,https://www.drone-dataset.com/,drone datasets,The goal of this repository is to make using ," as easy as possible. Therefore, we provide source code in Python for import and visualization. Thus, this source code not only allows to visualize trajectories and thus get an overview, but also serves as a template for your own projects."
23166,#datasets,Datasets,"
","
"
23235,http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz,Speech Command Dataset,We used the ," [1] (2nd version) as testbed to test our approach.  This dataset consists  on  aset of WAV audio files of 30 different spoken commands. The duration of all the files is fixed to 1 second, and the sample-rate is 16kHz in all the samples, so that each audio waveform is  composed  by 16000 values,  in  the  range [−2^15 , 2^15].   In the paper,  we used a subset of ten classes, those standard labels selected in previous publications: "
23263,#dataset-download-link,Dataset Download Link,"
","
"
23301,https://bdd-data.berkeley.edu,BDD100K dataset,". Also, the BDD-Anomaly dataset is sourced from the ",. Code for the multi-label out-of-distribution detection experiments is available in 
23346,https://github.com/nihalsid/ViewAL/tree/master/dataset/scannet-sample,"
dataset/scannet-sample
",A small example dataset is provided with this repository in ,.
23346,https://github.com/nihalsid/ViewAL/tree/master/dataset/preprocessing-scripts,"
dataset/preprocessing-scripts
","To use this repository datasets must be in the structure described in last section. For creating the lmdb database, seed set, train / test splits and superpixel maps check helper scripts in ",. We use 
23377,https://www.cityscapes-dataset.com/,Cityscapes dataset,First download the ," and then downsample the images and label maps to 1024x512 using bilinear and nearest-neighbor interpolation, respectively ("
23378,https://www.kaggle.com/bryanpark/jit-dataset,JIT Dataset,"
","
"
23378,https://www.kaggle.com/bryanpark/jejueo-single-speaker-speech-dataset,JSS Dataset,"
","
"
23410,http://www.ismir.net/resources/datasets/,ISMIR datasets page,"
","
"
23410,https://github.com/ismir/mir-datasets/blob/master/mir-datasets.yaml,mir-datasets.yaml,"Importantly, ", file is the 
23410,https://github.com/ismir/mir-datasets/blob/master/mir-datasets.yaml,mir-datasets.yaml,Each record in the , file adheres to one of the following formats:
23410,outputs/mir-datasets.md,mir-datasets.md,Which will produce the output , and 
23410,outputs/mir-datasets.js,mir-datasets.js, and , files contained in this repository. Note that this output file 
23480,https://github.com/huggingface/datasets,Huggingface's datasets,"
", library includes BERTScore in their metric collection.
23486,docs/demo-dataset.md,Demo Dataset,"
","
"
23507,http://www.cs.york.ac.uk/semeval-2013/task2/index.php?id=data,Semeval Twitter sentiment analysis dataset,For downloading tweets distributed using IDs to protect privacy.  Uses the format of the ,"
"
23517,https://ai.stanford.edu/~amaas/data/sentiment/,IMDB movies review dataset,"
","
"
23532,dataset_generation,dataset_generation,"
","
"
23532,dataset_generation/crawler.py,dataset_generation/crawler.py,"
","
"
23532,dataset_generation/random_paper_sampler.py,dataset_generation/random_paper_sampler.py,"
","
"
23532,dataset_generation/downloader.py,dataset_generation/downloader.py,"
","
"
23532,dataset_generation/latex_input_resolver.py,dataset_generation/latex_input_resolver.py,"
","
"
23532,dataset_generation/complete_dataset.py,dataset_generation/complete_dataset.py,"
","
"
23532,dataset_generation/renumber_paper.py,dataset_generation/renumber_paper.py,"
","
"
23567,http://www.cs.york.ac.uk/semeval-2013/task2/index.php?id=data,Semeval Twitter sentiment analysis dataset,For downloading tweets distributed using IDs to protect privacy.  Uses the format of the ,"
"
23587,https://lmb.informatik.uni-freiburg.de/resources/datasets/FlyingChairs.en.html,FlyingChairs dataset,Download all the relevant datasets including the ,", the "
23587,https://lmb.informatik.uni-freiburg.de/resources/datasets/SceneFlowDatasets.en.html,FlyingThings3D dataset,", the ", (we use 
23587,http://www.cvlibs.net/datasets/kitti/index.php,KITTI dataset," following the practice of FlowNet 2.0), the ",", and the "
23596,#datasets,Datasets,"
","
"
23696,https://sites.google.com/site/sznitr/code-and-datasets,RMIT dataset,", Right: ",)
23710,#download-datasets,Download the datasets,"
","
"
23714,http://cocodataset.org/#download,cocodataset,Please download the COCO dataset from ,. If you use 
23743,https://medium.com/@pierre_guillou/document-ai-document-understanding-model-at-line-level-with-lilt-tesseract-and-doclaynet-dataset-347107a643b8,"Document AI | Document Understanding model at line level with LiLT, Tesseract and DocLayNet dataset",Blog Post: ,"
"
23743,https://medium.com/@pierre_guillou/document-ai-processing-of-doclaynet-dataset-to-be-used-by-layout-models-of-the-hugging-face-hub-308d8bd81cdb,"Document AI | Processing of DocLayNet dataset to be used by layout models of the Hugging Face hub (finetuning, inference)",Blog post: ,"
"
23743,processing_DocLayNet_dataset_to_be_used_by_layout_models_of_HF_hub.ipynb,"Processing of DocLayNet dataset to be used by layout models of the Hugging Face hub (finetuning, inference)",Notebook ,"
"
23813,http://cvil.eecs.yorku.ca/projects/public_html/sRGB_WB_correction/dataset.html,Set1 of the Rendered WB dataset,We used images from , to build our method.
23911,https://www.kaggle.com/c/champs-scalar-coupling/data,Predicting Molecular Properties dataset from Kaggle.,Data preprocessing classes for ,"
"
23980,https://s3.eu-central-1.amazonaws.com/datasouls/public/sdsj2017_sberquad.csv,"Dataset: sdsj2017_sberquad.csv
","
","
"
23996,https://github.com/harvardnlp/boxscore-data/blob/master/rotowire.tar.bz2,RotoWire dataset,". More specifically, you just need to download the ",:
24007,scripts/1_download_dataset.sh,scripts/1_download_dataset.sh,The ," script is used for downloading all audio and metadata from the internet. The total size of AudioSet is around 1.1 TB. Notice there can be missing files on YouTube, so the numebr of files downloaded by users can be different from time to time. Our downloaded version contains 20550 / 22160 of the balaned training subset, 1913637 / 2041789 of the unbalanced training subset, and 18887 / 20371 of the evaluation subset."
24056,dataset/FaceShifter/README.md,dataset page, for more information! See its ," for updated numbers as well as an example video. If you want to access the new data and have already applied for our download script, simply reuse the original download link to get the updated script. Otherwise, please fill out "
24056,https://ai.googleblog.com/2019/09/contributing-data-to-deepfake-detection.html,Deep Fake Detection Dataset,"
",:
24056,dataset,dataset, We are hosting the Deep Fake Detection Dataset provided by Google & JigSaw. The dataset contains over 3000 manipulated videos from 28 actors in various scenes. The dataset has a similar file structure and is downloaded by default together with the regular dataset. See the , page for more information.
24065,http://www.cs.sfu.ca/~colour/data/shi_gehler/,Shi's Re-processing of Gehler's Raw Dataset:,"
","
"
24146,https://csegroups.case.edu/bearingdatacenter/pages/download-data-file/,CWRU Bearing Dataset,"
","
"
24146,https://mb.uni-paderborn.de/kat/forschung/datacenter/bearing-datacenter/,PU Bearing Dataset,"
","
"
24146,https://github.com/cathysiyu/Mechanical-datasets,SEU Gearbox Dataset,"
","
"
24146,https://github.com/ZhaoZhibin/DL-based-Intelligent-Diagnosis-Benchmark/tree/master/datasets,datasets,"
", contains the data augmentation methods and the Pytorch datasets for time and frequency domains.
24167,#loading-a-previously-transformed-dataset,Loading a Previously Transformed Dataset,"
","
"
24196,./data/README.md,Dataset README,Chatbot NLU Evaluation Benchmark dataset with missing/incorrect data (STT errors) and Twitter Sentiment dataset (Check ,)
24211,https://salu133445.github.io/lakh-pianoroll-dataset/,Lakh Pianoroll Dataset,We train the model with training data collected from ," to generate pop song phrases consisting of bass, drums, guitar, piano and strings tracks."
24211,https://salu133445.github.io/lakh-pianoroll-dataset/,Lakh Pianoroll Dataset,The training data is collected from ," (LPD), a new multitrack pianoroll dataset."
24221,dataset.csv,Dataset CSV,"
","
"
24227,http://archive.ics.uci.edu/ml/datasets/thyroid+disease,hypothyroid dataset,Example outliers from the ,:
24236,https://vision.in.tum.de/mono-dataset,https://vision.in.tum.de/mono-dataset,Get some datasets from , .
24236,https://vision.in.tum.de/mono-dataset,https://vision.in.tum.de/mono-dataset,Run on a dataset from , using
24236,https://vision.in.tum.de/mono-dataset,https://vision.in.tum.de/mono-dataset,The format assumed is that of ,". However, it should be easy to adapt it to your needs, if required. The binary is run with:"
24236,https://github.com/tum-vision/mono_dataset_code,https://github.com/tum-vision/mono_dataset_code,Use a photometric calibration (e.g. using , ).
24237,http://www.cvlibs.net/datasets/kitti/eval_odometry.php,KITTI dataset, cameras that computes the camera trajectory and a sparse 3D reconstruction (in the stereo and RGB-D case with true scale). It is able to detect loops and relocalize the camera in real time. We provide examples to run the SLAM system in the ," as stereo or monocular, in the "
24237,http://vision.in.tum.de/data/datasets/rgbd-dataset,TUM dataset," as stereo or monocular, in the "," as RGB-D or monocular, and in the "
24237,http://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets,EuRoC dataset," as RGB-D or monocular, and in the "," as stereo or monocular. We also provide a ROS node to process live monocular, stereo or RGB-D streams. "
24353,http://www.vision.ee.ethz.ch/en/datasets/,ETH Dataset," ETH or UCY datasets, you can find them here: ", and 
24353,https://graphics.cs.ucy.ac.cy/research/downloads/crowd-data,UCY Dataset, and ,.
24368,#datasets,Datasets,"
","
"
24395,https://github.com/pfliu-nlp/Named-Entity-Recognition-NER-Papers/blob/master/ner_dataset.md,NER Datasets 🔽,Mainstream ,"
"
24416,#download-event2012-dataset,Download Event2012 dataset,"
","
"
24416,#download-event2018-dataset,Download Event2018 dataset,"
","
"
24416,#use-first-story-detection-on-you-own-dataset,Use 'First Story Detection' on you own dataset,"
","
"
24426,https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus,Kaggle dataset, : Uses a , for implementing Named Entity Recognition using the 
24426,https://www.tensorflow.org/datasets/catalog/overview,TensorFlow datasets, and ,.
24426,https://www.tensorflow.org/datasets,TensorFlow Datasets,. Trax allows you to use , easily and you can also get an iterator from your own text file using the standard 
24445,https://vision.in.tum.de/data/datasets/rgbd-dataset/download,dataset website,Download selected sequences from the , and put them into some directory. You also need to download the 
24500,https://ls11-www.cs.tu-dortmund.de/staff/morris/graphkerneldatasets,dataset,", closeness centrality and also filtration functions on edges such as jaccard similarity, edge probability for commonly used graph classification ",.
24513,#finetuning-on-whole-dataset,Finetuning on whole dataset,"
","
"
24513,#sentiment-analysis-using-the-dutch-book-review-dataset,Sentiment analysis using the Dutch Book Review Dataset,"
","
"
24635,http://bit.ly/ted-data-zhijing,this dataset," For research use (strictly not commercial), download ", of all the transcripts of TED talks.
24688,./data/,TVR dataset,Data: ,"
"
24809,benchmark_dataset.zip,benchmark_dataset,The benchmark dataset can be downloaded from this Github repository: ,. Be aware that it expands to over 300 MB during decompression. The structure of the files is as follows.
24814,https://github.com/Valentyn1997/xray/wiki/First-look-at-dataset,First look at dataset,) and includes x-ray images of hands. The data seems not to be very clean (see ,). To handle this problem a data cleaning pipeline was implemented (see 
24844,https://www.kaggle.com/therohk/india-headlines-news-dataset,News Headlines Of India dataset,We use preprocessed samples from the ," to perform the comparison. Test cases are generated by taking the first 1000, 2 · 1000, . . . , 2¹⁰ · 1000 samples from the dataset. Given the same amount of time "
24844,https://www.kaggle.com/therohk/india-headlines-news-dataset,News Headlines Of India dataset, does not achieve this limit but signifi- cantly outperforms other methods. We used 10000 samples from the ,.
24844,https://archive.ics.uci.edu/ml/datasets/optical+recognition+of+handwritten+digits,Optical Recognition of Handwritten Digits Data Set,It is important that the proposed method has predictable behavior on simple datasets. We used the , which comprised 5620 preprocessed handwritten digits and thus has a simple structure that is assumed to be revealed by visualization. 
24911,https://cocodataset.org/,MSCOCO captioning dataset,"Dataset is developed at the Language Processing Laboratory, Uka Tarsadia University, Gujarat, India. It was part of ongoing research on Natural Lanugage Processing and Machine Translation. This dataset contains around 65000 english sentiences from ", that are translated to Gujarati and converted to parallel format.
24961,dataset.md,Datasets,"
","
"
25031,https://gradientdescending.com/alone-r-package-datasets-from-the-survival-tv-series/,Alone R package: Datasets from the survival TV series, | , | | 5 | 
25033,https://developers.google.com/search/docs/data-types/dataset,dataset discovery, generates a json-ld file (“linked data”) to aid in ,", creation of more extensive metadata (e.g. "
25077,https://voice.mozilla.org/en/datasets,common voices datasets,"Transfer learning on other languages, using the ","
"
25103,https://deepmind.com/research/open-source/open-source-datasets/kinetics/,Kinetics dataset, of ," consists of the 200 categories with most training examples; for each category, we randomly sample 400 examples from the training set, and 25 examples from the validation set, resulting in 80K training examples and 5K validation examples in total."
25168,https://medium.com/@jeffrey.lancaster/the-ultimate-game-of-thrones-dataset-a100c0cf35fb,"""The Ultimate Game of Thrones Dataset""","
","
"
25179,#how-can-i-use-my-own-dataset,How can I use my own dataset?,"
","
"
25250,dataset.zip,dataset,On the , of ~1000 most starred repositories on GitHub as of early February 2018 (
25266,https://datasets.simula.no/kvasir/,The Kvasir Dataset,Our dataset is a part of ,.
25268,http://people.ee.ethz.ch/~ihnatova/pynet.html#dataset,Zurich RAW to RGB mapping dataset,Download , and extract it into 
25275,docs/datasets.md,datasets.md,Please refer to , for details.
25282,https://www.tensorflow.org/datasets/catalog/imagenet2012,tensorflow_datasets,"Once you have created virtual machine with Cloud TPUs, and pre-downloaded the ImageNet data for ",", please set the following enviroment variables:"
25282,https://www.tensorflow.org/datasets/catalog/imagenet2012_subset,tensorflow datasets,You can access 1% and 10% ImageNet subsets used for semi-supervised learning via ,: simply set 
25332,https://github.com/TalwalkarLab/leaf/tree/master/data/shakespeare,instructions to prepare Shakespeare dataset,. Following the ,", we choose to use non-i.i.d., full-size dataset, and split 80% of the data points into the training dataset. Moreover, we set minimum number of samples per user at 9K. Thus, the following command returns our data partitioning:"
25411,#creating-the-dataset,Creating the dataset,"
","
"
25411,#creating-the-dataset-1,Creating the dataset,"
","
"
25424,dataset/,dataset/,"
", - contains files associated with preparation and loading the dataset of convex quadrangles
25468,#available-datasets,Available Datasets, - the directory with datasets. See , for summary.
25468,#available-datasets,Available Datasets, data! To use the clean dataset refer to ,. For the list of finally used predictors and the applied postprocessing refer to 
25532,https://archive.ics.uci.edu/ml/datasets/letter+recognition,letters dataset, provides an example for binary classification of the ,. Simply specify the data file location as well as Liblinear library location and run it.
25532,https://archive.ics.uci.edu/ml/datasets/MiniBooNE+particle+identification,MiniBooNE dataset, provides an example for binary classification of the , There are 3 inputs to run this program and several others to be supplied in a 
25545,#datasets,Datasets,"
","
"
25595,http://robotcar-dataset.robots.ox.ac.uk,Oxford Robotcar Dataset,This repo contains sample MATLAB and Python code for viewing and manipulating data from the , and 
25595,http://ori.ox.ac.uk/datasets/radar-robotcar-dataset,Oxford Radar Robotcar Dataset, and ,.
25595,https://github.com/dbarnes/radar-robotcar-dataset-sdk,radar-robotcar-dataset-sdk,An example script for scraping the dataset website can be found at ,.
25596,https://lcas.lincoln.ac.uk/wp/research/data-sets-software/l-cas-3d-point-cloud-people-dataset/,https://lcas.lincoln.ac.uk/wp/research/data-sets-software/l-cas-3d-point-cloud-people-dataset/,Dataset: ,"
"
25605,https://github.com/SsnL/dataset-distillation,Dataset Distillation,"
","
"
25648,http://www.cs.jhu.edu/~mdredze/datasets/sentiment/,Blitzer Dataset,Results on ,"
"
25658,https://research.googleblog.com/2017/08/launching-speech-commands-dataset.html,Google speech commands data set,Convolutional neural networks for , with 
25739,#about-dataset,About Dataset,"
","
"
25739,#dataset--preparation,Dataset Preparation,"
","
"
25741,#perform-training-on-coco-dataset,Perform Training on COCO Dataset,"
","
"
25741,#add-your-customized-dataset,Add your Customized Dataset,"
","
"
25741,#perform-training-on-coco-dataset,Perform Training on COCO Dataset,"
","
"
25741,#add-your-customized-dataset,Add your Customized Dataset,"
","
"
25741,#perform-training-on-coco-dataset,Perform Training on COCO Dataset,"
","
"
25741,maskrcnn_benchmark/data/datasets/__init__.py,"
vc_rcnn/data/datasets/__init__.py
","
",: add it to 
25752,#datasets,Datasets, // , // 
25862,https://github.com/DSE-MSU/DeepRobust/tree/master/deeprobust/graph/#supported-datasets,datasets,[12/2020] [Graph Package] Add four more , and one defense algorithm. More details can be found 
25874,#datasets,Datasets,"
","
"
25916,https://github.com/synalp/NER/tree/master/corpus/CoNLL-2003,"CoNLL 2003 POS, Chunking and NER datasets","
",.
25969,gamma-dataset,toy dataset,The respective datasets are: ,",  "
25969,/theta-dataset,theta-dataset,"Here, an additional visual examples on another dataset with GT (we call ",) for our 3 methods 
25980,latentspace/datasets.py,latentspace/datasets.py,"To work with a custom dataset, you need to implement a new dataset wrapper in ",. Add support to this dataset in 
25981,http://www.robotmultimodal.com/datasets/,http://www.robotmultimodal.com/datasets/,"This repository will host the machine learning models to benchmark the iCub multisensor datasets. To follow up-to-date information, visit ",.
25989,https://github.com/1024er/cbert_aug/tree/crayon/datasets/stsa.binary,https://github.com/1024er/cbert_aug/tree/crayon/datasets/stsa.binary,STSA-2 : ,"
"
25989,https://github.com/1024er/cbert_aug/tree/crayon/datasets/TREC,https://github.com/1024er/cbert_aug/tree/crayon/datasets/TREC,TREC : ,"
"
26018,lolip/dataset/__init__.py,lolip/dataset/__init__.py," with torchvision ImageFolder readable format. For more detail, please refer to ",.
26018,notebooks/dataset_dist.ipynb,notebooks/dataset_dist.ipynb,The code for getting train-train separation and test-train separation ,"
"
26018,notebooks/dataset_dist.ipynb,notebooks/dataset_dist.ipynb,Table1 and Figures in Appendix D: ,"
"
26069,https://csegroups.case.edu/bearingdatacenter/pages/download-data-file/,CWRU Bearing Dataset,"
","
"
26069,https://mfpt.org/fault-data-sets/,MFPT Bearing Dataset,"
","
"
26069,https://mb.uni-paderborn.de/kat/forschung/datacenter/bearing-datacenter/,PU Bearing Dataset,"
","
"
26069,http://biaowang.tech/xjtu-sy-bearing-datasets/,XJTU-SY Bearing Dataset,"
","
"
26069,https://github.com/cathysiyu/Mechanical-datasets,SEU Gearbox Dataset,"
","
"
26069,https://github.com/ZhaoZhibin/DL-based-Intelligent-Diagnosis-Benchmark/tree/master/datasets,datasets,"
", contains the data augmentation methods and the Pytorch datasets for 1D and 2D signals.
26107,https://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams20112014#,UCI electricity dataset,"This repository contains two sets of experiments, one for the ",", and one on historical S&P500 stock prices."
26143,http://picdataset.com:8000/challenge/task/download/,http://picdataset.com:8000/challenge/task/download/,Please find the dataset from the PIC challenge website: ,"
"
26191,https://ls11-www.cs.tu-dortmund.de/staff/morris/graphkerneldatasets,TUD Graph Kernel Datasets,", ",", and "
26214,https://figshare.com/articles/dataset/OpenEA_dataset_v1_1/19258760/3,v2.0 dataset, issue. It is strongly recommended to use the ," for evaluating attribute-based entity alignment methods, such that the results can better reflect the robustness of these methods in real-world situation."
26214,#kg-sampling-method-and-datasets,KG Sampling Method and Datasets,"
","
"
26214,#dataset-overview,Dataset Overview,"
","
"
26214,#dataset-description,Dataset Description,"
","
"
26283,app/utils/dataset_schema.json,utils/dataset_schema.json,All datasets must adhere to a specific dataset schema (see ,"). See the files in [demo_data] for examples, as well as those in "
26285,tree/master/utils/plot_dataset.py,utils/plot_dataset.py, is also provided in ,.
26287,https://github.com/alan-turing-institute/TCPD/blob/master/datasets/nile/nile.json#L8,nile dataset," field to mark the indices of each data point. At the moment, these indices need to be consecutive integers. This entry mainly exist for a future scenario where we may want to consider non-consecutive timesteps. If the time axis can be mapped to a date or time, then a type and format of this field can be specified (see e.g. the ",", which has year labels)."
26287,https://github.com/alan-turing-institute/TCPD/blob/master/datasets/brent_spot/brent_spot.json#L511,brent_spot dataset," object if possible (see, e.g., the ","). If this is not available, the time series name should be added to the "
26298,http://vipl.ict.ac.cn/view_database.php?id=14,LRW-1000 dataset,"
"," had cropped the mouth ROI, we directly sent them to the model."
26304,https://magenta.tensorflow.org/datasets/maestro,https://magenta.tensorflow.org/datasets/maestro,Download 'MAESTRO' dataset (,)
26304,https://magenta.tensorflow.org/datasets/nsynth,Nsynth dataset,"
","
"
26310,https://www.dropbox.com/s/8n02xqv3l9q18r1/datasets.zip?dl=0,ETH-UCY Dataset,"
", Provided by 
26328,os2d/data/dataset.py,os2d/data/dataset.py,. See , for docs and examples.
26334,datasets/README.md,datasets/README.md,See , for more details.
26336,http://tacodataset.org,tacodataset.org,"TACO is a growing image dataset of waste in the wild. It contains images of litter taken under diverse environments: woods, roads and beaches. These images are manually labeled and segmented according to a hierarchical taxonomy to train and evaluate object detection algorithms. Currently, images are hosted on Flickr and we have a server that is collecting more images and annotations @ ","
"
26345,#5-Small-datasets,Small datasets,"
", with 
26531,https://lmb.informatik.uni-freiburg.de/resources/datasets/RenderedHandposeDataset.en.html,Rendered Handpose Dataset,"
","
"
26549,http://www.cvlibs.net/datasets/kitti/raw_data.php,raw KITTI dataset,You can download the entire , by running:
26549,http://www.cvlibs.net/datasets/kitti/eval_odometry.php,KITTI odometry dataset,"For this evaluation, the ","
"
26550,http://ai.stanford.edu/~amaas/data/sentiment/,IMDB dataset, on the polluted , (please refer to the paper for details) for the demo purpose.
26550,http://snap.stanford.edu/data/web-BeerAdvocate.html,beer review dataset,The original ," has been removed by the dataset’s original author, at the request of the data owner, BeerAdvocate.  To respect the wishes and legal rights of the data owner, we do not include the data in our repo.  If you are interested in beer review, please first obtain the dataset from the original authors who released the dataset. We will then be happy to provide our data and environment partitions to whoever is granted rights to the data.  Once you have access to the dataset and have prepared it in the desired format, please refer to the "
26605,#train-the-2-fold-ecan-with-aeca-on-mnist-data-set,Train the 2-fold ECAN with AECA on MNIST data set,"
","
"
26605,#train-the-2-fold-ecan-with-veca-on-mnist-data-set,Train the 2-fold ECAN with VECA on MNIST data set,"
","
"
26679,https://github.com/jitinkrishnan/NASA-SE/blob/master/se_data/se_ner_annotated.tsv,CR annotated dataset,"
","
"
26679,https://github.com/jitinkrishnan/NASA-SE/blob/master/se_data/acronyms.txt,Accronyms dataset,"
","
"
26679,https://github.com/jitinkrishnan/NASA-SE/blob/master/se_data/definitions.txt,Definitions dataset,"
","
"
26679,https://github.com/jitinkrishnan/NASA-SE/blob/master/se_data/keywords2annotate.txt,Keyword annotated dataset,"
","
"
26688,http://www.bioinf.jku.at/people/klambauer/sars_cov_dataset.zip,Data set,"
"," (if you use this data set, please do not forget to cite this work!)"
26774,https://projects.asl.ethz.ch/datasets/doku.php?id=laserregistration:laserregistration,the ETH datasets,"
",;
26774,http://asrl.utias.utoronto.ca/datasets/3dmap/index.html,the Canadian Planetary Emulation Terrain 3D Mapping datasets,"
",;
26774,https://vision.in.tum.de/data/datasets/rgbd-dataset,the TUM Vision Groud RGBD datasets,"
",;
26774,https://irap.kaist.ac.kr/dataset/,the KAIST Urban datasets,"
",.
26793,https://huggingface.co/datasets/elenanereiss/german-ler,https://huggingface.co/datasets/elenanereiss/german-ler,Now available on Huggingface ,"
"
26819,https://github.com/hhase/sacrum_data-set,dataset,: corresponds to the location of the ,.
26879,#Supported-dataset-names,"
Supported dataset names
",. Check the ,"
"
26879,#Supported-dataset-names,"
Supported dataset names
",. Check the ,"
"
26889,https://motchallenge.net/data/MOT17Det/,MOT Challenge dataset,Prepare synthesized raw video denoising dataset (SRVD dataset) to pretrain RViDeNet. Please download ," and select four videos (02, 09, 10, 11) from train set. To convert sRGB clean videos to raw clean videos, run:"
26903,https://github.com/dgedon/DeepSSM_SysID/blob/master/options/dataset_options.py,/options/dataset_options.py,". A training, validation and test dataset has to be provided as numpy arrays of shape (sequence length, signal dimension). The sequence length is defined in the file ",.
26980,#training-on-synthetic-composite-adobe-dataset,Training code on synthetic-composite Adobe dataset,"
","
"
26980,#training-on-synthetic-composite-adobe-dataset,supervised training on synthetic-composite Adobe dataset,Training code for , and 
26989,http://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets,EuRoC MAV Dataset,Download ,". Although it contains stereo cameras, we only use one camera. Before testing, copy the new "
26997,http://vision.middlebury.edu/flow/data/,Middlebury-OTHERS dataset,[ , ] - download 
26997,https://github.com/baowenbo/MEMC-Net#hd-dataset-results,HD dataset,[ , ] - download the original ground truth videos [
27014,https://github.com/JoyHuYY1412/LST_LVIS/blob/master/jupyter_notebook/dataset_preprocess.ipynb,dataset_preprocess.ipynb,"
",: LVIS dataset is split into the base set and sets for the incremental phases.
27027,#dataset,Dataset,"
","
"
27038,http://irvlab.cs.umn.edu/resources/suim-dataset,SUIM Dataset,  • ,  • 
27082,https://github.com/huggingface/datasets,🤗 Datasets library, using the ,". Note that this is a very large dataset, so we ran the docTTTTTquery inference step across multiple TPUs. In fact, there is a signficant blow-up in the dataset size compared to MS MARCO v1, because of which we choose to only generate 20 queries per passage. Also, we use a different docTTTTTquery model trained on the MS MARCO v2 passage ranking dataset."
27082,https://github.com/huggingface/datasets,🤗 Datasets library, using the ,". Note that this is a very large dataset, so we ran the docTTTTTquery inference step across multiple TPUs. Also, we use a different docTTTTTquery model trained on the MS MARCO v2 passage ranking dataset."
27099,#prepare-datasets,Prepare datasets,"
","
"
27099,data/download_datasets.md,"
data/download_datasets.md
",Please download or preparation the data via following the instructions at ,.
27161,https://jacobkrantz.github.io/vlnce/data,dataset page, runs baseline models out of the box. See the ," for format, contents, and a changelog. We encourage use of the most recent version ("
27163,https://deep-geometry.github.io/abc-dataset/,ABC Dataset,Other shape datasets (i.e. ,", "
27178,https://github.com/X-zhangyang/AFD-dataset,original AFD dataset here,Get the ,.
27183,dataset,dataset,. Total dataset is ~507GB and contains 7 million frames. Dataset downloading and frame extraction code is located in ," directory. For model training, we use the split from "
27203,https://covid-19-uk-datasette-65tzkjlxkq-ew.a.run.app/,Datasette instance,"
"," hosting the data. This is useful for running simple SQL on the data, or exporting in JSON format."
27215,https://github.com/deepset-ai/COVID-QA/tree/master/data/question-answering/COVID-QA.json,COVID-QA Dataset,Link to ,"
"
27276,#datasets,Datasets,"
","
"
27276,#evaluation-on-ycb_video-dataset,Evaluation on YCB_Video Dataset,"
","
"
27276,#evaluation-on-linemod-dataset,Evaluation on LineMOD Dataset,"
","
"
27276,#tips-for-your-own-dataset,Tips for your own dataset,"
","
"
27290,./data/div2k_dataset.py#L11-L12,div2k_dataset," (test), or you can add your own path in the rootlist of ", or 
27290,./data/benchmark_dataset.py#L15-L16,benchmark_dataset, or ,.
27325,#standardized-dataset-json-file,Standardized dataset JSON file,. The script is supposed to download/process raw corpus data and output a standardized dataset json file (see ,).
27430,http://www.svcl.ucsd.edu/projects/anomaly/dataset.htm,original UCSD Ped 1 dataset,This project proposed an anomaly detection framework using multilevel information to identify anomaly objects in surveillance videos. Our research results in re-annotating the , which is one of the most widely-used datasets in Video Anomaly Detection. You can find the new label set in 
27431,http://cocodataset.org/#download,COCO dataset,"
","
"
27478,#dataset,dataset,"
","
"
27485,https://github.com/ieee8023/covid-chestxray-dataset,covid19 xray dataset released 4 days ago,", from a recent ",.
27519,https://vision.princeton.edu/projects/2012/SUN360/data/,SUN360 dataset, These images are extracted from the ,"
"
27527,https://www.kaggle.com/netflix-inc/netflix-prize-data,Netflix Prize dataset,This repository contains information about the genres of the movies of the ,.
27544,#datasets,datasets,Download and unzip the ,"
"
27544,scripts/make_dataset.sh,make_dataset.sh,You need to preprocess the datasets in order to index all the samples and extract faces. Just run the script ,"
"
27544,https://www.kaggle.com/c/deepfake-detection-challenge/data,Facebook's DeepFake Detection Challenge (DFDC) train dataset,"
", | 
27555,#dataset,Dataset,"
","
"
27564,https://cocodataset.org/#download,2014 COCO dataset,Download the , as well as 
27567,#dataset,Dataset,"
","
"
27578,#supported-datasets,datasets,: create the probing task datasets from the original ,.
27594,#get-the-processed-train/val/test-datasets,Get the processed train/val/test datasets,"
","
"
27594,https://www.dropbox.com/s/tavebz23va1hvrd/ExHiRD_test_datasets.zip?dl=1,processed testing datasets,Download the ,. Download the 
27594,https://www.dropbox.com/s/5sbwt2k66nly1ib/ExHiRD_train_valid_dataset.zip?dl=1,processed train_valid_dataset,. Download the ,.
27594,https://www.dropbox.com/s/5sbwt2k66nly1ib/ExHiRD_train_valid_dataset.zip?dl=1,processed train_valid_dataset," under the home folder (i.e., ExHiRD-DKG), download the ", into 
27613,https://github.com/feathers-dataset/feathersv1-dataset,FeathersV1 Dataset,This repository contains a Jupyter notebooks and scripts for solving sparse classification task based on ,.
27613,https://github.com/feathers-dataset/feathersv1-dataset,FeathersV1 Dataset,Download , into 
27616,#dataset,Dataset,"
","
"
27629,https://conala-corpus.github.io/,CoNaLa challenge dataset," software, and the ",.
27630,#uci-datasets,UCI Datasets,"
","
"
27630,#image-datasets,Image Datasets,"
","
"
27633,https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html,20 Newsgroups Dataset, on , Using 
27638,https://sibeiyang.github.io/dataset/ref-reasoning,Ref-Reasoning Dataset,"
","
"
27649,DEMO/load_data_tutorial.ipynb,Dataset Tutorial,| Name | Description | |-----------------|-------------| | , | Tutorial on how to use the dataset loader and read customized data| | 
27649,DEMO/load_data_tutorial.ipynb,Dataset Tutorial,Checkout ,.
27681,https://www.dropbox.com/s/9w8nmj791c9ogsx/data_upload_v3.zip?dl=0,dataset_link,"We prepared a dataset of around 5000 images, which can be downloaded from here: ","
"
27681,https://github.com/ieee8023/covid-chestxray-dataset,Covid-Chestxray-Dataset,"
",", for COVID-19 X-ray samples"
27682,#1-naver-clovacall-dataset-contribution,1. Naver ClovaCall dataset contribution,"
","
"
27682,#the-dataset-statistics,The dataset statistics,"
","
"
27682,#the-dataset-structure,The dataset structure,"
","
"
27682,#2-dataset-downloading-and-license,2. Dataset downloading and license,"
","
"
27683,#1-naver-clovacall-dataset-contribution,1. Naver ClovaCall dataset contribution,"
","
"
27683,#the-dataset-statistics,The dataset statistics,"
","
"
27683,#the-dataset-structure,The dataset structure,"
","
"
27683,#2-dataset-downloading-and-license,2. Dataset downloading and license,"
","
"
27704,https://lmb.informatik.uni-freiburg.de/resources/datasets/RenderedHandposeDataset.en.html,dataset, [,]
27708,https://github.com/ieee8023/covid-chestxray-dataset,covid-chestxray-dataset, uses the , for COVID-19 X-Ray images and 
27713,datasets,datasets," and can be downloaded by following the links below. First, download the ", and unpack into 
27763,#datasets,datasets, See , for an overview of the datasets (daily updates).
27763,#cord-19-dataset,CORD-19 dataset,"
","
"
27763,#covid19-preprints-dataset,COVID19 preprints dataset,"
","
"
27785,#4-covid-semiseg-dataset,4. COVID-SemiSeg Dataset,"
","
"
27819,datasets/,datasets,the , used for assessing our proposal
27823,https://github.com/huggingface/datasets,datasets,": loads data from plaintext, tsv, and huggingface's ","
"
27825,https://pytorch.org/docs/stable/torchvision/datasets.html#mnist,torchvision datasets," aims to make these processing steps easier, faster, and more intuitive to perform, while retaining full compatibility to and from the leading libraries. This also means you can grab a dataset from ", and use it directly with tensorflow:
27847,https://github.com/huggingface/datasets,"
datasets package", and datasets from the ,! Here's an example of loading and attacking a pre-trained model and dataset:
27871,https://github.com/Aatlantise/syntactic-augmentation-nli/tree/master/datasets,"
datasets
",Augmentation datasets are in the , folder. Each file is named using the following abbreviations:
27871,https://github.com/Aatlantise/syntactic-augmentation-nli/tree/master/generate_dataset.py,"
generate_dataset.py
", data files were used to augment the MultiNLI training set in our experiments. They are randomly selected subsets or unions of subsets of transformations created by running ,", which requires MultiNLI's json file "
27877,./data/dataset_metadata.csv,dataset_metadata.csv,"Feel free to use (and cite) our dataset. We currently have >200 LUS videos labelled with a diagnostic outcome. Moreover, lung severity scores for 136 videos are made available in the ", under the column 
27931,http://cvgl.stanford.edu/projects/uav_data/,Stanford Drone Dataset, dataset and the ,". For each dataset, we provide, in the "
27940,https://github.com/EdinburghNLP/csi-corpus,"
CSI dataset
","In this work, we summarize screenplays by taking into account their underlying narrative structure. We formalize screenplay summarization as scene selection, where we want to select an optimal subsequence of scenes that describe the story from beginning to end. We conduct experiments on the ", that contains gold-standard scene-level summary annotations.
27940,https://github.com/EdinburghNLP/csi-corpus,"
CSI dataset
","
",: Summarization dataset containing 39 episodes with scene-level binary annotations indicating whether each scene belongs to the summary.
28038,http://personal.ie.cuhk.edu.hk/~ccloy/downloads_mall_dataset.html,Mall dataset,: ,"
"
28071,notebooks/datasets.ipynb,datasets,See , notebook for an example of how to load the datasets provided below. The 
28121,dataset/,dataset/,| Path     	               | Description                         	| |------------------------- |------------------------------	| | ,     | The experiment notebooks expect the patched TACRED dataset splits to be stored here. | | 
28131,https://scifact.s3-us-west-2.amazonaws.com/release/latest/data.tar.gz,"
Download the dataset here
",⬇️,.
28131,#dataset,Dataset,"
","
"
28149,https://tudatalib.ulb.tu-darmstadt.de/handle/tudatalib/2329,Argument Aspect Detection dataset,"To train an aspect detection model, please download our "," (due to license reasons, it is necessary to fill the form with your name and email). As a model, we suggest BERT from "
28150,#indicnlp-news-article-classification-dataset,IndicNLP News Article Classification Dataset,"
","
"
28150,#publicly-available-classification-datasets,Publicly available Classification Datasets,"
","
"
28197,./dataset/,"
dataset
",. The documentation for the dataset can be found in ,.
28199,https://production-media.paperswithcode.com/about/datasets.json.gz,Datasets,"
","
"
28209,#running-on-new-datasets,Running on New Datasets,"
","
"
28210,#datasets,Datasets,"
","
"
28210,http://odds.cs.stonybrook.edu/yelpchi-dataset/,Yelp Spam Review Dataset,", we preprocessed ", with reviews as nodes and three relations as edges.
28227,#dataset-processing,download dataset,"
","
"
28227,#dataset-processing,convert dataset,"
","
"
28227,https://www.cs.cmu.edu/~glai1/data/race/,RACE dataset,"
","
"
28304,#examples-and-datasets,Examples and datasets,Dump data from the SQL database to a JSON file (see , for the JSON structure).
28317,https://github.com/LibraryOfCongress/newspaper-navigator/blob/master/process_beyond_words_dataset.py,process_beyond_words_dataset.py," annotations added since 12/01/2019, first update the annotations file from the Beyond Words website, then run the script ",".  To add the additional headline and advertisement annotations, you can retrieve them from "
28324,https://web.eecs.umich.edu/~lahiri/gutenberg_dataset.html,Project Guttenberg Dataset, no longer have it available for public download. The , is a somewhat smaller (200M word) collection of older books that are public domain.
28325,http://bvisionweb1.cs.unc.edu/licheng/referit/data/refcocog.zip,RefCOCOg dataset,This folder contains adversarial annotations for part of the test images from ,.
28365,https://github.com/jcblaisecruz02/Filipino-Text-Benchmarks#datasets,Released Datasets,"
","
"
28365,https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/,WikiText Long Term Dependency dataset," Large scale, unlabeled text dataset with 39 Million tokens in the training set. Inspired by the original "," (Merity et al., 2016). TL means ""Tagalog."" Originally published in "
28374,https://www.kaggle.com/naurosromim/bengali-hate-speech-dataset,https://www.kaggle.com/naurosromim/bengali-hate-speech-dataset,Link to data: ,"
"
28374,https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech,https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech,Link to data: ,"
"
28374,https://www.tensorflow.org/datasets/catalog/civil_comments,https://www.tensorflow.org/datasets/catalog/civil_comments,Link to data: ,"
"
28374,https://github.com/Vicomtech/hate-speech-dataset,https://github.com/Vicomtech/hate-speech-dataset,Link to data: ,"
"
28374,https://hasocfire.github.io/hasoc/2019/dataset.html,https://hasocfire.github.io/hasoc/2019/dataset.html,Link to data: ,"
"
28374,https://dataverse.mpi-sws.org/dataset.xhtml?persistentId=doi:10.5072/FK2/ZDTEMN,https://dataverse.mpi-sws.org/dataset.xhtml?persistentId=doi:10.5072/FK2/ZDTEMN,Link to data: ,"
"
28374,https://hasocfire.github.io/hasoc/2019/dataset.html,https://hasocfire.github.io/hasoc/2019/dataset.html,Link to data: ,"
"
28374,https://hasocfire.github.io/hasoc/2019/dataset.html,https://hasocfire.github.io/hasoc/2019/dataset.htm,Link to data: ,"
"
28378,#preprocessing-a-dataset,Preprocessing a Dataset,"
","
"
28378,#an-example-preprocessing-a-new-dataset,An Example: Preprocessing a New Dataset,"
","
"
28390,docs/dataset.md,BIG Dataset and Relabeled PASCAL VOC 2012,"
","
"
28468,#1-datasets,1. Datasets,"
","
"
28468,#11-regular-latin-datasets,1.1 Regular Latin Datasets,"
","
"
28468,#12-irregular-latin-datasets,1.2 Irregular Latin Datasets,"
","
"
28468,#13-multilingual-datasets,1.3 Multilingual Datasets,"
","
"
28468,#14-synthetic-datasets,1.4 Synthetic Datasets,"
","
"
28468,#15-comparison-of-the-benchmark-datasets,1.5 Comparison of the Benchmark Datasets,"
","
"
28468,#22-performance-comparison-on-benchmark-datasets,2.2 Performance Comparison on Benchmark Datasets,"
","
"
28468,#221-performance-comparison-of-recognition-algorithms-on-regular-latin-datasets,2.2.1 Performance Comparison of Recognition Algorithms on Regular Latin Datasets,"
","
"
28468,#222-performance-comparison-of-recognition-algorithms-on-irregular-latin-datasets,2.2.2 Performance Comparison of Recognition Algorithms on Irregular Latin Datasets,"
","
"
28468,http://cvit.iiit.ac.in/research/projects/cvit-projects/the-iiit-5k-word-dataset,dataset,"
","
"
28477,#extend-to-other-tasks-and-datasets,Extend to other tasks and datasets,"If you want to use your own datasets, please follow the guidance of next section ",.
28481,http://www.mustafabaydogan.com/files/viewdownload/14-multivariate-time-series-classification/29-multivariate-time-series-classification-datasets.html,Multivariate Time Series Classification Datasets,The multivariate dataset format is based on ,.
28489,https://github.com/rcamino/dataset-pre-processing,rcamino/dataset-pre-processing,Data is not included in the examples because of space limitations and because it does not belong to me. You can find example scripts to download the kind of data and metadata required for this project in ,.
28489,https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients,dataset repository,You can find more information about the dataset in the , or in 
28498,./released_datasets,released_datasets,We have released two subsets of Visdial val set (mentioned in our paper) in the folder ,:
28512,https://gitlab.ika.rwth-aachen.de/cam2bev/cam2bev-data/-/tree/master/1_FRLR,"
Dataset 1_FRLR
","
",": images from four vehicle-mounted cameras, ground-truth BEV image centered above the ego vehicle"
28512,https://gitlab.ika.rwth-aachen.de/cam2bev/cam2bev-data/-/tree/master/2_F,"
Dataset 2_F
","
",: images from one frontal vehicle camera; ground-truth BEV image left-aligned with ego vehicle
28528,dataset,dataset,"
", - consists of dataset generation codes
28584,(https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/stackoverflow/load_data),tff.simulation.datasets module,The main dataset used for these experiments is hosted by Kaggle and made available through the , in the 
28593,https://github.com/NVlabs/ffhq-dataset,Flickr-Faces-HQ dataset, | Raw data for the ,. | └  
28593,./dataset_tool.py,dataset_tool.py,"To obtain other datasets, including LSUN, please consult their corresponding project pages. The datasets can be converted to multi-resolution TFRecords using the provided ",:
28600,#supported-datasets,Supported datasets,"
","
"
28605,https://www.kaggle.com/bryanpark/the-world-english-bible-speech-dataset,Kaggle Datasets,. Kyubyong split each chapter by verse manually and aligned the segmented audio clips to the text. They are 72 hours in total. You can download them at ,.
28612,#custom-datasets,custom datasets,", abstracts from arXiv, and song lyrics. By default, the scripts are configured to use the hierarchical mask function outlined in our paper. This section outlines how to train ILM models on ", and 
28637,https://sites.google.com/view/cwisharedtask2018/datasets,Complex word identification Shared Task 2018 dataset,The full annotated dataset consisting of 4732 phrases extracted from the , is stored in the tab-separated file 
28637,https://github.com/ekochmar/MWE-CWI/blob/master/final_MWE_dataset.tsv,"
final_MWE_dataset.tsv
", is stored in the tab-separated file , with the following fields:
28650,https://dns4public.blob.core.windows.net/dns4archive/dns5-datasets-files-sha1.csv.bz2,dns5-datasets-files-sha1.csv.bz2, Personalized DNS datasets is available at: ,. The archive is 41.3MB in size and can be read in Python like this:
28677,#dataset,Dataset,"
","
"
28677,back-end/www/smoke_video_dataset.py,smoke_video_dataset.py,"
","
"
28684,#datasets,Datasets,"
","
"
28702,https://figshare.com/articles/dataset/SDM-Genomic-Datasets/14838342/1,SDM-Genomic-datasets,From ,", datasets including 10k, 100k, and 1M records with 25% and 75% duplicates rates, over six mapping rules with different complexities (1/4 simple object map, 2/5 object reference maps, 2/5 object join maps)"
28708,https://www.cs.toronto.edu/~vmnih/data/,Massachusetts Buildings Dataset,Download the ," Training Set as the source domain, and put it "
28719,ops/dataset_configs.py,ops/dataset_configs.py,Configure the dataset in ,.
28720,#deeplabv3-model-and-datasets,DeepLabv3+ Model and Datasets,"
","
"
28720,#how-to-add-your-own-dataset,How to add your own dataset,"
","
"
28720,https://www.audi-electronics-venture.de/aev/web/de/driving-dataset.html,A2D2 Dataset,"
","
"
28720,https://www.cityscapes-dataset.com/,Cityscapes Dataset,"
","
"
28720,https://pytorch.org/docs/1.3.1/data.html?highlight=dataset#torch.utils.data.Dataset,PyTorch dataset class,Write a , for your dataset. The 
28790,https://datashare.is.ed.ac.uk/handle/10283/2651,the VCTK dataset,Download and uncompress ,.
28810,http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d,KITTI object detection 3D dataset,"
","
"
28810,https://www.argoverse.org/data.html,Argoverse dataset v1.1,"
","
"
28810,https://self-driving.lyft.com/level5/data/,Lyft Level 5 dataset v1.02,"
","
"
28810,https://waymo.com/open/data/,Waymo dataset v1.0,"
","
"
28880,https://supervise.ly/explore/projects/supervisely-person-dataset-23304/datasets,"
Supervisely Person Dataset
","-Net for human segmentation, so we trained another example model for human segemntation based on ",. 
28965,https://commoncrawl.org/2016/10/news-dataset-available/,Common Crawl News dataset," (WCEP), each paired with a cluster of news articles associated with an event. These articles consist of sources cited by editors on WCEP, and are extended with articles automatically obtained from the ",". For more information about the dataset and experiments, check out our ACL 2020 paper: "
28970,news_tls/explore_dataset.py,news_tls/explore_dataset.py,Check out , to see how to load the provided datasets.
29021,"https://archive.ics.uci.edu/ml/datasets/Taxi+Service+Trajectory+-+Prediction+Challenge,+ECML+PKDD+2015#",ECML/PKDD 2015 dataset,"
","
"
29044,http://cvlibs.net/datasets/kitti/eval_tracking.php,KITTI Tracking Dataset," cameras that is able to track dynamic objects, estimate the camera poses along with the static and dynamic structure, the full SE(3) pose change of every rigid object in the scene, extract velocity information, and be demonstrable in real-world outdoor scenarios. We provide examples to run the SLAM system in the ",", and in the "
29044,https://robotic-esp.com/datasets/omd/,Oxford Multi-motion Dataset,", and in the ",.
29103,dataset.py,dataset.py, The processing of dataset happens inside the ,.
29116,https://github.com/mlmed/torchxrayvision/blob/master/torchxrayvision/datasets.py,View docstrings for more detail on each dataset,"
", and 
29163,toydataset/README.md,toydataset_README.md,Toydataset Domain Adaptation Experiments (,)
29163,toydataset,"
toydataset
",Full details on toydataset domain adaptation including codes in , subdirectory.
29163,toydataset/git_images/plots/videos,"
toydataset/git_images/plots/videos
","
", contains videos of the training of Contradistinguisher using CUDA as the epoch progresses. We can observe the decision boundary being updated to satisfy both the domains as they are jointly trained without domain alignment.
29166,https://github.com/JerryWei03/COVID-Q/blob/master/final_master_dataset.csv,final_master_dataset.csv,The dataset CSV file can be found at ,.
29236,http://data.gdeltproject.org/blog/2020-coronavirus-narrative/live_tvnews/MASTERFILELIST.TXT, COVID-19 Television Coverage Dataset,"
",: A New Dataset For Exploring The Coronavirus Narrative On Television News.
29236,https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data,CSSE COVID-19 Dataset,"
",: Daily case reports
29236,https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset,Novel Corona Virus 2019 Dataset,"
",": This dataset has daily level information on the number of affected cases, deaths and recovery from 2019 novel coronavirus. Please note that this is a time series data and so the number of cases on any given day is the cumulative number."
29236,https://github.com/covid19datahub/COVID19,Coronavirus COVID-19 (2019-nCoV) Epidemic Datasets ,"
",":Provide the research community with a unified data hub by collecting worldwide fine-grained data merged with demographics, air pollution, and other exogenous variables helpful for a better understanding of COVID-19."
29236,https://www.acaps.org/covid19-government-measures-dataset,#COVID19 Government Measures Dataset,"
",": The #COVID19 Government Measures Dataset puts together all the measures implemented by governments worldwide in response to the Coronavirus pandemic. Data collection includes secondary data review. The researched information available falls into five categories: Social distancing, Movement restrictions, Public health measures, Social and economic measures, Lockdowns."
29241,https://github.com/abin24/Magnetic-tile-defect-datasets.,Magnetic Tile Defect Dataset,"We used magetic tile defect dataset to test our proposed model, the original dataset can be found in ",". Before feeding the data into our model, we resize all the images into 100 by 100, and apply data augmentation techniques (flip and rotate) to enrich samples in classes ""crack"" and ""fray""."
29297,dataset_statistics,dataset_statistics,"
", - Statistics for all languages included in the training dataset mix.
29299,./latency_dataset,latency_dataset,We provide the datasets we collect in the , folder.
29299,./latency_dataset/predictors,latency_dataset/predictors, file contains the predictor's model architecture and training settings. We provide pre-trained predictors in , folder.
29317,https://grouplens.org/datasets/movielens/20m/,MovieLens 20M Dataset,Experients 7-10 are based on the ," which must be saved in as ""ratings.csv"" in the data subfolder."
29324,https://allenai.org/data/cord-19,COVID-19 Open Research Dataset (CORD-19),This application serves data from , dataset.
29358,#vlengagement-datasets,VLEngagement Datasets,"
","
"
29358,#vlengagement-12k-dataset,VLEngagement Dataset,"
","
"
29364,https://github.com/DefuLian/recsys/blob/master/test/dataset/test_script.m,test/dataset/test_script.m,See , for some examples of how to use this portal
29383,./notebooks/resize_hdataset.ipynb,resize_hdataset.ipynb,Before training we resize HAdobe5k subdataset so that each side is smaller than 1024. The resizing script is provided in ,.
29409,https://github.com/BIMCV-CSUSP/BIMCV-COVID-19/tree/master/padchest-covid#data-sources-bimcv-padchest,"The Padchest-pneumonia dataset, here","
","
"
29418,./data/,dataset, to use the , or the 
29425,https://dasci.es/transferencia/dascii-hub/open-data/covidgr-2/,More information about these datasets,Datasets of X-Ray imaging for detection of COVID-19. ,"
"
29449,data/reddit,"In data/reddit, we provide the Reddit data set we gathered.","
","
"
29476,https://tslearn.readthedocs.io/en/stable/gen_modules/tslearn.datasets.html#module-tslearn.datasets,You can load any of the UCR datasets in the required format.,"
","
"
29476,https://tslearn.readthedocs.io/en/stable/gen_modules/tslearn.datasets.html#module-tslearn.datasets,UCR Datasets,| data                                                                                                                                                                                         | processing                                                                                                              | clustering                                                                                                                                                       | classification                                                                                                                                                                          | regression                                                                                                                                                                           | metrics                                                                                                                              | |----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------| | ,                                                                           | 
29550,https://console.cloud.google.com/bigquery?project=crypto-eon-164220&p=crypto-eon-164220&d=historic&page=dataset,historic dataset,Open , in BigQuery
29575,#datasets,Datasets,"
","
"
29596,https://archive.ics.uci.edu/ml/datasets/Heterogeneity+Activity+Recognition,https://archive.ics.uci.edu/ml/datasets/Heterogeneity+Activity+Recognition,HHAR ,"
"
29596,https://archive.ics.uci.edu/ml/datasets/pamap2+physical+activity+monitoring,https://archive.ics.uci.edu/ml/datasets/pamap2+physical+activity+monitoring,PAMAP2 ,"
"
29605,docs/INSTALL.md#use-custom-dataset-optional,INSTALL.md/Use Custom Dataset, Please refer to ,.
29620,#dataset-prepare,Dataset prepare,"
","
"
29623,https://ls11-www.cs.tu-dortmund.de/staff/morris/graphkerneldatasets,Benchmark datasets for graph kernels,"
","
"
29630,./create_dataset_arrays.py,"
create_dataset_arrays.py
","
",": Processes a graph, as an edge-list file, and produces training files."
29630,./datasets,"
datasets/
","
",: Directory containing datasets used in our paper. The original datasets come from 
29630,./create_dataset_arrays.py,"
create_dataset_arrays.py
","To use, you must first create dataset files (using ","), then train the node embeddings and the edge function (using "
29630,./datasets/,datasets,". For example, if you want to simulate walks for the PPI dataset (see ","), then you can run the command:"
29717,https://keras.io/api/datasets/imdb/,IMDB Dataset,", ","
"
29738,http://mirg.city.ac.uk/codeapps/the-magnatagatune-dataset,MagnaTagATune Dataset,"
","
"
29785,http://people.ee.ethz.ch/~ihnatova/pynet-bokeh.html#dataset,EBB! dataset,Download the , and extract it into 
29807,https://landsat.usgs.gov/landsat-8-cloud-cover-assessment-validation-data,Biome dataset,Additionally it also accepts an image with its manually annotated cloud mask from the , or from the 
29814,http://odds.cs.stonybrook.edu/yelpchi-dataset/,Yelp Spam Review Datasets,"To run the code, you need the ",. Please send email with the title 
29816,https://archive.ics.uci.edu/ml/datasets/covertype,covertype dataset,Bayesian logistic regression with Gaussian prior on ," (the code is already prepared to download it). The code samples from the posterior using antithetic MLMC on the discretised Stochastic Langeving SDE and approximates E(F(X)), with F(X) = |X|^2. The code returns various plots specifying computational costs necessary to achieve different Mean Squared Errors."
29845,#datasets,Datasets,"
","
"
29851,/queries/statistics_dataset.md,statistics dataset,"After starting the server and logging in the browser interface (see Step 3 above), you can run the following SPARQL queries on the newly loaded triples: ",", "
29870,#datasets,Datasets,"
","
"
29884,#datasets,Datasets,"
","
"
29884,#creating-and-preprocessing-a-new-java-dataset,creating a new Java dataset,For , or 
29916,https://pytorch.org/docs/stable/torchvision/datasets.html#imagenet,torchvision.datasets,We hope to make our labels easier to use by integrating them with , after the release.
29916,https://www.tensorflow.org/datasets/catalog/imagenet2012_real,TensorFlow Datasets,Our labels are available in the , library.
30024,https://github.com/snakers4/open_stt/#dataset-composition,Dataset composition,"
","
"
30024,https://azure.microsoft.com/en-us/services/open-datasets/,Azure Open Datasets,Newest direct download links are a courtesy of ,;
30109,https://newsela.com/data/,[Newsela dataset], For the simplified outputs for the ,", please reach out to me at ddhruvkr@gmail.com. This is because the Newsela dataset is not publically available and only available via a contract with Newsela."
30120,#datasets,Datasets,"
","
"
30120,https://github.com/DavidDiazGuerra/Cross3D/tree/master/datasets/LibriSpeech,datasets/LibriSpeech," in your machine. By default, the main scripts look for it in ", but you can modify its phat with the 
30120,https://github.com/DavidDiazGuerra/Cross3D/tree/master/datasets/LOCATA,datasets/LOCATA,". By default, the main scripts look for it in ", but you can modify its phat with the 
30146,baal/active/dataset.py,"
ActiveLearningDataset
","
","
"
30149,#pre-training-datasets,Pre-training datasets,"
","
"
30149,#downstream-datasets,Downstream datasets,"
","
"
30179,https://www.dropbox.com/s/424wm7cp2fa4o2o/dataset.zip?dl=1,[dataset.zip],"Link to full dataset, with the extracted ROI frames and 3D reconstruction data (NMFCs, landmarks, expression, identity and camera parameters): ","
"
30231,https://mmselfsup.readthedocs.io/en/dev-1.x/user_guides/2_dataset_prepare.html,Prepare Dataset,"
","
"
30238,https://data-efficient-gans.mit.edu/datasets/,datasets, | , | 
30286,https://www.dropbox.com/s/ecem4kq0fdkver4/cityscapes-vps-dataset-1.0.zip?dl=0,Dataset,] [,] [
30338,https://github.com/google-research/meta-dataset#user-instructions,Meta-Dataset repository,"Follow the the ""User instructions"" in the "," for ""Installation"" and ""Downloading and converting datasets""."
30412,https://data.csail.mit.edu/graphics/fivek/,MIT-Adobe FiveK dataset,As the dataset was originally rendered using raw images taken from the ,", our sRGB2XYZ dataset follows the original license of the "
30412,https://data.csail.mit.edu/graphics/fivek/,MIT-Adobe FiveK dataset,", our sRGB2XYZ dataset follows the original license of the ",.
30418,#link-of-the-dataset,Dataset Description,"
","
"
30420,https://lmb.informatik.uni-freiburg.de/resources/datasets/SceneFlowDatasets.en.html,Scene Flow Datasets,Download ,", "
30438,https://grouplens.org/datasets/movielens,MovieLens Dataset,"
","
"
30465,https://pykeen.readthedocs.io/en/latest/byo/data.html,using your own dataset," dataclass that has attributes for the trained model, the training loop, the evaluation, and more. See the tutorials on ",", "
30465,https://pykeen.readthedocs.io/en/latest/byo/data.html,Bring Your Own Dataset,"The following 36 datasets are built in to PyKEEN. The citation for each dataset corresponds to either the paper describing the dataset, the first paper published using the dataset with knowledge graph embedding models, or the URL for the dataset if neither of the first two are available. If you want to use a custom dataset, see the "," tutorial. If you have a suggestion for another dataset to include in PyKEEN, please let us know "
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.AristoV4.html,"
pykeen.datasets.AristoV4
",| Name                               | Documentation                                                                                                       | Citation                                                                                                                |   Entities |   Relations |   Triples | |------------------------------------|---------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------|------------|-------------|-----------| | Aristo-v4                          | ,             | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.BioKG.html,"
pykeen.datasets.BioKG
",                                                        |      42016 |        1593 |    279425 | | BioKG                              | ,                   | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.CKG.html,"
pykeen.datasets.CKG
",                                                         |     105524 |          17 |   2067997 | | Clinical Knowledge Graph           | ,                       | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.CN3l.html,"
pykeen.datasets.CN3l
",                                                      |    7617419 |          11 |  26691525 | | CN3l Family                        | ,                     | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.CoDExLarge.html,"
pykeen.datasets.CoDExLarge
",                                                  |       3206 |          42 |     21777 | | CoDEx (large)                      | ,         | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.CoDExMedium.html,"
pykeen.datasets.CoDExMedium
",                                                               |      77951 |          69 |    612437 | | CoDEx (medium)                     | ,       | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.CoDExSmall.html,"
pykeen.datasets.CoDExSmall
",                                                               |      17050 |          51 |    206205 | | CoDEx (small)                      | ,         | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.ConceptNet.html,"
pykeen.datasets.ConceptNet
",                                                               |       2034 |          42 |     36543 | | ConceptNet                         | ,         | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.Countries.html,"
pykeen.datasets.Countries
",                                                                |   28370083 |          50 |  34074917 | | Countries                          | ,           | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.CSKG.html,"
pykeen.datasets.CSKG
",                          |        271 |           2 |      1158 | | Commonsense Knowledge Graph        | ,                     | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.DB100K.html,"
pykeen.datasets.DB100K
",                                                              |    2087833 |          58 |   4598728 | | DB100K                             | ,                 | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.DBpedia50.html,"
pykeen.datasets.DBpedia50
",                                                                 |      99604 |         470 |    697479 | | DBpedia50                          | ,           | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.DRKG.html,"
pykeen.datasets.DRKG
",                                                                  |      24624 |         351 |     34421 | | Drug Repositioning Knowledge Graph | ,                     | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.FB15k.html,"
pykeen.datasets.FB15k
",                                                                         |      97238 |         107 |   5874257 | | FB15k                              | ,                   | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.FB15k237.html,"
pykeen.datasets.FB15k237
", |      14951 |        1345 |    592213 | | FB15k-237                          | ,             | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.Globi.html,"
pykeen.datasets.Globi
",                                                  |      14505 |         237 |    310079 | | Global Biotic Interactions         | ,                   | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.Hetionet.html,"
pykeen.datasets.Hetionet
",                                                   |     404207 |          39 |   1966385 | | Hetionet                           | ,             | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.Kinships.html,"
pykeen.datasets.Kinships
",                                                       |      45158 |          24 |   2250197 | | Kinships                           | ,             | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.Nations.html,"
pykeen.datasets.Nations
",                                             |        104 |          25 |     10686 | | Nations                            | ,               | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.NationsLiteral.html,"
pykeen.datasets.NationsLiteral
",                                                   |         14 |          55 |      1992 | | NationsL                           | , | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.OGBBioKG.html,"
pykeen.datasets.OGBBioKG
",                                                                     |         14 |          55 |      1992 | | OGB BioKG                          | ,             | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.OGBWikiKG2.html,"
pykeen.datasets.OGBWikiKG2
",                                                                   |      45085 |          51 |   5088433 | | OGB WikiKG2                        | ,         | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.OpenBioLink.html,"
pykeen.datasets.OpenBioLink
",                                                                   |    2500604 |         535 |  17137181 | | OpenBioLink                        | ,       | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.OpenBioLinkLQ.html,"
pykeen.datasets.OpenBioLinkLQ
",                                                  |     180992 |          28 |   4563407 | | OpenBioLink LQ                     | ,   | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.OpenEA.html,"
pykeen.datasets.OpenEA
",                                                  |     480876 |          32 |  27320889 | | OpenEA Family                      | ,                 | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.PharmKG.html,"
pykeen.datasets.PharmKG
",                                                     |      15000 |         248 |     38265 | | PharmKG                            | ,               | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.PharmKG8k.html,"
pykeen.datasets.PharmKG8k
",                                                             |     188296 |          39 |   1093236 | | PharmKG8k                          | ,           | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.PrimeKG.html,"
pykeen.datasets.PrimeKG
",                                                             |       7247 |          28 |    485787 | | PrimeKG                            | ,               | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.UMLS.html,"
pykeen.datasets.UMLS
",                                                     |     129375 |          30 |   8100498 | | Unified Medical Language System    | ,                     | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.WD50KT.html,"
pykeen.datasets.WD50KT
",                                                   |        135 |          46 |      6529 | | WD50K (triples)                    | ,                 | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.Wikidata5M.html,"
pykeen.datasets.Wikidata5M
",                                          |      40107 |         473 |    232344 | | Wikidata5M                         | ,         | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.WK3l120k.html,"
pykeen.datasets.WK3l120k
",                                                                 |    4594149 |         822 |  20624239 | | WK3l-120k Family                   | ,             | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.WK3l15k.html,"
pykeen.datasets.WK3l15k
",                                                  |     119748 |        3109 |   1375406 | | WK3l-15k Family                    | ,               | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.WN18.html,"
pykeen.datasets.WN18
",                                                  |      15126 |        1841 |    209041 | | WordNet-18                         | ,                     | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.WN18RR.html,"
pykeen.datasets.WN18RR
",                                                                |      40943 |          18 |    151442 | | WordNet-18 (RR)                    | ,                 | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.YAGO310.html,"
pykeen.datasets.YAGO310
",                                                  |      40559 |          11 |     92583 | | YAGO3-10                           | ,               | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.ILPC2022Large.html,"
pykeen.datasets.ILPC2022Large
",| Name            | Documentation                                                                                                             | Citation                                                  | |-----------------|---------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------| | ILPC2022 Large  | ,         | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.ILPC2022Small.html,"
pykeen.datasets.ILPC2022Small
", | | ILPC2022 Small  | ,         | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.InductiveFB15k237.html,"
pykeen.datasets.InductiveFB15k237
", | | FB15k-237       | , | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.InductiveNELL.html,"
pykeen.datasets.InductiveNELL
",   | | NELL            | ,         | 
30465,https://pykeen.readthedocs.io/en/latest/api/pykeen.datasets.InductiveWN18RR.html,"
pykeen.datasets.InductiveWN18RR
",   | | WordNet-18 (RR) | ,     | 
30536,https://archive.ics.uci.edu/ml/datasets/adult,Adult Census Dataset,In this example we load the ,* which is a built-in demo dataset. We use CTGAN to learn from the real data and then generate some synthetic data.
30542,http://b2.cvl.iis.u-tokyo.ac.jp/~roxas/data_iros2019_open.zip,dataset,Our dataset can be accessed from: ,". There are 56 image pairs with ground truth depth, simulated LIDAR data, semantic segmentation results from "
30557,dataset/,dataset,"For details and instructions for downloading the dataset used in this work, please see ",.
30596,https://www.tensorflow.org/api_docs/python/tf/data/Dataset,"
tf.data.Dataset
","After downloading the dataset files, you can read them as ", instances with the readers provided. The example below shows how to read the colored-sprites-and-background version of Multi-dSprites:
30607,#datasets,Datasets,"
","
"
30638,dataset,dataset,We release five open-domain distantly/weakly labeled NER datasets here: ,". For gazetteers information and distant label generation code, please directly email cliang73@gatech.edu."
30683,http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d,Kitti Object Detection Dataset,Download the , (
30691,https://www.dropbox.com/s/p5rseuzntkhos7f/data.zip?dl=1,datasets, and , as described in 
30695,https://pytorch.org/vision/stable/datasets.html#imagefolder,"
datasets.ImageFolder
", train and val images. The directory structure is the standard layout for the torchvision , as follows:
30734,https://github.com/waymo-research/waymo-open-dataset,waymo-open-dataset,"
","
"
30750,datasets/datasets.md#top,Datasets,"
","
"
30766,#sample-datasets,"
Sample datasets
","
","
"
30854,http://cocodataset.org/#home,COCO dataset,"For the needs of our application we utilized YOLOv3 detector, trained on the ",. You can download this detector from 
30858,https://github.com/deepmind/multi-object-datasets/,Multi-Object Datasets,. A few steps are required for setting up each individual dataset. We also provide a PyTorch wrapper around the , used for the experiments on the 
30858,https://github.com/deepmind/dsprites-dataset,dSprites dataset,Generate coloured Multi-dSprites from the original , with:
30858,https://github.com/deepmind/gqn-datasets,GQN datasets,The , are quite large. The 
30858,https://github.com/deepmind/multi_object_datasets,Multi-Object Datasets,The repository contains a wrapper around the ,", returning an iterable which behaves similarly to a PyTorch DataLoader object. The default config assumes that any datasets you wish to use have been downloaded to "
30858,https://github.com/deepmind/multi_object_datasets,multi_object_datasets,"
", (Apache v2 license)
30886,http://www.cvlibs.net/download.php?file=data_object_image_2.zip,KITTI dataset,Note that the training of SpatialEmbedding needs KITTI object detection left color images as well as the KINS annotations. Please download images from ,", and unzip the zip file under "
30894,https://medium.com/towards-artificial-intelligence/the-50-best-public-datasets-for-machine-learning-d80e9f030279,The Best Public Datasets for Machine Learning and Data Science,"
", On TowardsDataScience.com
30894,https://www.reddit.com/r/datasets/comments/b4yy6p/480000_rotten_tomato_critic_reviews/,Reddit/r/Datasets,6th post of all-time on ,"
"
30903,https://www.tensorflow.org/datasets/catalog/scientific_papers,Tensorflow Datasets,The dataset is also available on , which makes it easy to use within Tensorflow or colab.
31002,https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/datasets/wikics.html#WikiCS,"
torch_geometric.datasets.WikiCS
",You can load the dataset easily using the , class in PyTorch Geometric. Note that the 
31019,https://kelvins.esa.int/proba-v-super-resolution/data/,dataset,Give easy access to a unique ,", introduced by ESA in 2019, to work on the very challenging task of multi-frame super-resolution. If you've never heard about this computer vision task, "
31019,https://kelvins.esa.int/proba-v-super-resolution/data/,dataset, we give you the possibility to preprocess this ," and dive directly into the design of your methodology. It's a very flexible pipeline where all steps can be easily omitted. All data are included with this repository, already split in train validation and testing. At the end of the process you will have three primary tensors: "
31019,https://kelvins.esa.int/proba-v-super-resolution/data/,original dataset, notebook to process the Proba-V , and obtain the training/validation/testing arrays ready to be used.
31079,#requesting-dataset,Instructions to request our full dataset.,"
","
"
31079,#dataset-contents,Documentation on our dataset structure and contents.,"
","
"
31097,https://github.com/googlecreativelab/quickdraw-dataset,Google QuickDraw dataset,". In particular, these 345 categories are corresponding to the 345 free-hand sketch categories of ",. Please see 
31100,create_datasets.py,create_dataset.py,The 50% dataset has 4GB in size and the 20% dataset has 16.5GB in size. Use the , to create the two datasets used from the original dataset.
31110,http://cseweb.ucsd.edu/~jmcauley/datasets.html,dataset link,The original dataset are from ,", including Amazon QA and reviews data."
31111,http://cseweb.ucsd.edu/~jmcauley/datasets.html,dataset link,The Amazon PQA dataset (including reviews and QA data) can be downloaded from ,.
31131,#1-our-dataset-contribution,1. Our dataset contribution,"
","
"
31131,#the-dataset-splits,The dataset splits,"
","
"
31131,#2-dataset-downloading-and-license,2. Dataset downloading and license,"
","
"
31131,#dataset-statistics,Dataset statistics,"
","
"
31131,#prepare-traineval-datasets,Prepare train+eval datasets,"
","
"
31131,dataset,dataset, images at ,. Metadata and box annotations already exist in this repository under 
31131,dataset,dataset,". OpenImages mask annotations are also downloaded by the above script, and will be saved under ", with the images.
31166,#create-the-dataset,Create the dataset,"
","
"
31166,#settings-for-the-creation-of-the-dataset,Settings for the creation of the dataset,"
","
"
31166,#create-the-dataset,create the dataset,"The above commands will start the process of optimizing the baseline DNN, using the data that were created in the ", section.
31187,https://github.com/alters-mit/tdw_image_dataset,tdw_image_dataset,High-level API: ,"
"
31222,http://www.cs.columbia.edu/CAVE/databases/multispectral,CAVE dataset,) of the , (Using 
31236,https://huggingface.co/datasets,HuggingFace Datasets Hub," major public datasets (image datasets, audio datasets, text datasets in 467 languages and dialects, etc.) provided on the ",. With a simple command like 
31236,https://huggingface.co/datasets,"🔎 Find a dataset in the Hub
","
","
"
31236,https://huggingface.co/docs/datasets/share.html,"🌟 Add a new dataset to the Hub
","
","
"
31236,https://github.com/tensorflow/datasets,TensorFlow Datasets,🤗 Datasets originated from a fork of the awesome , and the HuggingFace team want to deeply thank the TensorFlow Datasets team for building this amazing library. More details on the differences between 🤗 Datasets and 
31236,#main-differences-between--datasets-and-tfds,"Main differences between 🤗 Datasets and tfds
", can be found in the section ,.
31236,https://huggingface.co/datasets,HuggingFace Datasets Hub, datasets already provided on the ,.
31236,https://huggingface.co/docs/datasets/upload_dataset,how to upload a dataset to the Hub using your web browser or Python,"
", and also
31245,https://github.com/piergiaj/AViD/tree/master/dataset,dataset,"The annotations are provided in this repository, in the ", directory. This contains the 
31245,https://github.com/piergiaj/AViD/blob/master/dataset/avid_full.json,full dataset, directory. This contains the , with labels and weak tags as well as classification-only 
31256,./docs/en/developer/datasets.md,Dataset Guide,", ",", "
31280,#2-dataset,2. Dataset,"
","
"
31284,https://www.eecs.yorku.ca/~kamel/sidd/dataset.php,SIDD Medium Dataset,The DANet model was trained on ,", and tested on SIDD "
31306,https://www.robots.ox.ac.uk/~vgg/data/vgg_face/,Oxford's VGGFace Dataset,Each row / column is one of 2622 classes (celebrities) from ,". Male vs. female celebrities define the major two blocks in the matrix. Prominent subgroups in these blocks are based on wrinkles and hair / skin color. Chromaticity defines two of these sub-groups (split marked in red), and indicates that the CNN uses unreliable features to recognize the corresponding celebrities."
31309,http://cocodataset.org/#download,official COCO dataset website,Please follow the , to download the dataset. After downloading the dataset you should have the following directory structure:
31339,https://github.com/googlecreativelab/quickdraw-dataset,"Quick, Draw! Dataset", trained on ,. Each time any of categories from the dataset appears on the page I generate and add random picture somewhere arround.
31383,https://download.visinf.tu-darmstadt.de/data/from_games/,GTA5 dataset,Download ,.
31399,#multiviewx-dataset,MultiviewX dataset,"
","
"
31417,datasets/README.md,Download Datasets,"
","
"
31432,#datasets,Datasets,"
","
"
31445,https://pyterrier.readthedocs.io/en/latest/datasets.html,dataset API,PyTerrier allows simple access to standard information retrieval test collections through its ,", which can download the topics, qrels, corpus or, for some test collections, a ready-made Terrier index."
31445,https://github.com/allenai/ir_datasets,ir_datasets package,All datasets from the , are available under the 
31447,#input-dataset,Input Dataset,"
","
"
31502,#synthetic-dataset,Comparisons of Reconstruction on the synthetic dataset,"
","
"
31502,#real-dataset,Comparisons of Reconstruction on the real dataset,"
","
"
31575,https://download.visinf.tu-darmstadt.de/data/from_games/,The GTA5 Dataset,Download ,"
"
31575,http://synthia-dataset.net/download/808/,The SYNTHIA Dataset,Download ,"
"
31575,https://www.cityscapes-dataset.com/,The Cityscapes Dataset,Download ,"
"
31658,https://github.com/hpatches/hpatches-dataset,HPatches dataset repository, and HPSequences dataset published along with it (,). Thanks to the authors for providing the dataset and the evaluation details.
31687,#dataset-preparation,Dataset Preparation,"
","
"
31699,#drkg-dataset,DRKG dataset,"We present an example of using pretrained DRKG model for drug repurposing for COVID-19. In the example, we directly use the pretrained model provided at ", and proposed 100 drugs for COVID-19. The following notebook provides the details:
31739,https://github.com/evidencebp/commit-classification/tree/master/data,Data sets,"
","
"
31782,https://github.com/JDAI-CV/lapa-dataset,https://github.com/JDAI-CV/lapa-dataset, : ,"
"
31807,https://cocodataset.org/#keypoints-2017,COCO 2017 dataset,COCO-WholeBody dataset is the first large-scale benchmark for whole-body pose estimation. It is an extension of , with the same train/val split as COCO.
31807,https://github.com/cocodataset/cocoapi,@cocodataset/cocoapi,We provide evaluation tools for COCO-WholeBody dataset. Our evaluation tools is developed based on ,.
31810,https://github.com/EricArazo/PseudoLabeling/blob/master/miniImagenet/dataset/create_dataset.txt,create_dataset.txt,"To run the CIFAR experiments download the corresponding dataset in the folder ./CIFAR10/data or ./CIFAR100/data. To run the MiniImageNet experiments download the ImageNet dataset, pre-process it (see ","), and place it in ./miniImagenet/data."
31821,#dataset-and-pre-processing,Dataset and Pre-processing,"
","
"
31877,https://github.com/alexandre-bayle/cvci/blob/master/processing_dataset.py,processing_dataset.py,"
",": performs the initial processing of the dataset; takes as inputs the task (""Clf"" or ""Reg"") and the path to the folder where you saved the downloaded dataset (Higgs dataset for ""Clf"" and FlightDelays dataset for ""Reg""),"
31902,dataset_train.txt,dataset_train.txt,Download the source file ,"
"
31906,#hd-dataset-results,HD Dataset Results,"
","
"
31968,https://www.kaggle.com/google/google-landmarks-dataset,Google-Landmarks Dataset,", which has been trained on the ",", a large dataset consisting of more than 1M images and 15K classes."
31976,http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d,Kitti Object Detection Dataset,Download the , (
32037,[/meta/dataset/kg/raw/,/meta/dataset/kg/raw/,", the fact file could be found in directory ",". Before, next two tasks, query registration and maintaining query results, set few parameters in "
32070,#dataset,Dataset,"
","
"
32104,./docs/data/pre_data.md,Prepare Public Dataset,"
","
"
32104,./docs/data/marker/marker.md,Prepare Customized Dataset,"
","
"
32116,#dataset-for-data-augmentation,Dataset for data augmentation,"
","
"
